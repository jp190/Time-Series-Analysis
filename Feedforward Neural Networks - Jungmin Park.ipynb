{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\tClassification of XOR data (20 + 10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 (a)\tPlot the decision boundaries of the earliest network in the training process that achieves 100% accuracy by plotting the network outputs in a densely sampled region around [-0.5,1.5] x [-0.5,1.5]. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,3)\n",
    "        self.fc2 = nn.Linear(3,3)\n",
    "        self.fc3 = nn.Linear(3,3)\n",
    "        self.fc4 = nn.Linear(3,3)\n",
    "        self.fc5 = nn.Linear(3,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "\n",
    "\n",
    "def plot_decision_boundary(clf, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    #x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    #y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    x_min, x_max = -0.5, 1.5\n",
    "    y_min, y_max = -0.5, 1.5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    X_out = net(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype = torch.float))\n",
    "    Z = X_out.data.max(1)[1]\n",
    "    # Z.shape\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "\n",
    "    \n",
    "\n",
    "# input values\n",
    "X = np.array([[0.,0.], [0.,1.], [1.,0.], [1.,1.]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "# read data         \n",
    "X = torch.tensor(X, dtype = torch.float)   \n",
    "y = torch.tensor(y, dtype = torch.long)    \n",
    "\n",
    "# train \n",
    "net = Net()\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# create a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "nepochs = 10000\n",
    "data, target = X, y\n",
    "\n",
    "# run the main training loop\n",
    "for epoch in range(nepochs):\n",
    "#    adjust learning rate if desired\n",
    "#    if epoch % 3000 == 0 and epoch <= 24000:\n",
    "#        for g in optimizer.param_groups:\n",
    "#            g['lr'] = g['lr']/2\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagate\n",
    "    net_out = net(data)\n",
    "    # compute loss\n",
    "    loss = criterion(net_out, target)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # print out report\n",
    "    if epoch % 10 == 0:\n",
    "        #print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correctidx = pred.eq(target.data) \n",
    "        ncorrect = correctidx.sum()\n",
    "        accuracy = ncorrect.item()/len(data)\n",
    "        #print('Training accuracy is ', accuracy)\n",
    "\n",
    "plot_decision_boundary(net, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 (b)\tPlot the decision boundaries of a network after the cross-entropy loss falls below 1x10^(-4). (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,3)\n",
    "        self.fc2 = nn.Linear(3,3)\n",
    "        self.fc3 = nn.Linear(3,3)\n",
    "        self.fc4 = nn.Linear(3,3)\n",
    "        self.fc5 = nn.Linear(3,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "def plot_decision_boundary(clf, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    #x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    #y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    x_min, x_max = -0.5, 1.5\n",
    "    y_min, y_max = -0.5, 1.5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    X_out = net(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype = torch.float))\n",
    "    Z = X_out.data.max(1)[1]\n",
    "    # Z.shape\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "\n",
    "\n",
    "# input values\n",
    "X = np.array([[0.,0.], [0.,1.], [1.,0.], [1.,1.]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "# read data         \n",
    "X = torch.tensor(X, dtype = torch.float)   \n",
    "y = torch.tensor(y, dtype = torch.long)    \n",
    "\n",
    "# train \n",
    "net = Net()\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# create a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "nepochs = 10000\n",
    "data, target = X, y\n",
    "\n",
    "# run the main training loop\n",
    "for epoch in range(nepochs):\n",
    "#    adjust learning rate if desired\n",
    "#    if epoch % 3000 == 0 and epoch <= 24000:\n",
    "#        for g in optimizer.param_groups:\n",
    "#            g['lr'] = g['lr']/2\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagate\n",
    "    net_out = net(data)\n",
    "    # compute loss\n",
    "    loss = criterion(net_out, target)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # print out report\n",
    "    if epoch % 10 == 0:\n",
    "        #print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correctidx = pred.eq(target.data) \n",
    "        ncorrect = correctidx.sum()\n",
    "        accuracy = ncorrect.item()/len(data)\n",
    "        #print('Training accuracy is ', accuracy)\n",
    "    if loss.item() < 10^(-4):\n",
    "        break   \n",
    "\n",
    "\n",
    "plot_decision_boundary(net, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Gradually decrease the capacity of the network above.  Find the smallest network that can still separate the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 (a)\tWhat are the number of hidden layers and neurons of the smallest network that still can separate the data? (5 points)\n",
    "\n",
    "Hidden layers of the smallest network: 2\n",
    "\n",
    "number of neurons of the smallest network: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss  0.7004944086074829\n",
      "Training accuracy is  0.5\n",
      "Epoch  10 Loss  0.6977705955505371\n",
      "Training accuracy is  0.5\n",
      "Epoch  20 Loss  0.6948106288909912\n",
      "Training accuracy is  0.5\n",
      "Epoch  30 Loss  0.6936300992965698\n",
      "Training accuracy is  0.5\n",
      "Epoch  40 Loss  0.6933964490890503\n",
      "Training accuracy is  0.5\n",
      "Epoch  50 Loss  0.6933751106262207\n",
      "Training accuracy is  0.5\n",
      "Epoch  60 Loss  0.6933529376983643\n",
      "Training accuracy is  0.5\n",
      "Epoch  70 Loss  0.6933220028877258\n",
      "Training accuracy is  0.5\n",
      "Epoch  80 Loss  0.6932957172393799\n",
      "Training accuracy is  0.5\n",
      "Epoch  90 Loss  0.6932758688926697\n",
      "Training accuracy is  0.5\n",
      "Epoch  100 Loss  0.6932597756385803\n",
      "Training accuracy is  0.5\n",
      "Epoch  110 Loss  0.6932457685470581\n",
      "Training accuracy is  0.5\n",
      "Epoch  120 Loss  0.6932333707809448\n",
      "Training accuracy is  0.5\n",
      "Epoch  130 Loss  0.6932224035263062\n",
      "Training accuracy is  0.5\n",
      "Epoch  140 Loss  0.6932126879692078\n",
      "Training accuracy is  0.5\n",
      "Epoch  150 Loss  0.6932039856910706\n",
      "Training accuracy is  0.5\n",
      "Epoch  160 Loss  0.6931962966918945\n",
      "Training accuracy is  0.5\n",
      "Epoch  170 Loss  0.6931893229484558\n",
      "Training accuracy is  0.5\n",
      "Epoch  180 Loss  0.6931830644607544\n",
      "Training accuracy is  0.5\n",
      "Epoch  190 Loss  0.693177342414856\n",
      "Training accuracy is  0.5\n",
      "Epoch  200 Loss  0.6931722164154053\n",
      "Training accuracy is  0.5\n",
      "Epoch  210 Loss  0.6931674480438232\n",
      "Training accuracy is  0.5\n",
      "Epoch  220 Loss  0.6931630373001099\n",
      "Training accuracy is  0.5\n",
      "Epoch  230 Loss  0.6931588649749756\n",
      "Training accuracy is  0.5\n",
      "Epoch  240 Loss  0.6931549906730652\n",
      "Training accuracy is  0.5\n",
      "Epoch  250 Loss  0.6931512355804443\n",
      "Training accuracy is  0.5\n",
      "Epoch  260 Loss  0.6931475400924683\n",
      "Training accuracy is  0.5\n",
      "Epoch  270 Loss  0.6931439638137817\n",
      "Training accuracy is  0.5\n",
      "Epoch  280 Loss  0.6931403875350952\n",
      "Training accuracy is  0.5\n",
      "Epoch  290 Loss  0.6931366920471191\n",
      "Training accuracy is  0.5\n",
      "Epoch  300 Loss  0.6931329369544983\n",
      "Training accuracy is  0.5\n",
      "Epoch  310 Loss  0.6931290030479431\n",
      "Training accuracy is  0.5\n",
      "Epoch  320 Loss  0.6931248903274536\n",
      "Training accuracy is  0.5\n",
      "Epoch  330 Loss  0.6931205987930298\n",
      "Training accuracy is  0.5\n",
      "Epoch  340 Loss  0.6931158304214478\n",
      "Training accuracy is  0.5\n",
      "Epoch  350 Loss  0.6931107640266418\n",
      "Training accuracy is  0.5\n",
      "Epoch  360 Loss  0.6931052207946777\n",
      "Training accuracy is  0.5\n",
      "Epoch  370 Loss  0.6930991411209106\n",
      "Training accuracy is  0.5\n",
      "Epoch  380 Loss  0.6930924654006958\n",
      "Training accuracy is  0.5\n",
      "Epoch  390 Loss  0.6930851340293884\n",
      "Training accuracy is  0.5\n",
      "Epoch  400 Loss  0.6930769681930542\n",
      "Training accuracy is  0.5\n",
      "Epoch  410 Loss  0.6930679082870483\n",
      "Training accuracy is  0.5\n",
      "Epoch  420 Loss  0.6930578351020813\n",
      "Training accuracy is  0.5\n",
      "Epoch  430 Loss  0.6930466294288635\n",
      "Training accuracy is  0.5\n",
      "Epoch  440 Loss  0.6930340528488159\n",
      "Training accuracy is  0.5\n",
      "Epoch  450 Loss  0.6930200457572937\n",
      "Training accuracy is  0.5\n",
      "Epoch  460 Loss  0.6930042505264282\n",
      "Training accuracy is  0.5\n",
      "Epoch  470 Loss  0.6929866075515747\n",
      "Training accuracy is  0.5\n",
      "Epoch  480 Loss  0.6929668188095093\n",
      "Training accuracy is  0.5\n",
      "Epoch  490 Loss  0.6929446458816528\n",
      "Training accuracy is  0.5\n",
      "Epoch  500 Loss  0.6929197311401367\n",
      "Training accuracy is  0.5\n",
      "Epoch  510 Loss  0.6928915977478027\n",
      "Training accuracy is  0.5\n",
      "Epoch  520 Loss  0.6928600668907166\n",
      "Training accuracy is  0.5\n",
      "Epoch  530 Loss  0.6928243041038513\n",
      "Training accuracy is  0.5\n",
      "Epoch  540 Loss  0.6927841305732727\n",
      "Training accuracy is  0.5\n",
      "Epoch  550 Loss  0.6927386522293091\n",
      "Training accuracy is  0.5\n",
      "Epoch  560 Loss  0.6926872134208679\n",
      "Training accuracy is  0.5\n",
      "Epoch  570 Loss  0.6926289796829224\n",
      "Training accuracy is  0.5\n",
      "Epoch  580 Loss  0.6925628781318665\n",
      "Training accuracy is  0.5\n",
      "Epoch  590 Loss  0.6924877166748047\n",
      "Training accuracy is  0.5\n",
      "Epoch  600 Loss  0.692402184009552\n",
      "Training accuracy is  0.5\n",
      "Epoch  610 Loss  0.6923115253448486\n",
      "Training accuracy is  0.5\n",
      "Epoch  620 Loss  0.6922096014022827\n",
      "Training accuracy is  0.5\n",
      "Epoch  630 Loss  0.6920949220657349\n",
      "Training accuracy is  0.5\n",
      "Epoch  640 Loss  0.6919652223587036\n",
      "Training accuracy is  0.5\n",
      "Epoch  650 Loss  0.6918177008628845\n",
      "Training accuracy is  0.5\n",
      "Epoch  660 Loss  0.6916497349739075\n",
      "Training accuracy is  0.5\n",
      "Epoch  670 Loss  0.6914569139480591\n",
      "Training accuracy is  0.5\n",
      "Epoch  680 Loss  0.6912357211112976\n",
      "Training accuracy is  0.5\n",
      "Epoch  690 Loss  0.6909807920455933\n",
      "Training accuracy is  0.5\n",
      "Epoch  700 Loss  0.6906841993331909\n",
      "Training accuracy is  0.5\n",
      "Epoch  710 Loss  0.6903399229049683\n",
      "Training accuracy is  0.5\n",
      "Epoch  720 Loss  0.6899498105049133\n",
      "Training accuracy is  0.5\n",
      "Epoch  730 Loss  0.6894934177398682\n",
      "Training accuracy is  0.75\n",
      "Epoch  740 Loss  0.6889573931694031\n",
      "Training accuracy is  0.75\n",
      "Epoch  750 Loss  0.6883183717727661\n",
      "Training accuracy is  0.75\n",
      "Epoch  760 Loss  0.6875576972961426\n",
      "Training accuracy is  0.75\n",
      "Epoch  770 Loss  0.6866433024406433\n",
      "Training accuracy is  1.0\n",
      "Epoch  780 Loss  0.6855352520942688\n",
      "Training accuracy is  1.0\n",
      "Epoch  790 Loss  0.6841709017753601\n",
      "Training accuracy is  1.0\n",
      "Epoch  800 Loss  0.6824769973754883\n",
      "Training accuracy is  1.0\n",
      "Epoch  810 Loss  0.6803504824638367\n",
      "Training accuracy is  1.0\n",
      "Epoch  820 Loss  0.6776363253593445\n",
      "Training accuracy is  1.0\n",
      "Epoch  830 Loss  0.6741814613342285\n",
      "Training accuracy is  1.0\n",
      "Epoch  840 Loss  0.669583261013031\n",
      "Training accuracy is  1.0\n",
      "Epoch  850 Loss  0.6637091040611267\n",
      "Training accuracy is  1.0\n",
      "Epoch  860 Loss  0.6559587717056274\n",
      "Training accuracy is  1.0\n",
      "Epoch  870 Loss  0.6451511979103088\n",
      "Training accuracy is  1.0\n",
      "Epoch  880 Loss  0.6318835616111755\n",
      "Training accuracy is  1.0\n",
      "Epoch  890 Loss  0.6161163449287415\n",
      "Training accuracy is  1.0\n",
      "Epoch  900 Loss  0.5959519743919373\n",
      "Training accuracy is  1.0\n",
      "Epoch  910 Loss  0.5709036588668823\n",
      "Training accuracy is  1.0\n",
      "Epoch  920 Loss  0.5409204959869385\n",
      "Training accuracy is  1.0\n",
      "Epoch  930 Loss  0.5040215849876404\n",
      "Training accuracy is  1.0\n",
      "Epoch  940 Loss  0.4600728750228882\n",
      "Training accuracy is  1.0\n",
      "Epoch  950 Loss  0.41207289695739746\n",
      "Training accuracy is  1.0\n",
      "Epoch  960 Loss  0.36202964186668396\n",
      "Training accuracy is  1.0\n",
      "Epoch  970 Loss  0.31356269121170044\n",
      "Training accuracy is  1.0\n",
      "Epoch  980 Loss  0.26930883526802063\n",
      "Training accuracy is  1.0\n",
      "Epoch  990 Loss  0.22770842909812927\n",
      "Training accuracy is  1.0\n",
      "Epoch  1000 Loss  0.1952604353427887\n",
      "Training accuracy is  1.0\n",
      "Epoch  1010 Loss  0.16770288348197937\n",
      "Training accuracy is  1.0\n",
      "Epoch  1020 Loss  0.14508046209812164\n",
      "Training accuracy is  1.0\n",
      "Epoch  1030 Loss  0.12752258777618408\n",
      "Training accuracy is  1.0\n",
      "Epoch  1040 Loss  0.112921342253685\n",
      "Training accuracy is  1.0\n",
      "Epoch  1050 Loss  0.10070513188838959\n",
      "Training accuracy is  1.0\n",
      "Epoch  1060 Loss  0.09021997451782227\n",
      "Training accuracy is  1.0\n",
      "Epoch  1070 Loss  0.08165823668241501\n",
      "Training accuracy is  1.0\n",
      "Epoch  1080 Loss  0.07449781894683838\n",
      "Training accuracy is  1.0\n",
      "Epoch  1090 Loss  0.06844525784254074\n",
      "Training accuracy is  1.0\n",
      "Epoch  1100 Loss  0.06311193108558655\n",
      "Training accuracy is  1.0\n",
      "Epoch  1110 Loss  0.05868010222911835\n",
      "Training accuracy is  1.0\n",
      "Epoch  1120 Loss  0.05479051545262337\n",
      "Training accuracy is  1.0\n",
      "Epoch  1130 Loss  0.05134008452296257\n",
      "Training accuracy is  1.0\n",
      "Epoch  1140 Loss  0.047998394817113876\n",
      "Training accuracy is  1.0\n",
      "Epoch  1150 Loss  0.04521569609642029\n",
      "Training accuracy is  1.0\n",
      "Epoch  1160 Loss  0.04255042225122452\n",
      "Training accuracy is  1.0\n",
      "Epoch  1170 Loss  0.040365684777498245\n",
      "Training accuracy is  1.0\n",
      "Epoch  1180 Loss  0.03847196325659752\n",
      "Training accuracy is  1.0\n",
      "Epoch  1190 Loss  0.036474574357271194\n",
      "Training accuracy is  1.0\n",
      "Epoch  1200 Loss  0.034731149673461914\n",
      "Training accuracy is  1.0\n",
      "Epoch  1210 Loss  0.03312431648373604\n",
      "Training accuracy is  1.0\n",
      "Epoch  1220 Loss  0.03174954280257225\n",
      "Training accuracy is  1.0\n",
      "Epoch  1230 Loss  0.030418647453188896\n",
      "Training accuracy is  1.0\n",
      "Epoch  1240 Loss  0.02919597178697586\n",
      "Training accuracy is  1.0\n",
      "Epoch  1250 Loss  0.02813258208334446\n",
      "Training accuracy is  1.0\n",
      "Epoch  1260 Loss  0.02707872912287712\n",
      "Training accuracy is  1.0\n",
      "Epoch  1270 Loss  0.026103775948286057\n",
      "Training accuracy is  1.0\n",
      "Epoch  1280 Loss  0.02519681677222252\n",
      "Training accuracy is  1.0\n",
      "Epoch  1290 Loss  0.024308044463396072\n",
      "Training accuracy is  1.0\n",
      "Epoch  1300 Loss  0.023503828793764114\n",
      "Training accuracy is  1.0\n",
      "Epoch  1310 Loss  0.02283705212175846\n",
      "Training accuracy is  1.0\n",
      "Epoch  1320 Loss  0.022037243470549583\n",
      "Training accuracy is  1.0\n",
      "Epoch  1330 Loss  0.021374361589550972\n",
      "Training accuracy is  1.0\n",
      "Epoch  1340 Loss  0.020726878196001053\n",
      "Training accuracy is  1.0\n",
      "Epoch  1350 Loss  0.0201227068901062\n",
      "Training accuracy is  1.0\n",
      "Epoch  1360 Loss  0.019594706594944\n",
      "Training accuracy is  1.0\n",
      "Epoch  1370 Loss  0.019009461626410484\n",
      "Training accuracy is  1.0\n",
      "Epoch  1380 Loss  0.018567707389593124\n",
      "Training accuracy is  1.0\n",
      "Epoch  1390 Loss  0.01804838329553604\n",
      "Training accuracy is  1.0\n",
      "Epoch  1400 Loss  0.017583327367901802\n",
      "Training accuracy is  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1410 Loss  0.01713644526898861\n",
      "Training accuracy is  1.0\n",
      "Epoch  1420 Loss  0.016719579696655273\n",
      "Training accuracy is  1.0\n",
      "Epoch  1430 Loss  0.016310814768075943\n",
      "Training accuracy is  1.0\n",
      "Epoch  1440 Loss  0.015930593013763428\n",
      "Training accuracy is  1.0\n",
      "Epoch  1450 Loss  0.015576733276247978\n",
      "Training accuracy is  1.0\n",
      "Epoch  1460 Loss  0.0152201596647501\n",
      "Training accuracy is  1.0\n",
      "Epoch  1470 Loss  0.014889871701598167\n",
      "Training accuracy is  1.0\n",
      "Epoch  1480 Loss  0.014573548920452595\n",
      "Training accuracy is  1.0\n",
      "Epoch  1490 Loss  0.014256680384278297\n",
      "Training accuracy is  1.0\n",
      "Epoch  1500 Loss  0.013951430097222328\n",
      "Training accuracy is  1.0\n",
      "Epoch  1510 Loss  0.01369971502572298\n",
      "Training accuracy is  1.0\n",
      "Epoch  1520 Loss  0.013408799655735493\n",
      "Training accuracy is  1.0\n",
      "Epoch  1530 Loss  0.013132346794009209\n",
      "Training accuracy is  1.0\n",
      "Epoch  1540 Loss  0.012904522940516472\n",
      "Training accuracy is  1.0\n",
      "Epoch  1550 Loss  0.012624719180166721\n",
      "Training accuracy is  1.0\n",
      "Epoch  1560 Loss  0.012389803305268288\n",
      "Training accuracy is  1.0\n",
      "Epoch  1570 Loss  0.012158827856183052\n",
      "Training accuracy is  1.0\n",
      "Epoch  1580 Loss  0.011931912042200565\n",
      "Training accuracy is  1.0\n",
      "Epoch  1590 Loss  0.011745862662792206\n",
      "Training accuracy is  1.0\n",
      "Epoch  1600 Loss  0.011529565788805485\n",
      "Training accuracy is  1.0\n",
      "Epoch  1610 Loss  0.011328193359076977\n",
      "Training accuracy is  1.0\n",
      "Epoch  1620 Loss  0.011124957352876663\n",
      "Training accuracy is  1.0\n",
      "Epoch  1630 Loss  0.01095210574567318\n",
      "Training accuracy is  1.0\n",
      "Epoch  1640 Loss  0.010751749388873577\n",
      "Training accuracy is  1.0\n",
      "Epoch  1650 Loss  0.010578488931059837\n",
      "Training accuracy is  1.0\n",
      "Epoch  1660 Loss  0.010402758605778217\n",
      "Training accuracy is  1.0\n",
      "Epoch  1670 Loss  0.010249130427837372\n",
      "Training accuracy is  1.0\n",
      "Epoch  1680 Loss  0.010079259052872658\n",
      "Training accuracy is  1.0\n",
      "Epoch  1690 Loss  0.009915911592543125\n",
      "Training accuracy is  1.0\n",
      "Epoch  1700 Loss  0.00976262055337429\n",
      "Training accuracy is  1.0\n",
      "Epoch  1710 Loss  0.00961278099566698\n",
      "Training accuracy is  1.0\n",
      "Epoch  1720 Loss  0.00946851260960102\n",
      "Training accuracy is  1.0\n",
      "Epoch  1730 Loss  0.009329873137176037\n",
      "Training accuracy is  1.0\n",
      "Epoch  1740 Loss  0.009190979413688183\n",
      "Training accuracy is  1.0\n",
      "Epoch  1750 Loss  0.009060944430530071\n",
      "Training accuracy is  1.0\n",
      "Epoch  1760 Loss  0.008938349783420563\n",
      "Training accuracy is  1.0\n",
      "Epoch  1770 Loss  0.008805564604699612\n",
      "Training accuracy is  1.0\n",
      "Epoch  1780 Loss  0.008680966682732105\n",
      "Training accuracy is  1.0\n",
      "Epoch  1790 Loss  0.008557437919080257\n",
      "Training accuracy is  1.0\n",
      "Epoch  1800 Loss  0.00843790266662836\n",
      "Training accuracy is  1.0\n",
      "Epoch  1810 Loss  0.008329207077622414\n",
      "Training accuracy is  1.0\n",
      "Epoch  1820 Loss  0.008213065564632416\n",
      "Training accuracy is  1.0\n",
      "Epoch  1830 Loss  0.008104043081402779\n",
      "Training accuracy is  1.0\n",
      "Epoch  1840 Loss  0.008003037422895432\n",
      "Training accuracy is  1.0\n",
      "Epoch  1850 Loss  0.007900051772594452\n",
      "Training accuracy is  1.0\n",
      "Epoch  1860 Loss  0.007793691009283066\n",
      "Training accuracy is  1.0\n",
      "Epoch  1870 Loss  0.007694080471992493\n",
      "Training accuracy is  1.0\n",
      "Epoch  1880 Loss  0.0075969272293150425\n",
      "Training accuracy is  1.0\n",
      "Epoch  1890 Loss  0.0075074234046041965\n",
      "Training accuracy is  1.0\n",
      "Epoch  1900 Loss  0.007410739082843065\n",
      "Training accuracy is  1.0\n",
      "Epoch  1910 Loss  0.007318990305066109\n",
      "Training accuracy is  1.0\n",
      "Epoch  1920 Loss  0.007227628957480192\n",
      "Training accuracy is  1.0\n",
      "Epoch  1930 Loss  0.007144513074308634\n",
      "Training accuracy is  1.0\n",
      "Epoch  1940 Loss  0.007058779709041119\n",
      "Training accuracy is  1.0\n",
      "Epoch  1950 Loss  0.006974355783313513\n",
      "Training accuracy is  1.0\n",
      "Epoch  1960 Loss  0.006894433870911598\n",
      "Training accuracy is  1.0\n",
      "Epoch  1970 Loss  0.006812782026827335\n",
      "Training accuracy is  1.0\n",
      "Epoch  1980 Loss  0.006734510883688927\n",
      "Training accuracy is  1.0\n",
      "Epoch  1990 Loss  0.006656002253293991\n",
      "Training accuracy is  1.0\n",
      "Epoch  2000 Loss  0.006579822860658169\n",
      "Training accuracy is  1.0\n",
      "Epoch  2010 Loss  0.006505927070975304\n",
      "Training accuracy is  1.0\n",
      "Epoch  2020 Loss  0.006441934499889612\n",
      "Training accuracy is  1.0\n",
      "Epoch  2030 Loss  0.006360987666994333\n",
      "Training accuracy is  1.0\n",
      "Epoch  2040 Loss  0.006291125435382128\n",
      "Training accuracy is  1.0\n",
      "Epoch  2050 Loss  0.006221130955964327\n",
      "Training accuracy is  1.0\n",
      "Epoch  2060 Loss  0.006158086005598307\n",
      "Training accuracy is  1.0\n",
      "Epoch  2070 Loss  0.006091116461902857\n",
      "Training accuracy is  1.0\n",
      "Epoch  2080 Loss  0.006029351148754358\n",
      "Training accuracy is  1.0\n",
      "Epoch  2090 Loss  0.005963267758488655\n",
      "Training accuracy is  1.0\n",
      "Epoch  2100 Loss  0.0058983685448765755\n",
      "Training accuracy is  1.0\n",
      "Epoch  2110 Loss  0.005835691932588816\n",
      "Training accuracy is  1.0\n",
      "Epoch  2120 Loss  0.00578193599358201\n",
      "Training accuracy is  1.0\n",
      "Epoch  2130 Loss  0.0057144323363900185\n",
      "Training accuracy is  1.0\n",
      "Epoch  2140 Loss  0.005656447261571884\n",
      "Training accuracy is  1.0\n",
      "Epoch  2150 Loss  0.005598119460046291\n",
      "Training accuracy is  1.0\n",
      "Epoch  2160 Loss  0.0055392743088305\n",
      "Training accuracy is  1.0\n",
      "Epoch  2170 Loss  0.005489917006343603\n",
      "Training accuracy is  1.0\n",
      "Epoch  2180 Loss  0.005430686753243208\n",
      "Training accuracy is  1.0\n",
      "Epoch  2190 Loss  0.0053802067413926125\n",
      "Training accuracy is  1.0\n",
      "Epoch  2200 Loss  0.005324734374880791\n",
      "Training accuracy is  1.0\n",
      "Epoch  2210 Loss  0.005272148177027702\n",
      "Training accuracy is  1.0\n",
      "Epoch  2220 Loss  0.005219491198658943\n",
      "Training accuracy is  1.0\n",
      "Epoch  2230 Loss  0.005168844014406204\n",
      "Training accuracy is  1.0\n",
      "Epoch  2240 Loss  0.0051200129091739655\n",
      "Training accuracy is  1.0\n",
      "Epoch  2250 Loss  0.005070928484201431\n",
      "Training accuracy is  1.0\n",
      "Epoch  2260 Loss  0.005027020815759897\n",
      "Training accuracy is  1.0\n",
      "Epoch  2270 Loss  0.004975773859769106\n",
      "Training accuracy is  1.0\n",
      "Epoch  2280 Loss  0.0049284216947853565\n",
      "Training accuracy is  1.0\n",
      "Epoch  2290 Loss  0.004881567321717739\n",
      "Training accuracy is  1.0\n",
      "Epoch  2300 Loss  0.004834884777665138\n",
      "Training accuracy is  1.0\n",
      "Epoch  2310 Loss  0.004794746171683073\n",
      "Training accuracy is  1.0\n",
      "Epoch  2320 Loss  0.004747450351715088\n",
      "Training accuracy is  1.0\n",
      "Epoch  2330 Loss  0.004705240949988365\n",
      "Training accuracy is  1.0\n",
      "Epoch  2340 Loss  0.004665798041969538\n",
      "Training accuracy is  1.0\n",
      "Epoch  2350 Loss  0.004619315266609192\n",
      "Training accuracy is  1.0\n",
      "Epoch  2360 Loss  0.004577502142637968\n",
      "Training accuracy is  1.0\n",
      "Epoch  2370 Loss  0.004535654094070196\n",
      "Training accuracy is  1.0\n",
      "Epoch  2380 Loss  0.004494843073189259\n",
      "Training accuracy is  1.0\n",
      "Epoch  2390 Loss  0.004458792041987181\n",
      "Training accuracy is  1.0\n",
      "Epoch  2400 Loss  0.004415614064782858\n",
      "Training accuracy is  1.0\n",
      "Epoch  2410 Loss  0.004378208890557289\n",
      "Training accuracy is  1.0\n",
      "Epoch  2420 Loss  0.004339131526648998\n",
      "Training accuracy is  1.0\n",
      "Epoch  2430 Loss  0.0043046968057751656\n",
      "Training accuracy is  1.0\n",
      "Epoch  2440 Loss  0.004263491369783878\n",
      "Training accuracy is  1.0\n",
      "Epoch  2450 Loss  0.004227133467793465\n",
      "Training accuracy is  1.0\n",
      "Epoch  2460 Loss  0.004192177671939135\n",
      "Training accuracy is  1.0\n",
      "Epoch  2470 Loss  0.004155520349740982\n",
      "Training accuracy is  1.0\n",
      "Epoch  2480 Loss  0.004120342433452606\n",
      "Training accuracy is  1.0\n",
      "Epoch  2490 Loss  0.004084418062120676\n",
      "Training accuracy is  1.0\n",
      "Epoch  2500 Loss  0.004048934672027826\n",
      "Training accuracy is  1.0\n",
      "Epoch  2510 Loss  0.004016753751784563\n",
      "Training accuracy is  1.0\n",
      "Epoch  2520 Loss  0.003982509486377239\n",
      "Training accuracy is  1.0\n",
      "Epoch  2530 Loss  0.003948773257434368\n",
      "Training accuracy is  1.0\n",
      "Epoch  2540 Loss  0.003916073590517044\n",
      "Training accuracy is  1.0\n",
      "Epoch  2550 Loss  0.0038831322453916073\n",
      "Training accuracy is  1.0\n",
      "Epoch  2560 Loss  0.003852779045701027\n",
      "Training accuracy is  1.0\n",
      "Epoch  2570 Loss  0.0038202148862183094\n",
      "Training accuracy is  1.0\n",
      "Epoch  2580 Loss  0.003789345733821392\n",
      "Training accuracy is  1.0\n",
      "Epoch  2590 Loss  0.003758915700018406\n",
      "Training accuracy is  1.0\n",
      "Epoch  2600 Loss  0.0037293273489922285\n",
      "Training accuracy is  1.0\n",
      "Epoch  2610 Loss  0.00369770429097116\n",
      "Training accuracy is  1.0\n",
      "Epoch  2620 Loss  0.00366786471568048\n",
      "Training accuracy is  1.0\n",
      "Epoch  2630 Loss  0.0036384700797498226\n",
      "Training accuracy is  1.0\n",
      "Epoch  2640 Loss  0.0036119315773248672\n",
      "Training accuracy is  1.0\n",
      "Epoch  2650 Loss  0.0035805038642138243\n",
      "Training accuracy is  1.0\n",
      "Epoch  2660 Loss  0.0035530058667063713\n",
      "Training accuracy is  1.0\n",
      "Epoch  2670 Loss  0.003524729749187827\n",
      "Training accuracy is  1.0\n",
      "Epoch  2680 Loss  0.0034963316284120083\n",
      "Training accuracy is  1.0\n",
      "Epoch  2690 Loss  0.003472818061709404\n",
      "Training accuracy is  1.0\n",
      "Epoch  2700 Loss  0.003442504908889532\n",
      "Training accuracy is  1.0\n",
      "Epoch  2710 Loss  0.0034160951618105173\n",
      "Training accuracy is  1.0\n",
      "Epoch  2720 Loss  0.0033891175407916307\n",
      "Training accuracy is  1.0\n",
      "Epoch  2730 Loss  0.003365891519933939\n",
      "Training accuracy is  1.0\n",
      "Epoch  2740 Loss  0.00333741819486022\n",
      "Training accuracy is  1.0\n",
      "Epoch  2750 Loss  0.003312217304483056\n",
      "Training accuracy is  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2760 Loss  0.003286688821390271\n",
      "Training accuracy is  1.0\n",
      "Epoch  2770 Loss  0.0032608313485980034\n",
      "Training accuracy is  1.0\n",
      "Epoch  2780 Loss  0.0032388875260949135\n",
      "Training accuracy is  1.0\n",
      "Epoch  2790 Loss  0.0032122652046382427\n",
      "Training accuracy is  1.0\n",
      "Epoch  2800 Loss  0.0031879788730293512\n",
      "Training accuracy is  1.0\n",
      "Epoch  2810 Loss  0.0031637498177587986\n",
      "Training accuracy is  1.0\n",
      "Epoch  2820 Loss  0.003140204818919301\n",
      "Training accuracy is  1.0\n",
      "Epoch  2830 Loss  0.0031183557584881783\n",
      "Training accuracy is  1.0\n",
      "Epoch  2840 Loss  0.0030938514973968267\n",
      "Training accuracy is  1.0\n",
      "Epoch  2850 Loss  0.003070955164730549\n",
      "Training accuracy is  1.0\n",
      "Epoch  2860 Loss  0.0030478781554847956\n",
      "Training accuracy is  1.0\n",
      "Epoch  2870 Loss  0.003025455167517066\n",
      "Training accuracy is  1.0\n",
      "Epoch  2880 Loss  0.003005712293088436\n",
      "Training accuracy is  1.0\n",
      "Epoch  2890 Loss  0.0029816455207765102\n",
      "Training accuracy is  1.0\n",
      "Epoch  2900 Loss  0.0029604672454297543\n",
      "Training accuracy is  1.0\n",
      "Epoch  2910 Loss  0.002938662888482213\n",
      "Training accuracy is  1.0\n",
      "Epoch  2920 Loss  0.0029169160407036543\n",
      "Training accuracy is  1.0\n",
      "Epoch  2930 Loss  0.0028972539585083723\n",
      "Training accuracy is  1.0\n",
      "Epoch  2940 Loss  0.002875384408980608\n",
      "Training accuracy is  1.0\n",
      "Epoch  2950 Loss  0.002854824298992753\n",
      "Training accuracy is  1.0\n",
      "Epoch  2960 Loss  0.0028339361306279898\n",
      "Training accuracy is  1.0\n",
      "Epoch  2970 Loss  0.0028133424930274487\n",
      "Training accuracy is  1.0\n",
      "Epoch  2980 Loss  0.002793344436213374\n",
      "Training accuracy is  1.0\n",
      "Epoch  2990 Loss  0.0027747456915676594\n",
      "Training accuracy is  1.0\n",
      "Epoch  3000 Loss  0.0027547734789550304\n",
      "Training accuracy is  1.0\n",
      "Epoch  3010 Loss  0.002735515357926488\n",
      "Training accuracy is  1.0\n",
      "Epoch  3020 Loss  0.002715898910537362\n",
      "Training accuracy is  1.0\n",
      "Epoch  3030 Loss  0.002696430077776313\n",
      "Training accuracy is  1.0\n",
      "Epoch  3040 Loss  0.002678597578778863\n",
      "Training accuracy is  1.0\n",
      "Epoch  3050 Loss  0.002659691497683525\n",
      "Training accuracy is  1.0\n",
      "Epoch  3060 Loss  0.0026410238351672888\n",
      "Training accuracy is  1.0\n",
      "Epoch  3070 Loss  0.00262244394980371\n",
      "Training accuracy is  1.0\n",
      "Epoch  3080 Loss  0.0026038922369480133\n",
      "Training accuracy is  1.0\n",
      "Epoch  3090 Loss  0.0025879922322928905\n",
      "Training accuracy is  1.0\n",
      "Epoch  3100 Loss  0.0025684540160000324\n",
      "Training accuracy is  1.0\n",
      "Epoch  3110 Loss  0.0025510608684271574\n",
      "Training accuracy is  1.0\n",
      "Epoch  3120 Loss  0.002533398102968931\n",
      "Training accuracy is  1.0\n",
      "Epoch  3130 Loss  0.0025159732904285192\n",
      "Training accuracy is  1.0\n",
      "Epoch  3140 Loss  0.002498844638466835\n",
      "Training accuracy is  1.0\n",
      "Epoch  3150 Loss  0.002483086660504341\n",
      "Training accuracy is  1.0\n",
      "Epoch  3160 Loss  0.002465688157826662\n",
      "Training accuracy is  1.0\n",
      "Epoch  3170 Loss  0.0024491518270224333\n",
      "Training accuracy is  1.0\n",
      "Epoch  3180 Loss  0.0024324071127921343\n",
      "Training accuracy is  1.0\n",
      "Epoch  3190 Loss  0.0024157206062227488\n",
      "Training accuracy is  1.0\n",
      "Epoch  3200 Loss  0.0023995095398277044\n",
      "Training accuracy is  1.0\n",
      "Epoch  3210 Loss  0.0023848481941968203\n",
      "Training accuracy is  1.0\n",
      "Epoch  3220 Loss  0.0023678899742662907\n",
      "Training accuracy is  1.0\n",
      "Epoch  3230 Loss  0.002352301962673664\n",
      "Training accuracy is  1.0\n",
      "Epoch  3240 Loss  0.002336860401555896\n",
      "Training accuracy is  1.0\n",
      "Epoch  3250 Loss  0.0023210644721984863\n",
      "Training accuracy is  1.0\n",
      "Epoch  3260 Loss  0.00230571161955595\n",
      "Training accuracy is  1.0\n",
      "Epoch  3270 Loss  0.0022912234999239445\n",
      "Training accuracy is  1.0\n",
      "Epoch  3280 Loss  0.0022758699487894773\n",
      "Training accuracy is  1.0\n",
      "Epoch  3290 Loss  0.0022612300235778093\n",
      "Training accuracy is  1.0\n",
      "Epoch  3300 Loss  0.0022465900983661413\n",
      "Training accuracy is  1.0\n",
      "Epoch  3310 Loss  0.002231830032542348\n",
      "Training accuracy is  1.0\n",
      "Epoch  3320 Loss  0.0022171579767018557\n",
      "Training accuracy is  1.0\n",
      "Epoch  3330 Loss  0.0022025154903531075\n",
      "Training accuracy is  1.0\n",
      "Epoch  3340 Loss  0.0021893028169870377\n",
      "Training accuracy is  1.0\n",
      "Epoch  3350 Loss  0.0021746282000094652\n",
      "Training accuracy is  1.0\n",
      "Epoch  3360 Loss  0.0021607286762446165\n",
      "Training accuracy is  1.0\n",
      "Epoch  3370 Loss  0.0021467385813593864\n",
      "Training accuracy is  1.0\n",
      "Epoch  3380 Loss  0.0021327780559659004\n",
      "Training accuracy is  1.0\n",
      "Epoch  3390 Loss  0.00211923336610198\n",
      "Training accuracy is  1.0\n",
      "Epoch  3400 Loss  0.002106791129335761\n",
      "Training accuracy is  1.0\n",
      "Epoch  3410 Loss  0.0020927388686686754\n",
      "Training accuracy is  1.0\n",
      "Epoch  3420 Loss  0.002079994883388281\n",
      "Training accuracy is  1.0\n",
      "Epoch  3430 Loss  0.002066479530185461\n",
      "Training accuracy is  1.0\n",
      "Epoch  3440 Loss  0.0020533790811896324\n",
      "Training accuracy is  1.0\n",
      "Epoch  3450 Loss  0.0020402478985488415\n",
      "Training accuracy is  1.0\n",
      "Epoch  3460 Loss  0.0020274738781154156\n",
      "Training accuracy is  1.0\n",
      "Epoch  3470 Loss  0.0020156532991677523\n",
      "Training accuracy is  1.0\n",
      "Epoch  3480 Loss  0.002002549823373556\n",
      "Training accuracy is  1.0\n",
      "Epoch  3490 Loss  0.0019901609048247337\n",
      "Training accuracy is  1.0\n",
      "Epoch  3500 Loss  0.001977742649614811\n",
      "Training accuracy is  1.0\n",
      "Epoch  3510 Loss  0.001965471776202321\n",
      "Training accuracy is  1.0\n",
      "Epoch  3520 Loss  0.001953290542587638\n",
      "Training accuracy is  1.0\n",
      "Epoch  3530 Loss  0.001941227586939931\n",
      "Training accuracy is  1.0\n",
      "Epoch  3540 Loss  0.0019301180727779865\n",
      "Training accuracy is  1.0\n",
      "Epoch  3550 Loss  0.0019178447546437383\n",
      "Training accuracy is  1.0\n",
      "Epoch  3560 Loss  0.0019061682978644967\n",
      "Training accuracy is  1.0\n",
      "Epoch  3570 Loss  0.0018944907933473587\n",
      "Training accuracy is  1.0\n",
      "Epoch  3580 Loss  0.0018828129395842552\n",
      "Training accuracy is  1.0\n",
      "Epoch  3590 Loss  0.001871163840405643\n",
      "Training accuracy is  1.0\n",
      "Epoch  3600 Loss  0.0018598423339426517\n",
      "Training accuracy is  1.0\n",
      "Epoch  3610 Loss  0.0018486097687855363\n",
      "Training accuracy is  1.0\n",
      "Epoch  3620 Loss  0.001838330994360149\n",
      "Training accuracy is  1.0\n",
      "Epoch  3630 Loss  0.001826679683290422\n",
      "Training accuracy is  1.0\n",
      "Epoch  3640 Loss  0.0018158926395699382\n",
      "Training accuracy is  1.0\n",
      "Epoch  3650 Loss  0.0018048674101009965\n",
      "Training accuracy is  1.0\n",
      "Epoch  3660 Loss  0.001793990028090775\n",
      "Training accuracy is  1.0\n",
      "Epoch  3670 Loss  0.0017832913435995579\n",
      "Training accuracy is  1.0\n",
      "Epoch  3680 Loss  0.0017727111699059606\n",
      "Training accuracy is  1.0\n",
      "Epoch  3690 Loss  0.0017621605657041073\n",
      "Training accuracy is  1.0\n",
      "Epoch  3700 Loss  0.0017523547867313027\n",
      "Training accuracy is  1.0\n",
      "Epoch  3710 Loss  0.001741713611409068\n",
      "Training accuracy is  1.0\n",
      "Epoch  3720 Loss  0.0017314002616330981\n",
      "Training accuracy is  1.0\n",
      "Epoch  3730 Loss  0.0017211759695783257\n",
      "Training accuracy is  1.0\n",
      "Epoch  3740 Loss  0.0017110403859987855\n",
      "Training accuracy is  1.0\n",
      "Epoch  3750 Loss  0.001701053697615862\n",
      "Training accuracy is  1.0\n",
      "Epoch  3760 Loss  0.0016911851707845926\n",
      "Training accuracy is  1.0\n",
      "Epoch  3770 Loss  0.0016813469119369984\n",
      "Training accuracy is  1.0\n",
      "Epoch  3780 Loss  0.0016717169201001525\n",
      "Training accuracy is  1.0\n",
      "Epoch  3790 Loss  0.0016621159156784415\n",
      "Training accuracy is  1.0\n",
      "Epoch  3800 Loss  0.001652366016060114\n",
      "Training accuracy is  1.0\n",
      "Epoch  3810 Loss  0.0016428239177912474\n",
      "Training accuracy is  1.0\n",
      "Epoch  3820 Loss  0.0016334305983036757\n",
      "Training accuracy is  1.0\n",
      "Epoch  3830 Loss  0.0016239774413406849\n",
      "Training accuracy is  1.0\n",
      "Epoch  3840 Loss  0.0016147324349731207\n",
      "Training accuracy is  1.0\n",
      "Epoch  3850 Loss  0.0016055168816819787\n",
      "Training accuracy is  1.0\n",
      "Epoch  3860 Loss  0.00159710634034127\n",
      "Training accuracy is  1.0\n",
      "Epoch  3870 Loss  0.0015875321114435792\n",
      "Training accuracy is  1.0\n",
      "Epoch  3880 Loss  0.0015785839641466737\n",
      "Training accuracy is  1.0\n",
      "Epoch  3890 Loss  0.0015695166075602174\n",
      "Training accuracy is  1.0\n",
      "Epoch  3900 Loss  0.0015606273664161563\n",
      "Training accuracy is  1.0\n",
      "Epoch  3910 Loss  0.0015519167063757777\n",
      "Training accuracy is  1.0\n",
      "Epoch  3920 Loss  0.0015431460924446583\n",
      "Training accuracy is  1.0\n",
      "Epoch  3930 Loss  0.0015345241408795118\n",
      "Training accuracy is  1.0\n",
      "Epoch  3940 Loss  0.0015260211657732725\n",
      "Training accuracy is  1.0\n",
      "Epoch  3950 Loss  0.001517905737273395\n",
      "Training accuracy is  1.0\n",
      "Epoch  3960 Loss  0.001509372377768159\n",
      "Training accuracy is  1.0\n",
      "Epoch  3970 Loss  0.0015008683549240232\n",
      "Training accuracy is  1.0\n",
      "Epoch  3980 Loss  0.001492573181167245\n",
      "Training accuracy is  1.0\n",
      "Epoch  3990 Loss  0.001484158681705594\n",
      "Training accuracy is  1.0\n",
      "Epoch  4000 Loss  0.0014759222976863384\n",
      "Training accuracy is  1.0\n",
      "Epoch  4010 Loss  0.0014678348088636994\n",
      "Training accuracy is  1.0\n",
      "Epoch  4020 Loss  0.0014598064590245485\n",
      "Training accuracy is  1.0\n",
      "Epoch  4030 Loss  0.0014518378302454948\n",
      "Training accuracy is  1.0\n",
      "Epoch  4040 Loss  0.0014438983052968979\n",
      "Training accuracy is  1.0\n",
      "Epoch  4050 Loss  0.001435929094441235\n",
      "Training accuracy is  1.0\n",
      "Epoch  4060 Loss  0.0014287944650277495\n",
      "Training accuracy is  1.0\n",
      "Epoch  4070 Loss  0.0014206452760845423\n",
      "Training accuracy is  1.0\n",
      "Epoch  4080 Loss  0.0014131520874798298\n",
      "Training accuracy is  1.0\n",
      "Epoch  4090 Loss  0.0014056882355362177\n",
      "Training accuracy is  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4100 Loss  0.0013983433600515127\n",
      "Training accuracy is  1.0\n",
      "Epoch  4110 Loss  0.001391117344610393\n",
      "Training accuracy is  1.0\n",
      "Epoch  4120 Loss  0.001383861294016242\n",
      "Training accuracy is  1.0\n",
      "Epoch  4130 Loss  0.0013767542550340295\n",
      "Training accuracy is  1.0\n",
      "Epoch  4140 Loss  0.0013696765527129173\n",
      "Training accuracy is  1.0\n",
      "Epoch  4150 Loss  0.0013626284198835492\n",
      "Training accuracy is  1.0\n",
      "Epoch  4160 Loss  0.0013557297643274069\n",
      "Training accuracy is  1.0\n",
      "Epoch  4170 Loss  0.0013489194680005312\n",
      "Training accuracy is  1.0\n",
      "Epoch  4180 Loss  0.0013419309398159385\n",
      "Training accuracy is  1.0\n",
      "Epoch  4190 Loss  0.0013349715154618025\n",
      "Training accuracy is  1.0\n",
      "Epoch  4200 Loss  0.0013282799627631903\n",
      "Training accuracy is  1.0\n",
      "Epoch  4210 Loss  0.0013214992359280586\n",
      "Training accuracy is  1.0\n",
      "Epoch  4220 Loss  0.0013147777644917369\n",
      "Training accuracy is  1.0\n",
      "Epoch  4230 Loss  0.0013082053046673536\n",
      "Training accuracy is  1.0\n",
      "Epoch  4240 Loss  0.0013016025768592954\n",
      "Training accuracy is  1.0\n",
      "Epoch  4250 Loss  0.0012950595701113343\n",
      "Training accuracy is  1.0\n",
      "Epoch  4260 Loss  0.001288635190576315\n",
      "Training accuracy is  1.0\n",
      "Epoch  4270 Loss  0.0012823899742215872\n",
      "Training accuracy is  1.0\n",
      "Epoch  4280 Loss  0.0012759059900417924\n",
      "Training accuracy is  1.0\n",
      "Epoch  4290 Loss  0.001269571017473936\n",
      "Training accuracy is  1.0\n",
      "Epoch  4300 Loss  0.0012632653815671802\n",
      "Training accuracy is  1.0\n",
      "Epoch  4310 Loss  0.0012569297105073929\n",
      "Training accuracy is  1.0\n",
      "Epoch  4320 Loss  0.0012506238417699933\n",
      "Training accuracy is  1.0\n",
      "Epoch  4330 Loss  0.0012445265892893076\n",
      "Training accuracy is  1.0\n",
      "Epoch  4340 Loss  0.001238369382917881\n",
      "Training accuracy is  1.0\n",
      "Epoch  4350 Loss  0.0012323311530053616\n",
      "Training accuracy is  1.0\n",
      "Epoch  4360 Loss  0.001226322608999908\n",
      "Training accuracy is  1.0\n",
      "Epoch  4370 Loss  0.0012203140649944544\n",
      "Training accuracy is  1.0\n",
      "Epoch  4380 Loss  0.0012148123933002353\n",
      "Training accuracy is  1.0\n",
      "Epoch  4390 Loss  0.0012086243368685246\n",
      "Training accuracy is  1.0\n",
      "Epoch  4400 Loss  0.001202734769321978\n",
      "Training accuracy is  1.0\n",
      "Epoch  4410 Loss  0.0011968746548518538\n",
      "Training accuracy is  1.0\n",
      "Epoch  4420 Loss  0.0011912225745618343\n",
      "Training accuracy is  1.0\n",
      "Epoch  4430 Loss  0.0011853923788294196\n",
      "Training accuracy is  1.0\n",
      "Epoch  4440 Loss  0.0011796809267252684\n",
      "Training accuracy is  1.0\n",
      "Epoch  4450 Loss  0.0011740288464352489\n",
      "Training accuracy is  1.0\n",
      "Epoch  4460 Loss  0.001168406568467617\n",
      "Training accuracy is  1.0\n",
      "Epoch  4470 Loss  0.0011628734646365047\n",
      "Training accuracy is  1.0\n",
      "Epoch  4480 Loss  0.0011573105584830046\n",
      "Training accuracy is  1.0\n",
      "Epoch  4490 Loss  0.0011517771054059267\n",
      "Training accuracy is  1.0\n",
      "Epoch  4500 Loss  0.0011465417919680476\n",
      "Training accuracy is  1.0\n",
      "Epoch  4510 Loss  0.001140978536568582\n",
      "Training accuracy is  1.0\n",
      "Epoch  4520 Loss  0.0011356238974258304\n",
      "Training accuracy is  1.0\n",
      "Epoch  4530 Loss  0.0011303283972665668\n",
      "Training accuracy is  1.0\n",
      "Epoch  4540 Loss  0.0011249136878177524\n",
      "Training accuracy is  1.0\n",
      "Epoch  4550 Loss  0.0011197372805327177\n",
      "Training accuracy is  1.0\n",
      "Epoch  4560 Loss  0.0011144416639581323\n",
      "Training accuracy is  1.0\n",
      "Epoch  4570 Loss  0.0011092948261648417\n",
      "Training accuracy is  1.0\n",
      "Epoch  4580 Loss  0.0011041181860491633\n",
      "Training accuracy is  1.0\n",
      "Epoch  4590 Loss  0.0010990009177476168\n",
      "Training accuracy is  1.0\n",
      "Epoch  4600 Loss  0.0010939730564132333\n",
      "Training accuracy is  1.0\n",
      "Epoch  4610 Loss  0.0010888556716963649\n",
      "Training accuracy is  1.0\n",
      "Epoch  4620 Loss  0.0010838870657607913\n",
      "Training accuracy is  1.0\n",
      "Epoch  4630 Loss  0.0010789782973006368\n",
      "Training accuracy is  1.0\n",
      "Epoch  4640 Loss  0.0010740095749497414\n",
      "Training accuracy is  1.0\n",
      "Epoch  4650 Loss  0.0010690706549212337\n",
      "Training accuracy is  1.0\n",
      "Epoch  4660 Loss  0.0010642207926139235\n",
      "Training accuracy is  1.0\n",
      "Epoch  4670 Loss  0.0010593413608148694\n",
      "Training accuracy is  1.0\n",
      "Epoch  4680 Loss  0.0010545211844146252\n",
      "Training accuracy is  1.0\n",
      "Epoch  4690 Loss  0.0010498203337192535\n",
      "Training accuracy is  1.0\n",
      "Epoch  4700 Loss  0.0010450596455484629\n",
      "Training accuracy is  1.0\n",
      "Epoch  4710 Loss  0.001040239236317575\n",
      "Training accuracy is  1.0\n",
      "Epoch  4720 Loss  0.0010355679551139474\n",
      "Training accuracy is  1.0\n",
      "Epoch  4730 Loss  0.0010309262434020638\n",
      "Training accuracy is  1.0\n",
      "Epoch  4740 Loss  0.0010263142175972462\n",
      "Training accuracy is  1.0\n",
      "Epoch  4750 Loss  0.0010217617964372039\n",
      "Training accuracy is  1.0\n",
      "Epoch  4760 Loss  0.0010172092588618398\n",
      "Training accuracy is  1.0\n",
      "Epoch  4770 Loss  0.001012895256280899\n",
      "Training accuracy is  1.0\n",
      "Epoch  4780 Loss  0.0010082233930006623\n",
      "Training accuracy is  1.0\n",
      "Epoch  4790 Loss  0.0010037599131464958\n",
      "Training accuracy is  1.0\n",
      "Epoch  4800 Loss  0.0009992964332923293\n",
      "Training accuracy is  1.0\n",
      "Epoch  4810 Loss  0.0009948925580829382\n",
      "Training accuracy is  1.0\n",
      "Epoch  4820 Loss  0.0009904885664582253\n",
      "Training accuracy is  1.0\n",
      "Epoch  4830 Loss  0.0009860844584181905\n",
      "Training accuracy is  1.0\n",
      "Epoch  4840 Loss  0.00098185904789716\n",
      "Training accuracy is  1.0\n",
      "Epoch  4850 Loss  0.0009775144280865788\n",
      "Training accuracy is  1.0\n",
      "Epoch  4860 Loss  0.0009732890757732093\n",
      "Training accuracy is  1.0\n",
      "Epoch  4870 Loss  0.0009690633742138743\n",
      "Training accuracy is  1.0\n",
      "Epoch  4880 Loss  0.0009648079867474735\n",
      "Training accuracy is  1.0\n",
      "Epoch  4890 Loss  0.0009606419480405748\n",
      "Training accuracy is  1.0\n",
      "Epoch  4900 Loss  0.0009564757347106934\n",
      "Training accuracy is  1.0\n",
      "Epoch  4910 Loss  0.0009523691260255873\n",
      "Training accuracy is  1.0\n",
      "Epoch  4920 Loss  0.0009483816684223711\n",
      "Training accuracy is  1.0\n",
      "Epoch  4930 Loss  0.0009442153968848288\n",
      "Training accuracy is  1.0\n",
      "Epoch  4940 Loss  0.0009402574505656958\n",
      "Training accuracy is  1.0\n",
      "Epoch  4950 Loss  0.0009361209231428802\n",
      "Training accuracy is  1.0\n",
      "Epoch  4960 Loss  0.0009321331162936985\n",
      "Training accuracy is  1.0\n",
      "Epoch  4970 Loss  0.0009282049140892923\n",
      "Training accuracy is  1.0\n",
      "Epoch  4980 Loss  0.0009242468513548374\n",
      "Training accuracy is  1.0\n",
      "Epoch  4990 Loss  0.0009203184745274484\n",
      "Training accuracy is  1.0\n",
      "Epoch  5000 Loss  0.0009163901559077203\n",
      "Training accuracy is  1.0\n",
      "Epoch  5010 Loss  0.0009125510696321726\n",
      "Training accuracy is  1.0\n",
      "Epoch  5020 Loss  0.0009087119833566248\n",
      "Training accuracy is  1.0\n",
      "Epoch  5030 Loss  0.0009049323853105307\n",
      "Training accuracy is  1.0\n",
      "Epoch  5040 Loss  0.0009010931826196611\n",
      "Training accuracy is  1.0\n",
      "Epoch  5050 Loss  0.0008973433286882937\n",
      "Training accuracy is  1.0\n",
      "Epoch  5060 Loss  0.0008936231606639922\n",
      "Training accuracy is  1.0\n",
      "Epoch  5070 Loss  0.0008898731903173029\n",
      "Training accuracy is  1.0\n",
      "Epoch  5080 Loss  0.0008862125687301159\n",
      "Training accuracy is  1.0\n",
      "Epoch  5090 Loss  0.0008826710982248187\n",
      "Training accuracy is  1.0\n",
      "Epoch  5100 Loss  0.0008788913255557418\n",
      "Training accuracy is  1.0\n",
      "Epoch  5110 Loss  0.0008752603316679597\n",
      "Training accuracy is  1.0\n",
      "Epoch  5120 Loss  0.0008716590236872435\n",
      "Training accuracy is  1.0\n",
      "Epoch  5130 Loss  0.0008681173785589635\n",
      "Training accuracy is  1.0\n",
      "Epoch  5140 Loss  0.0008645458146929741\n",
      "Training accuracy is  1.0\n",
      "Epoch  5150 Loss  0.0008609743090346456\n",
      "Training accuracy is  1.0\n",
      "Epoch  5160 Loss  0.0008574622333981097\n",
      "Training accuracy is  1.0\n",
      "Epoch  5170 Loss  0.0008539501577615738\n",
      "Training accuracy is  1.0\n",
      "Epoch  5180 Loss  0.0008505274308845401\n",
      "Training accuracy is  1.0\n",
      "Epoch  5190 Loss  0.0008470449829474092\n",
      "Training accuracy is  1.0\n",
      "Epoch  5200 Loss  0.0008436818025074899\n",
      "Training accuracy is  1.0\n",
      "Epoch  5210 Loss  0.0008402292151004076\n",
      "Training accuracy is  1.0\n",
      "Epoch  5220 Loss  0.0008368063136003911\n",
      "Training accuracy is  1.0\n",
      "Epoch  5230 Loss  0.0008335025049746037\n",
      "Training accuracy is  1.0\n",
      "Epoch  5240 Loss  0.0008301688358187675\n",
      "Training accuracy is  1.0\n",
      "Epoch  5250 Loss  0.0008269842946901917\n",
      "Training accuracy is  1.0\n",
      "Epoch  5260 Loss  0.0008235612185671926\n",
      "Training accuracy is  1.0\n",
      "Epoch  5270 Loss  0.0008202572935260832\n",
      "Training accuracy is  1.0\n",
      "Epoch  5280 Loss  0.0008169832290150225\n",
      "Training accuracy is  1.0\n",
      "Epoch  5290 Loss  0.0008137089898809791\n",
      "Training accuracy is  1.0\n",
      "Epoch  5300 Loss  0.0008105240995064378\n",
      "Training accuracy is  1.0\n",
      "Epoch  5310 Loss  0.0008072498603723943\n",
      "Training accuracy is  1.0\n",
      "Epoch  5320 Loss  0.0008040947723202407\n",
      "Training accuracy is  1.0\n",
      "Epoch  5330 Loss  0.0008009396260604262\n",
      "Training accuracy is  1.0\n",
      "Epoch  5340 Loss  0.0007978142239153385\n",
      "Training accuracy is  1.0\n",
      "Epoch  5350 Loss  0.0007946589612402022\n",
      "Training accuracy is  1.0\n",
      "Epoch  5360 Loss  0.0007915335008874536\n",
      "Training accuracy is  1.0\n",
      "Epoch  5370 Loss  0.0007884675869718194\n",
      "Training accuracy is  1.0\n",
      "Epoch  5380 Loss  0.000785431417170912\n",
      "Training accuracy is  1.0\n",
      "Epoch  5390 Loss  0.0007823356427252293\n",
      "Training accuracy is  1.0\n",
      "Epoch  5400 Loss  0.0007793292752467096\n",
      "Training accuracy is  1.0\n",
      "Epoch  5410 Loss  0.0007762929890304804\n",
      "Training accuracy is  1.0\n",
      "Epoch  5420 Loss  0.0007733162492513657\n",
      "Training accuracy is  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5430 Loss  0.0007703097653575242\n",
      "Training accuracy is  1.0\n",
      "Epoch  5440 Loss  0.0007673925720155239\n",
      "Training accuracy is  1.0\n",
      "Epoch  5450 Loss  0.00076453504152596\n",
      "Training accuracy is  1.0\n",
      "Epoch  5460 Loss  0.0007615284412167966\n",
      "Training accuracy is  1.0\n",
      "Epoch  5470 Loss  0.0007587005384266376\n",
      "Training accuracy is  1.0\n",
      "Epoch  5480 Loss  0.0007557832868769765\n",
      "Training accuracy is  1.0\n",
      "Epoch  5490 Loss  0.0007528660353273153\n",
      "Training accuracy is  1.0\n",
      "Epoch  5500 Loss  0.00074997846968472\n",
      "Training accuracy is  1.0\n",
      "Epoch  5510 Loss  0.0007471504504792392\n",
      "Training accuracy is  1.0\n",
      "Epoch  5520 Loss  0.0007442926871590316\n",
      "Training accuracy is  1.0\n",
      "Epoch  5530 Loss  0.0007414944702759385\n",
      "Training accuracy is  1.0\n",
      "Epoch  5540 Loss  0.0007386961369775236\n",
      "Training accuracy is  1.0\n",
      "Epoch  5550 Loss  0.0007358978618867695\n",
      "Training accuracy is  1.0\n",
      "Epoch  5560 Loss  0.00073315913323313\n",
      "Training accuracy is  1.0\n",
      "Epoch  5570 Loss  0.0007303905440494418\n",
      "Training accuracy is  1.0\n",
      "Epoch  5580 Loss  0.000727681559510529\n",
      "Training accuracy is  1.0\n",
      "Epoch  5590 Loss  0.0007250321796163917\n",
      "Training accuracy is  1.0\n",
      "Epoch  5600 Loss  0.0007223528809845448\n",
      "Training accuracy is  1.0\n",
      "Epoch  5610 Loss  0.0007196140359155834\n",
      "Training accuracy is  1.0\n",
      "Epoch  5620 Loss  0.0007169347954913974\n",
      "Training accuracy is  1.0\n",
      "Epoch  5630 Loss  0.0007142851827666163\n",
      "Training accuracy is  1.0\n",
      "Epoch  5640 Loss  0.0007116654887795448\n",
      "Training accuracy is  1.0\n",
      "Epoch  5650 Loss  0.0007091350271366537\n",
      "Training accuracy is  1.0\n",
      "Epoch  5660 Loss  0.0007064556702971458\n",
      "Training accuracy is  1.0\n",
      "Epoch  5670 Loss  0.0007038954645395279\n",
      "Training accuracy is  1.0\n",
      "Epoch  5680 Loss  0.0007013054564595222\n",
      "Training accuracy is  1.0\n",
      "Epoch  5690 Loss  0.000698685587849468\n",
      "Training accuracy is  1.0\n",
      "Epoch  5700 Loss  0.0006961848121136427\n",
      "Training accuracy is  1.0\n",
      "Epoch  5710 Loss  0.0006936245481483638\n",
      "Training accuracy is  1.0\n",
      "Epoch  5720 Loss  0.0006911535165272653\n",
      "Training accuracy is  1.0\n",
      "Epoch  5730 Loss  0.00068865274079144\n",
      "Training accuracy is  1.0\n",
      "Epoch  5740 Loss  0.0006861519650556147\n",
      "Training accuracy is  1.0\n",
      "Epoch  5750 Loss  0.0006836809334345162\n",
      "Training accuracy is  1.0\n",
      "Epoch  5760 Loss  0.0006812396459281445\n",
      "Training accuracy is  1.0\n",
      "Epoch  5770 Loss  0.0006787686143070459\n",
      "Training accuracy is  1.0\n",
      "Epoch  5780 Loss  0.0006763273268006742\n",
      "Training accuracy is  1.0\n",
      "Epoch  5790 Loss  0.0006739455857314169\n",
      "Training accuracy is  1.0\n",
      "Epoch  5800 Loss  0.0006715042982250452\n",
      "Training accuracy is  1.0\n",
      "Epoch  5810 Loss  0.0006690927548334002\n",
      "Training accuracy is  1.0\n",
      "Epoch  5820 Loss  0.0006667406996712089\n",
      "Training accuracy is  1.0\n",
      "Epoch  5830 Loss  0.000664418563246727\n",
      "Training accuracy is  1.0\n",
      "Epoch  5840 Loss  0.0006620367057621479\n",
      "Training accuracy is  1.0\n",
      "Epoch  5850 Loss  0.0006596847088076174\n",
      "Training accuracy is  1.0\n",
      "Epoch  5860 Loss  0.0006573623395524919\n",
      "Training accuracy is  1.0\n",
      "Epoch  5870 Loss  0.0006550996913574636\n",
      "Training accuracy is  1.0\n",
      "Epoch  5880 Loss  0.0006528071826323867\n",
      "Training accuracy is  1.0\n",
      "Epoch  5890 Loss  0.0006504848715849221\n",
      "Training accuracy is  1.0\n",
      "Epoch  5900 Loss  0.0006482221069745719\n",
      "Training accuracy is  1.0\n",
      "Epoch  5910 Loss  0.000645929598249495\n",
      "Training accuracy is  1.0\n",
      "Epoch  5920 Loss  0.0006436668336391449\n",
      "Training accuracy is  1.0\n",
      "Epoch  5930 Loss  0.0006414635572582483\n",
      "Training accuracy is  1.0\n",
      "Epoch  5940 Loss  0.000639230536762625\n",
      "Training accuracy is  1.0\n",
      "Epoch  5950 Loss  0.0006369975162670016\n",
      "Training accuracy is  1.0\n",
      "Epoch  5960 Loss  0.0006347942398861051\n",
      "Training accuracy is  1.0\n",
      "Epoch  5970 Loss  0.0006325910217128694\n",
      "Training accuracy is  1.0\n",
      "Epoch  5980 Loss  0.0006304472917690873\n",
      "Training accuracy is  1.0\n",
      "Epoch  5990 Loss  0.0006282737012952566\n",
      "Training accuracy is  1.0\n",
      "Epoch  6000 Loss  0.0006261002854444087\n",
      "Training accuracy is  1.0\n",
      "Epoch  6010 Loss  0.0006239862414076924\n",
      "Training accuracy is  1.0\n",
      "Epoch  6020 Loss  0.0006218425114639103\n",
      "Training accuracy is  1.0\n",
      "Epoch  6030 Loss  0.0006197583279572427\n",
      "Training accuracy is  1.0\n",
      "Epoch  6040 Loss  0.0006176145398057997\n",
      "Training accuracy is  1.0\n",
      "Epoch  6050 Loss  0.0006155899027362466\n",
      "Training accuracy is  1.0\n",
      "Epoch  6060 Loss  0.0006134758586995304\n",
      "Training accuracy is  1.0\n",
      "Epoch  6070 Loss  0.0006113320123404264\n",
      "Training accuracy is  1.0\n",
      "Epoch  6080 Loss  0.0006092776311561465\n",
      "Training accuracy is  1.0\n",
      "Epoch  6090 Loss  0.0006072826217859983\n",
      "Training accuracy is  1.0\n",
      "Epoch  6100 Loss  0.0006052281241863966\n",
      "Training accuracy is  1.0\n",
      "Epoch  6110 Loss  0.0006031438824720681\n",
      "Training accuracy is  1.0\n",
      "Epoch  6120 Loss  0.0006011488731019199\n",
      "Training accuracy is  1.0\n",
      "Epoch  6130 Loss  0.0005991838406771421\n",
      "Training accuracy is  1.0\n",
      "Epoch  6140 Loss  0.0005971292266622186\n",
      "Training accuracy is  1.0\n",
      "Epoch  6150 Loss  0.0005951938219368458\n",
      "Training accuracy is  1.0\n",
      "Epoch  6160 Loss  0.0005931988707743585\n",
      "Training accuracy is  1.0\n",
      "Epoch  6170 Loss  0.0005912932683713734\n",
      "Training accuracy is  1.0\n",
      "Epoch  6180 Loss  0.0005892684566788375\n",
      "Training accuracy is  1.0\n",
      "Epoch  6190 Loss  0.0005873329937458038\n",
      "Training accuracy is  1.0\n",
      "Epoch  6200 Loss  0.000585397589020431\n",
      "Training accuracy is  1.0\n",
      "Epoch  6210 Loss  0.0005834918119944632\n",
      "Training accuracy is  1.0\n",
      "Epoch  6220 Loss  0.0005815564072690904\n",
      "Training accuracy is  1.0\n",
      "Epoch  6230 Loss  0.0005796209443360567\n",
      "Training accuracy is  1.0\n",
      "Epoch  6240 Loss  0.0005777748301625252\n",
      "Training accuracy is  1.0\n",
      "Epoch  6250 Loss  0.0005758691113442183\n",
      "Training accuracy is  1.0\n",
      "Epoch  6260 Loss  0.0005739931366406381\n",
      "Training accuracy is  1.0\n",
      "Epoch  6270 Loss  0.0005721172201447189\n",
      "Training accuracy is  1.0\n",
      "Epoch  6280 Loss  0.0005702710477635264\n",
      "Training accuracy is  1.0\n",
      "Epoch  6290 Loss  0.0005684249335899949\n",
      "Training accuracy is  1.0\n",
      "Epoch  6300 Loss  0.0005666085053235292\n",
      "Training accuracy is  1.0\n",
      "Epoch  6310 Loss  0.0005647623329423368\n",
      "Training accuracy is  1.0\n",
      "Epoch  6320 Loss  0.0005629161023534834\n",
      "Training accuracy is  1.0\n",
      "Epoch  6330 Loss  0.0005610997322946787\n",
      "Training accuracy is  1.0\n",
      "Epoch  6340 Loss  0.0005592832458205521\n",
      "Training accuracy is  1.0\n",
      "Epoch  6350 Loss  0.0005574966198764741\n",
      "Training accuracy is  1.0\n",
      "Epoch  6360 Loss  0.0005557695403695107\n",
      "Training accuracy is  1.0\n",
      "Epoch  6370 Loss  0.0005539828562177718\n",
      "Training accuracy is  1.0\n",
      "Epoch  6380 Loss  0.0005521962302736938\n",
      "Training accuracy is  1.0\n",
      "Epoch  6390 Loss  0.000550409487914294\n",
      "Training accuracy is  1.0\n",
      "Epoch  6400 Loss  0.0005487122107297182\n",
      "Training accuracy is  1.0\n",
      "Epoch  6410 Loss  0.0005469850730150938\n",
      "Training accuracy is  1.0\n",
      "Epoch  6420 Loss  0.0005452877376228571\n",
      "Training accuracy is  1.0\n",
      "Epoch  6430 Loss  0.0005435904604382813\n",
      "Training accuracy is  1.0\n",
      "Epoch  6440 Loss  0.0005418335204012692\n",
      "Training accuracy is  1.0\n",
      "Epoch  6450 Loss  0.0005401361268013716\n",
      "Training accuracy is  1.0\n",
      "Epoch  6460 Loss  0.0005384089308790863\n",
      "Training accuracy is  1.0\n",
      "Epoch  6470 Loss  0.0005367115954868495\n",
      "Training accuracy is  1.0\n",
      "Epoch  6480 Loss  0.0005350737483240664\n",
      "Training accuracy is  1.0\n",
      "Epoch  6490 Loss  0.0005334061570465565\n",
      "Training accuracy is  1.0\n",
      "Epoch  6500 Loss  0.0005317385657690465\n",
      "Training accuracy is  1.0\n",
      "Epoch  6510 Loss  0.0005301007768139243\n",
      "Training accuracy is  1.0\n",
      "Epoch  6520 Loss  0.0005284331273287535\n",
      "Training accuracy is  1.0\n",
      "Epoch  6530 Loss  0.0005267952801659703\n",
      "Training accuracy is  1.0\n",
      "Epoch  6540 Loss  0.0005251872353255749\n",
      "Training accuracy is  1.0\n",
      "Epoch  6550 Loss  0.0005235493299551308\n",
      "Training accuracy is  1.0\n",
      "Epoch  6560 Loss  0.0005219412851147354\n",
      "Training accuracy is  1.0\n",
      "Epoch  6570 Loss  0.0005203629843890667\n",
      "Training accuracy is  1.0\n",
      "Epoch  6580 Loss  0.0005186952766962349\n",
      "Training accuracy is  1.0\n",
      "Epoch  6590 Loss  0.0005171765806153417\n",
      "Training accuracy is  1.0\n",
      "Epoch  6600 Loss  0.0005155386752448976\n",
      "Training accuracy is  1.0\n",
      "Epoch  6610 Loss  0.0005139603745192289\n",
      "Training accuracy is  1.0\n",
      "Epoch  6620 Loss  0.0005124416784383357\n",
      "Training accuracy is  1.0\n",
      "Epoch  6630 Loss  0.0005108633195050061\n",
      "Training accuracy is  1.0\n",
      "Epoch  6640 Loss  0.0005093147628940642\n",
      "Training accuracy is  1.0\n",
      "Epoch  6650 Loss  0.0005077364039607346\n",
      "Training accuracy is  1.0\n",
      "Epoch  6660 Loss  0.0005062176496721804\n",
      "Training accuracy is  1.0\n",
      "Epoch  6670 Loss  0.000504728639498353\n",
      "Training accuracy is  1.0\n",
      "Epoch  6680 Loss  0.0005032396293245256\n",
      "Training accuracy is  1.0\n",
      "Epoch  6690 Loss  0.0005016910727135837\n",
      "Training accuracy is  1.0\n",
      "Epoch  6700 Loss  0.0005002020625397563\n",
      "Training accuracy is  1.0\n",
      "Epoch  6710 Loss  0.0004987130523659289\n",
      "Training accuracy is  1.0\n",
      "Epoch  6720 Loss  0.0004972240421921015\n",
      "Training accuracy is  1.0\n",
      "Epoch  6730 Loss  0.0004957350320182741\n",
      "Training accuracy is  1.0\n",
      "Epoch  6740 Loss  0.0004942460218444467\n",
      "Training accuracy is  1.0\n",
      "Epoch  6750 Loss  0.0004927569534629583\n",
      "Training accuracy is  1.0\n",
      "Epoch  6760 Loss  0.0004912977456115186\n",
      "Training accuracy is  1.0\n",
      "Epoch  6770 Loss  0.0004898682236671448\n",
      "Training accuracy is  1.0\n",
      "Epoch  6780 Loss  0.0004883792134933174\n",
      "Training accuracy is  1.0\n",
      "Epoch  6790 Loss  0.000486949720652774\n",
      "Training accuracy is  1.0\n",
      "Epoch  6800 Loss  0.00048552025691606104\n",
      "Training accuracy is  1.0\n",
      "Epoch  6810 Loss  0.0004841205372940749\n",
      "Training accuracy is  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6820 Loss  0.00048269107355736196\n",
      "Training accuracy is  1.0\n",
      "Epoch  6830 Loss  0.0004812913539353758\n",
      "Training accuracy is  1.0\n",
      "Epoch  6840 Loss  0.0004798916634172201\n",
      "Training accuracy is  1.0\n",
      "Epoch  6850 Loss  0.0004784323391504586\n",
      "Training accuracy is  1.0\n",
      "Epoch  6860 Loss  0.0004770326195284724\n",
      "Training accuracy is  1.0\n",
      "Epoch  6870 Loss  0.00047566270222887397\n",
      "Training accuracy is  1.0\n",
      "Epoch  6880 Loss  0.0004742927267216146\n",
      "Training accuracy is  1.0\n",
      "Epoch  6890 Loss  0.0004729227803181857\n",
      "Training accuracy is  1.0\n",
      "Epoch  6900 Loss  0.0004715528339147568\n",
      "Training accuracy is  1.0\n",
      "Epoch  6910 Loss  0.00047018288751132786\n",
      "Training accuracy is  1.0\n",
      "Epoch  6920 Loss  0.0004688427143264562\n",
      "Training accuracy is  1.0\n",
      "Epoch  6930 Loss  0.00046750257024541497\n",
      "Training accuracy is  1.0\n",
      "Epoch  6940 Loss  0.0004661623388528824\n",
      "Training accuracy is  1.0\n",
      "Epoch  6950 Loss  0.0004648221656680107\n",
      "Training accuracy is  1.0\n",
      "Epoch  6960 Loss  0.0004634819633793086\n",
      "Training accuracy is  1.0\n",
      "Epoch  6970 Loss  0.0004621715925168246\n",
      "Training accuracy is  1.0\n",
      "Epoch  6980 Loss  0.0004608611634466797\n",
      "Training accuracy is  1.0\n",
      "Epoch  6990 Loss  0.0004595209611579776\n",
      "Training accuracy is  1.0\n",
      "Epoch  7000 Loss  0.0004582105320878327\n",
      "Training accuracy is  1.0\n",
      "Epoch  7010 Loss  0.0004569299053400755\n",
      "Training accuracy is  1.0\n",
      "Epoch  7020 Loss  0.00045564924948848784\n",
      "Training accuracy is  1.0\n",
      "Epoch  7030 Loss  0.0004543388495221734\n",
      "Training accuracy is  1.0\n",
      "Epoch  7040 Loss  0.00045302839134819806\n",
      "Training accuracy is  1.0\n",
      "Epoch  7050 Loss  0.00045177756692282856\n",
      "Training accuracy is  1.0\n",
      "Epoch  7060 Loss  0.00045049688196741045\n",
      "Training accuracy is  1.0\n",
      "Epoch  7070 Loss  0.00044921625521965325\n",
      "Training accuracy is  1.0\n",
      "Epoch  7080 Loss  0.0004479653434827924\n",
      "Training accuracy is  1.0\n",
      "Epoch  7090 Loss  0.00044677406549453735\n",
      "Training accuracy is  1.0\n",
      "Epoch  7100 Loss  0.0004454934096429497\n",
      "Training accuracy is  1.0\n",
      "Epoch  7110 Loss  0.0004442425270099193\n",
      "Training accuracy is  1.0\n",
      "Epoch  7120 Loss  0.00044299167348071933\n",
      "Training accuracy is  1.0\n",
      "Epoch  7130 Loss  0.0004417705349624157\n",
      "Training accuracy is  1.0\n",
      "Epoch  7140 Loss  0.000440549454651773\n",
      "Training accuracy is  1.0\n",
      "Epoch  7150 Loss  0.0004392985429149121\n",
      "Training accuracy is  1.0\n",
      "Epoch  7160 Loss  0.0004381370381452143\n",
      "Training accuracy is  1.0\n",
      "Epoch  7170 Loss  0.0004369158996269107\n",
      "Training accuracy is  1.0\n",
      "Epoch  7180 Loss  0.0004356947902124375\n",
      "Training accuracy is  1.0\n",
      "Epoch  7190 Loss  0.00043453325633890927\n",
      "Training accuracy is  1.0\n",
      "Epoch  7200 Loss  0.0004333121469244361\n",
      "Training accuracy is  1.0\n",
      "Epoch  7210 Loss  0.00043209100840613246\n",
      "Training accuracy is  1.0\n",
      "Epoch  7220 Loss  0.0004309294163249433\n",
      "Training accuracy is  1.0\n",
      "Epoch  7230 Loss  0.0004297381092328578\n",
      "Training accuracy is  1.0\n",
      "Epoch  7240 Loss  0.00042860631947405636\n",
      "Training accuracy is  1.0\n",
      "Epoch  7250 Loss  0.00042741495417430997\n",
      "Training accuracy is  1.0\n",
      "Epoch  7260 Loss  0.00042622361797839403\n",
      "Training accuracy is  1.0\n",
      "Epoch  7270 Loss  0.00042512163054198027\n",
      "Training accuracy is  1.0\n",
      "Epoch  7280 Loss  0.00042396006756462157\n",
      "Training accuracy is  1.0\n",
      "Epoch  7290 Loss  0.00042279850458726287\n",
      "Training accuracy is  1.0\n",
      "Epoch  7300 Loss  0.00042169648804701865\n",
      "Training accuracy is  1.0\n",
      "Epoch  7310 Loss  0.00042050512274727225\n",
      "Training accuracy is  1.0\n",
      "Epoch  7320 Loss  0.0004194329085294157\n",
      "Training accuracy is  1.0\n",
      "Epoch  7330 Loss  0.00041827131644822657\n",
      "Training accuracy is  1.0\n",
      "Epoch  7340 Loss  0.00041716929990798235\n",
      "Training accuracy is  1.0\n",
      "Epoch  7350 Loss  0.0004160673124715686\n",
      "Training accuracy is  1.0\n",
      "Epoch  7360 Loss  0.00041493549360893667\n",
      "Training accuracy is  1.0\n",
      "Epoch  7370 Loss  0.0004138335061725229\n",
      "Training accuracy is  1.0\n",
      "Epoch  7380 Loss  0.0004127314605284482\n",
      "Training accuracy is  1.0\n",
      "Epoch  7390 Loss  0.0004115996416658163\n",
      "Training accuracy is  1.0\n",
      "Epoch  7400 Loss  0.0004105274274479598\n",
      "Training accuracy is  1.0\n",
      "Epoch  7410 Loss  0.00040945515502244234\n",
      "Training accuracy is  1.0\n",
      "Epoch  7420 Loss  0.0004083531384821981\n",
      "Training accuracy is  1.0\n",
      "Epoch  7430 Loss  0.00040731069748289883\n",
      "Training accuracy is  1.0\n",
      "Epoch  7440 Loss  0.00040620865183882415\n",
      "Training accuracy is  1.0\n",
      "Epoch  7450 Loss  0.0004051661817356944\n",
      "Training accuracy is  1.0\n",
      "Epoch  7460 Loss  0.0004040939384140074\n",
      "Training accuracy is  1.0\n",
      "Epoch  7470 Loss  0.00040302169509232044\n",
      "Training accuracy is  1.0\n",
      "Epoch  7480 Loss  0.0004020090273115784\n",
      "Training accuracy is  1.0\n",
      "Epoch  7490 Loss  0.0004009367257822305\n",
      "Training accuracy is  1.0\n",
      "Epoch  7500 Loss  0.00039986451156437397\n",
      "Training accuracy is  1.0\n",
      "Epoch  7510 Loss  0.00039882201235741377\n",
      "Training accuracy is  1.0\n",
      "Epoch  7520 Loss  0.0003978093445766717\n",
      "Training accuracy is  1.0\n",
      "Epoch  7530 Loss  0.0003967668453697115\n",
      "Training accuracy is  1.0\n",
      "Epoch  7540 Loss  0.000395754148485139\n",
      "Training accuracy is  1.0\n",
      "Epoch  7550 Loss  0.00039468187605962157\n",
      "Training accuracy is  1.0\n",
      "Epoch  7560 Loss  0.00039369898149743676\n",
      "Training accuracy is  1.0\n",
      "Epoch  7570 Loss  0.00039262667996808887\n",
      "Training accuracy is  1.0\n",
      "Epoch  7580 Loss  0.0003916438145097345\n",
      "Training accuracy is  1.0\n",
      "Epoch  7590 Loss  0.00039066089084371924\n",
      "Training accuracy is  1.0\n",
      "Epoch  7600 Loss  0.0003896183625329286\n",
      "Training accuracy is  1.0\n",
      "Epoch  7610 Loss  0.000388665241189301\n",
      "Training accuracy is  1.0\n",
      "Epoch  7620 Loss  0.0003876823466271162\n",
      "Training accuracy is  1.0\n",
      "Epoch  7630 Loss  0.0003866695915348828\n",
      "Training accuracy is  1.0\n",
      "Epoch  7640 Loss  0.00038568672607652843\n",
      "Training accuracy is  1.0\n",
      "Epoch  7650 Loss  0.0003847335756290704\n",
      "Training accuracy is  1.0\n",
      "Epoch  7660 Loss  0.00038375065196305513\n",
      "Training accuracy is  1.0\n",
      "Epoch  7670 Loss  0.0003827676991932094\n",
      "Training accuracy is  1.0\n",
      "Epoch  7680 Loss  0.0003818145487457514\n",
      "Training accuracy is  1.0\n",
      "Epoch  7690 Loss  0.00038080179365351796\n",
      "Training accuracy is  1.0\n",
      "Epoch  7700 Loss  0.0003798486723098904\n",
      "Training accuracy is  1.0\n",
      "Epoch  7710 Loss  0.00037892532418482006\n",
      "Training accuracy is  1.0\n",
      "Epoch  7720 Loss  0.00037791256909258664\n",
      "Training accuracy is  1.0\n",
      "Epoch  7730 Loss  0.00037695944774895906\n",
      "Training accuracy is  1.0\n",
      "Epoch  7740 Loss  0.00037603609962388873\n",
      "Training accuracy is  1.0\n",
      "Epoch  7750 Loss  0.00037511272239498794\n",
      "Training accuracy is  1.0\n",
      "Epoch  7760 Loss  0.0003741595719475299\n",
      "Training accuracy is  1.0\n",
      "Epoch  7770 Loss  0.0003732063923962414\n",
      "Training accuracy is  1.0\n",
      "Epoch  7780 Loss  0.00037231281748972833\n",
      "Training accuracy is  1.0\n",
      "Epoch  7790 Loss  0.00037141924258321524\n",
      "Training accuracy is  1.0\n",
      "Epoch  7800 Loss  0.0003704362316057086\n",
      "Training accuracy is  1.0\n",
      "Epoch  7810 Loss  0.00036951288348063827\n",
      "Training accuracy is  1.0\n",
      "Epoch  7820 Loss  0.0003685895062517375\n",
      "Training accuracy is  1.0\n",
      "Epoch  7830 Loss  0.0003677257045637816\n",
      "Training accuracy is  1.0\n",
      "Epoch  7840 Loss  0.00036680232733488083\n",
      "Training accuracy is  1.0\n",
      "Epoch  7850 Loss  0.0003659087233245373\n",
      "Training accuracy is  1.0\n",
      "Epoch  7860 Loss  0.00036501517752185464\n",
      "Training accuracy is  1.0\n",
      "Epoch  7870 Loss  0.0003641215735115111\n",
      "Training accuracy is  1.0\n",
      "Epoch  7880 Loss  0.00036319816717877984\n",
      "Training accuracy is  1.0\n",
      "Epoch  7890 Loss  0.00036233433638699353\n",
      "Training accuracy is  1.0\n",
      "Epoch  7900 Loss  0.00036144073237665\n",
      "Training accuracy is  1.0\n",
      "Epoch  7910 Loss  0.0003605769306886941\n",
      "Training accuracy is  1.0\n",
      "Epoch  7920 Loss  0.000359683355782181\n",
      "Training accuracy is  1.0\n",
      "Epoch  7930 Loss  0.0003588195249903947\n",
      "Training accuracy is  1.0\n",
      "Epoch  7940 Loss  0.0003579556941986084\n",
      "Training accuracy is  1.0\n",
      "Epoch  7950 Loss  0.00035703228786587715\n",
      "Training accuracy is  1.0\n",
      "Epoch  7960 Loss  0.00035616845707409084\n",
      "Training accuracy is  1.0\n",
      "Epoch  7970 Loss  0.00035533439950086176\n",
      "Training accuracy is  1.0\n",
      "Epoch  7980 Loss  0.0003544705978129059\n",
      "Training accuracy is  1.0\n",
      "Epoch  7990 Loss  0.00035360679612495005\n",
      "Training accuracy is  1.0\n",
      "Epoch  8000 Loss  0.00035274296533316374\n",
      "Training accuracy is  1.0\n",
      "Epoch  8010 Loss  0.00035193871008232236\n",
      "Training accuracy is  1.0\n",
      "Epoch  8020 Loss  0.0003510748501867056\n",
      "Training accuracy is  1.0\n",
      "Epoch  8030 Loss  0.00035024082171730697\n",
      "Training accuracy is  1.0\n",
      "Epoch  8040 Loss  0.00034940679324790835\n",
      "Training accuracy is  1.0\n",
      "Epoch  8050 Loss  0.0003486025088932365\n",
      "Training accuracy is  1.0\n",
      "Epoch  8060 Loss  0.0003477387363091111\n",
      "Training accuracy is  1.0\n",
      "Epoch  8070 Loss  0.0003469344519544393\n",
      "Training accuracy is  1.0\n",
      "Epoch  8080 Loss  0.00034613016759976745\n",
      "Training accuracy is  1.0\n",
      "Epoch  8090 Loss  0.00034526633680798113\n",
      "Training accuracy is  1.0\n",
      "Epoch  8100 Loss  0.00034446208155713975\n",
      "Training accuracy is  1.0\n",
      "Epoch  8110 Loss  0.0003436578263062984\n",
      "Training accuracy is  1.0\n",
      "Epoch  8120 Loss  0.000342853571055457\n",
      "Training accuracy is  1.0\n",
      "Epoch  8130 Loss  0.00034201948437839746\n",
      "Training accuracy is  1.0\n",
      "Epoch  8140 Loss  0.0003412450314499438\n",
      "Training accuracy is  1.0\n",
      "Epoch  8150 Loss  0.00034044074709527194\n",
      "Training accuracy is  1.0\n",
      "Epoch  8160 Loss  0.0003396364627406001\n",
      "Training accuracy is  1.0\n",
      "Epoch  8170 Loss  0.00033883220748975873\n",
      "Training accuracy is  1.0\n",
      "Epoch  8180 Loss  0.00033802795223891735\n",
      "Training accuracy is  1.0\n",
      "Epoch  8190 Loss  0.0003372236678842455\n",
      "Training accuracy is  1.0\n",
      "Epoch  8200 Loss  0.00033641941263340414\n",
      "Training accuracy is  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8210 Loss  0.00033567470381967723\n",
      "Training accuracy is  1.0\n",
      "Epoch  8220 Loss  0.0003349002217873931\n",
      "Training accuracy is  1.0\n",
      "Epoch  8230 Loss  0.0003340959083288908\n",
      "Training accuracy is  1.0\n",
      "Epoch  8240 Loss  0.00033332142629660666\n",
      "Training accuracy is  1.0\n",
      "Epoch  8250 Loss  0.0003325171710457653\n",
      "Training accuracy is  1.0\n",
      "Epoch  8260 Loss  0.0003317426599096507\n",
      "Training accuracy is  1.0\n",
      "Epoch  8270 Loss  0.0003309979510959238\n",
      "Training accuracy is  1.0\n",
      "Epoch  8280 Loss  0.00033025327138602734\n",
      "Training accuracy is  1.0\n",
      "Epoch  8290 Loss  0.00032950856257230043\n",
      "Training accuracy is  1.0\n",
      "Epoch  8300 Loss  0.00032873405143618584\n",
      "Training accuracy is  1.0\n",
      "Epoch  8310 Loss  0.00032798934262245893\n",
      "Training accuracy is  1.0\n",
      "Epoch  8320 Loss  0.0003272446629125625\n",
      "Training accuracy is  1.0\n",
      "Epoch  8330 Loss  0.00032647018088027835\n",
      "Training accuracy is  1.0\n",
      "Epoch  8340 Loss  0.0003257552452851087\n",
      "Training accuracy is  1.0\n",
      "Epoch  8350 Loss  0.0003250105364713818\n",
      "Training accuracy is  1.0\n",
      "Epoch  8360 Loss  0.0003242658276576549\n",
      "Training accuracy is  1.0\n",
      "Epoch  8370 Loss  0.0003235210897400975\n",
      "Training accuracy is  1.0\n",
      "Epoch  8380 Loss  0.0003227763809263706\n",
      "Training accuracy is  1.0\n",
      "Epoch  8390 Loss  0.0003220316721126437\n",
      "Training accuracy is  1.0\n",
      "Epoch  8400 Loss  0.00032134653883986175\n",
      "Training accuracy is  1.0\n",
      "Epoch  8410 Loss  0.0003206018009223044\n",
      "Training accuracy is  1.0\n",
      "Epoch  8420 Loss  0.00031988692353479564\n",
      "Training accuracy is  1.0\n",
      "Epoch  8430 Loss  0.0003191719588357955\n",
      "Training accuracy is  1.0\n",
      "Epoch  8440 Loss  0.0003184272500220686\n",
      "Training accuracy is  1.0\n",
      "Epoch  8450 Loss  0.00031774211674928665\n",
      "Training accuracy is  1.0\n",
      "Epoch  8460 Loss  0.00031702721025794744\n",
      "Training accuracy is  1.0\n",
      "Epoch  8470 Loss  0.0003163122455589473\n",
      "Training accuracy is  1.0\n",
      "Epoch  8480 Loss  0.00031559730996377766\n",
      "Training accuracy is  1.0\n",
      "Epoch  8490 Loss  0.0003148525720462203\n",
      "Training accuracy is  1.0\n",
      "Epoch  8500 Loss  0.00031422701431438327\n",
      "Training accuracy is  1.0\n",
      "Epoch  8510 Loss  0.0003134823346044868\n",
      "Training accuracy is  1.0\n",
      "Epoch  8520 Loss  0.0003127971722278744\n",
      "Training accuracy is  1.0\n",
      "Epoch  8530 Loss  0.0003120524052064866\n",
      "Training accuracy is  1.0\n",
      "Epoch  8540 Loss  0.00031142684747464955\n",
      "Training accuracy is  1.0\n",
      "Epoch  8550 Loss  0.0003107417142018676\n",
      "Training accuracy is  1.0\n",
      "Epoch  8560 Loss  0.0003100267786066979\n",
      "Training accuracy is  1.0\n",
      "Epoch  8570 Loss  0.0003093118139076978\n",
      "Training accuracy is  1.0\n",
      "Epoch  8580 Loss  0.0003086862852796912\n",
      "Training accuracy is  1.0\n",
      "Epoch  8590 Loss  0.0003080011229030788\n",
      "Training accuracy is  1.0\n",
      "Epoch  8600 Loss  0.0003073159896302968\n",
      "Training accuracy is  1.0\n",
      "Epoch  8610 Loss  0.00030663079814985394\n",
      "Training accuracy is  1.0\n",
      "Epoch  8620 Loss  0.0003059754380956292\n",
      "Training accuracy is  1.0\n",
      "Epoch  8630 Loss  0.0003052902757190168\n",
      "Training accuracy is  1.0\n",
      "Epoch  8640 Loss  0.00030460511334240437\n",
      "Training accuracy is  1.0\n",
      "Epoch  8650 Loss  0.00030397955561056733\n",
      "Training accuracy is  1.0\n",
      "Epoch  8660 Loss  0.0003032943932339549\n",
      "Training accuracy is  1.0\n",
      "Epoch  8670 Loss  0.0003026092308573425\n",
      "Training accuracy is  1.0\n",
      "Epoch  8680 Loss  0.00030198367312550545\n",
      "Training accuracy is  1.0\n",
      "Epoch  8690 Loss  0.00030135808628983796\n",
      "Training accuracy is  1.0\n",
      "Epoch  8700 Loss  0.00030067292391322553\n",
      "Training accuracy is  1.0\n",
      "Epoch  8710 Loss  0.0003000473661813885\n",
      "Training accuracy is  1.0\n",
      "Epoch  8720 Loss  0.00029939194791950285\n",
      "Training accuracy is  1.0\n",
      "Epoch  8730 Loss  0.00029870678554289043\n",
      "Training accuracy is  1.0\n",
      "Epoch  8740 Loss  0.00029808125691488385\n",
      "Training accuracy is  1.0\n",
      "Epoch  8750 Loss  0.0002974556409753859\n",
      "Training accuracy is  1.0\n",
      "Epoch  8760 Loss  0.00029683008324354887\n",
      "Training accuracy is  1.0\n",
      "Epoch  8770 Loss  0.0002961746940854937\n",
      "Training accuracy is  1.0\n",
      "Epoch  8780 Loss  0.0002955193049274385\n",
      "Training accuracy is  1.0\n",
      "Epoch  8790 Loss  0.0002949235204141587\n",
      "Training accuracy is  1.0\n",
      "Epoch  8800 Loss  0.00029429796268232167\n",
      "Training accuracy is  1.0\n",
      "Epoch  8810 Loss  0.0002937021490652114\n",
      "Training accuracy is  1.0\n",
      "Epoch  8820 Loss  0.00029304675990715623\n",
      "Training accuracy is  1.0\n",
      "Epoch  8830 Loss  0.00029242117307148874\n",
      "Training accuracy is  1.0\n",
      "Epoch  8840 Loss  0.00029179558623582125\n",
      "Training accuracy is  1.0\n",
      "Epoch  8850 Loss  0.0002911700285039842\n",
      "Training accuracy is  1.0\n",
      "Epoch  8860 Loss  0.0002905443834606558\n",
      "Training accuracy is  1.0\n",
      "Epoch  8870 Loss  0.000289948598947376\n",
      "Training accuracy is  1.0\n",
      "Epoch  8880 Loss  0.00028932298300787807\n",
      "Training accuracy is  1.0\n",
      "Epoch  8890 Loss  0.0002887272275984287\n",
      "Training accuracy is  1.0\n",
      "Epoch  8900 Loss  0.00028810164076276124\n",
      "Training accuracy is  1.0\n",
      "Epoch  8910 Loss  0.0002875356294680387\n",
      "Training accuracy is  1.0\n",
      "Epoch  8920 Loss  0.00028691001352854073\n",
      "Training accuracy is  1.0\n",
      "Epoch  8930 Loss  0.0002862545952666551\n",
      "Training accuracy is  1.0\n",
      "Epoch  8940 Loss  0.000285688613075763\n",
      "Training accuracy is  1.0\n",
      "Epoch  8950 Loss  0.00028509279945865273\n",
      "Training accuracy is  1.0\n",
      "Epoch  8960 Loss  0.0002845267881639302\n",
      "Training accuracy is  1.0\n",
      "Epoch  8970 Loss  0.0002839012013282627\n",
      "Training accuracy is  1.0\n",
      "Epoch  8980 Loss  0.00028333519003354013\n",
      "Training accuracy is  1.0\n",
      "Epoch  8990 Loss  0.0002827393473125994\n",
      "Training accuracy is  1.0\n",
      "Epoch  9000 Loss  0.00028217333601787686\n",
      "Training accuracy is  1.0\n",
      "Epoch  9010 Loss  0.00028157755150459707\n",
      "Training accuracy is  1.0\n",
      "Epoch  9020 Loss  0.0002810115402098745\n",
      "Training accuracy is  1.0\n",
      "Epoch  9030 Loss  0.00028038592427037656\n",
      "Training accuracy is  1.0\n",
      "Epoch  9040 Loss  0.0002798497152980417\n",
      "Training accuracy is  1.0\n",
      "Epoch  9050 Loss  0.00027925390168093145\n",
      "Training accuracy is  1.0\n",
      "Epoch  9060 Loss  0.00027871766360476613\n",
      "Training accuracy is  1.0\n",
      "Epoch  9070 Loss  0.0002780920476652682\n",
      "Training accuracy is  1.0\n",
      "Epoch  9080 Loss  0.0002775558386929333\n",
      "Training accuracy is  1.0\n",
      "Epoch  9090 Loss  0.00027696002507582307\n",
      "Training accuracy is  1.0\n",
      "Epoch  9100 Loss  0.0002764238161034882\n",
      "Training accuracy is  1.0\n",
      "Epoch  9110 Loss  0.0002758279733825475\n",
      "Training accuracy is  1.0\n",
      "Epoch  9120 Loss  0.00027532156673260033\n",
      "Training accuracy is  1.0\n",
      "Epoch  9130 Loss  0.0002746959507931024\n",
      "Training accuracy is  1.0\n",
      "Epoch  9140 Loss  0.0002741894859354943\n",
      "Training accuracy is  1.0\n",
      "Epoch  9150 Loss  0.00027359367231838405\n",
      "Training accuracy is  1.0\n",
      "Epoch  9160 Loss  0.00027305743424221873\n",
      "Training accuracy is  1.0\n",
      "Epoch  9170 Loss  0.000272461591521278\n",
      "Training accuracy is  1.0\n",
      "Epoch  9180 Loss  0.00027195518487133086\n",
      "Training accuracy is  1.0\n",
      "Epoch  9190 Loss  0.00027141894679516554\n",
      "Training accuracy is  1.0\n",
      "Epoch  9200 Loss  0.0002708231331780553\n",
      "Training accuracy is  1.0\n",
      "Epoch  9210 Loss  0.00027028689510188997\n",
      "Training accuracy is  1.0\n",
      "Epoch  9220 Loss  0.00026972085470333695\n",
      "Training accuracy is  1.0\n",
      "Epoch  9230 Loss  0.00026921441894955933\n",
      "Training accuracy is  1.0\n",
      "Epoch  9240 Loss  0.0002686484076548368\n",
      "Training accuracy is  1.0\n",
      "Epoch  9250 Loss  0.0002681419427972287\n",
      "Training accuracy is  1.0\n",
      "Epoch  9260 Loss  0.0002676057047210634\n",
      "Training accuracy is  1.0\n",
      "Epoch  9270 Loss  0.00026703966432251036\n",
      "Training accuracy is  1.0\n",
      "Epoch  9280 Loss  0.00026653322856873274\n",
      "Training accuracy is  1.0\n",
      "Epoch  9290 Loss  0.0002659969904925674\n",
      "Training accuracy is  1.0\n",
      "Epoch  9300 Loss  0.00026546072331257164\n",
      "Training accuracy is  1.0\n",
      "Epoch  9310 Loss  0.0002649543166626245\n",
      "Training accuracy is  1.0\n",
      "Epoch  9320 Loss  0.00026438827626407146\n",
      "Training accuracy is  1.0\n",
      "Epoch  9330 Loss  0.0002639116137288511\n",
      "Training accuracy is  1.0\n",
      "Epoch  9340 Loss  0.0002633455442264676\n",
      "Training accuracy is  1.0\n",
      "Epoch  9350 Loss  0.00026283910847269\n",
      "Training accuracy is  1.0\n",
      "Epoch  9360 Loss  0.00026233267271891236\n",
      "Training accuracy is  1.0\n",
      "Epoch  9370 Loss  0.00026179643464274704\n",
      "Training accuracy is  1.0\n",
      "Epoch  9380 Loss  0.00026131977210752666\n",
      "Training accuracy is  1.0\n",
      "Epoch  9390 Loss  0.00026081333635374904\n",
      "Training accuracy is  1.0\n",
      "Epoch  9400 Loss  0.00026024726685136557\n",
      "Training accuracy is  1.0\n",
      "Epoch  9410 Loss  0.00025977063341997564\n",
      "Training accuracy is  1.0\n",
      "Epoch  9420 Loss  0.00025923436623997986\n",
      "Training accuracy is  1.0\n",
      "Epoch  9430 Loss  0.0002587577037047595\n",
      "Training accuracy is  1.0\n",
      "Epoch  9440 Loss  0.00025825126795098186\n",
      "Training accuracy is  1.0\n",
      "Epoch  9450 Loss  0.0002577150007709861\n",
      "Training accuracy is  1.0\n",
      "Epoch  9460 Loss  0.0002572383382357657\n",
      "Training accuracy is  1.0\n",
      "Epoch  9470 Loss  0.0002567616757005453\n",
      "Training accuracy is  1.0\n",
      "Epoch  9480 Loss  0.0002561956353019923\n",
      "Training accuracy is  1.0\n",
      "Epoch  9490 Loss  0.00025574874598532915\n",
      "Training accuracy is  1.0\n",
      "Epoch  9500 Loss  0.00025524231023155153\n",
      "Training accuracy is  1.0\n",
      "Epoch  9510 Loss  0.00025473584537394345\n",
      "Training accuracy is  1.0\n",
      "Epoch  9520 Loss  0.00025425918283872306\n",
      "Training accuracy is  1.0\n",
      "Epoch  9530 Loss  0.0002537825203035027\n",
      "Training accuracy is  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9540 Loss  0.0002532760554458946\n",
      "Training accuracy is  1.0\n",
      "Epoch  9550 Loss  0.0002527993929106742\n",
      "Training accuracy is  1.0\n",
      "Epoch  9560 Loss  0.00025229292805306613\n",
      "Training accuracy is  1.0\n",
      "Epoch  9570 Loss  0.000251846038736403\n",
      "Training accuracy is  1.0\n",
      "Epoch  9580 Loss  0.0002513693762011826\n",
      "Training accuracy is  1.0\n",
      "Epoch  9590 Loss  0.000250862940447405\n",
      "Training accuracy is  1.0\n",
      "Epoch  9600 Loss  0.00025038624880835414\n",
      "Training accuracy is  1.0\n",
      "Epoch  9610 Loss  0.00024993938859552145\n",
      "Training accuracy is  1.0\n",
      "Epoch  9620 Loss  0.0002494031214155257\n",
      "Training accuracy is  1.0\n",
      "Epoch  9630 Loss  0.0002489264588803053\n",
      "Training accuracy is  1.0\n",
      "Epoch  9640 Loss  0.00024847956956364214\n",
      "Training accuracy is  1.0\n",
      "Epoch  9650 Loss  0.00024797310470603406\n",
      "Training accuracy is  1.0\n",
      "Epoch  9660 Loss  0.0002475262444932014\n",
      "Training accuracy is  1.0\n",
      "Epoch  9670 Loss  0.00024707935517653823\n",
      "Training accuracy is  1.0\n",
      "Epoch  9680 Loss  0.0002466324658598751\n",
      "Training accuracy is  1.0\n",
      "Epoch  9690 Loss  0.00024609622778370976\n",
      "Training accuracy is  1.0\n",
      "Epoch  9700 Loss  0.0002456493384670466\n",
      "Training accuracy is  1.0\n",
      "Epoch  9710 Loss  0.00024520244915038347\n",
      "Training accuracy is  1.0\n",
      "Epoch  9720 Loss  0.000244785362156108\n",
      "Training accuracy is  1.0\n",
      "Epoch  9730 Loss  0.00024427889729849994\n",
      "Training accuracy is  1.0\n",
      "Epoch  9740 Loss  0.00024383202253375202\n",
      "Training accuracy is  1.0\n",
      "Epoch  9750 Loss  0.0002433851477690041\n",
      "Training accuracy is  1.0\n",
      "Epoch  9760 Loss  0.0002429382730042562\n",
      "Training accuracy is  1.0\n",
      "Epoch  9770 Loss  0.00024246158136520535\n",
      "Training accuracy is  1.0\n",
      "Epoch  9780 Loss  0.00024201470660045743\n",
      "Training accuracy is  1.0\n",
      "Epoch  9790 Loss  0.0002415678318357095\n",
      "Training accuracy is  1.0\n",
      "Epoch  9800 Loss  0.00024112094251904637\n",
      "Training accuracy is  1.0\n",
      "Epoch  9810 Loss  0.00024064425087999552\n",
      "Training accuracy is  1.0\n",
      "Epoch  9820 Loss  0.0002401973761152476\n",
      "Training accuracy is  1.0\n",
      "Epoch  9830 Loss  0.00023975048679858446\n",
      "Training accuracy is  1.0\n",
      "Epoch  9840 Loss  0.000239333399804309\n",
      "Training accuracy is  1.0\n",
      "Epoch  9850 Loss  0.00023891631281003356\n",
      "Training accuracy is  1.0\n",
      "Epoch  9860 Loss  0.00023843962117098272\n",
      "Training accuracy is  1.0\n",
      "Epoch  9870 Loss  0.0002379927464062348\n",
      "Training accuracy is  1.0\n",
      "Epoch  9880 Loss  0.00023754585708957165\n",
      "Training accuracy is  1.0\n",
      "Epoch  9890 Loss  0.00023715855786576867\n",
      "Training accuracy is  1.0\n",
      "Epoch  9900 Loss  0.00023671166854910553\n",
      "Training accuracy is  1.0\n",
      "Epoch  9910 Loss  0.0002362349914619699\n",
      "Training accuracy is  1.0\n",
      "Epoch  9920 Loss  0.00023578810214530677\n",
      "Training accuracy is  1.0\n",
      "Epoch  9930 Loss  0.00023540080292150378\n",
      "Training accuracy is  1.0\n",
      "Epoch  9940 Loss  0.00023495391360484064\n",
      "Training accuracy is  1.0\n",
      "Epoch  9950 Loss  0.00023456659982912242\n",
      "Training accuracy is  1.0\n",
      "Epoch  9960 Loss  0.00023406012041959912\n",
      "Training accuracy is  1.0\n",
      "Epoch  9970 Loss  0.00023364303342532367\n",
      "Training accuracy is  1.0\n",
      "Epoch  9980 Loss  0.00023325573420152068\n",
      "Training accuracy is  1.0\n",
      "Epoch  9990 Loss  0.00023280884488485754\n",
      "Training accuracy is  1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,2)\n",
    "        self.fc2 = nn.Linear(2,2)\n",
    "        self.fc3 = nn.Linear(2,2)\n",
    "        self.fc4 = nn.Linear(2,2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "\n",
    "\n",
    "def plot_decision_boundary(clf, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    #x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    #y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    x_min, x_max = -0.5, 1.5\n",
    "    y_min, y_max = -0.5, 1.5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    X_out = net(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype = torch.float))\n",
    "    Z = X_out.data.max(1)[1]\n",
    "    # Z.shape\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "\n",
    "\n",
    "    \n",
    "# input values\n",
    "X = np.array([[0.,0.], [0.,1.], [1.,0.], [1.,1.]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "# read data         \n",
    "X = torch.tensor(X, dtype = torch.float)   \n",
    "y = torch.tensor(y, dtype = torch.long)    \n",
    "\n",
    "# train \n",
    "net = Net()\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# create a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "nepochs = 10000\n",
    "data, target = X, y\n",
    "\n",
    "# run the main training loop\n",
    "for epoch in range(nepochs):\n",
    "#    adjust learning rate if desired\n",
    "#    if epoch % 3000 == 0 and epoch <= 24000:\n",
    "#        for g in optimizer.param_groups:\n",
    "#            g['lr'] = g['lr']/2\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagate\n",
    "    net_out = net(data)\n",
    "    # compute loss\n",
    "    loss = criterion(net_out, target)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # print out report\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correctidx = pred.eq(target.data) \n",
    "        ncorrect = correctidx.sum()\n",
    "        accuracy = ncorrect.item()/len(data)\n",
    "        print('Training accuracy is ', accuracy)\n",
    "        \n",
    "plot_decision_boundary(net, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 (b)\tPlot the decision boundaries of the network as before, that is, right after the network achieves perfect accuracy and after the cross-entropy loss falls below 1x10-4. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decision boundaries of right after the network achieves perfect accuracy\n",
    "\n",
    "# run the main training loop\n",
    "for epoch in range(nepochs):\n",
    "#    adjust learning rate if desired\n",
    "#    if epoch % 3000 == 0 and epoch <= 24000:\n",
    "#        for g in optimizer.param_groups:\n",
    "#            g['lr'] = g['lr']/2\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagate\n",
    "    net_out = net(data)\n",
    "    # compute loss\n",
    "    loss = criterion(net_out, target)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # print out report\n",
    "    if epoch % 10 == 0:\n",
    "        #print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correctidx = pred.eq(target.data) \n",
    "        ncorrect = correctidx.sum()\n",
    "        accuracy = ncorrect.item()/len(data)\n",
    "        #print('Training accuracy is ', accuracy)\n",
    "    # if network achieves perfect accuracy, then break the loop\n",
    "    if accuracy == 1.0:\n",
    "        break\n",
    "    \n",
    "plot_decision_boundary(net, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decision boundaries of right after the cross-entropy loss falls below 1x10-4\n",
    "\n",
    "# run the main training loop\n",
    "for epoch in range(nepochs):\n",
    "#    adjust learning rate if desired\n",
    "#    if epoch % 3000 == 0 and epoch <= 24000:\n",
    "#        for g in optimizer.param_groups:\n",
    "#            g['lr'] = g['lr']/2\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagate\n",
    "    net_out = net(data)\n",
    "    # compute loss\n",
    "    loss = criterion(net_out, target)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # print out report\n",
    "    if epoch % 10 == 0:\n",
    "        #print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correctidx = pred.eq(target.data) \n",
    "        ncorrect = correctidx.sum()\n",
    "        accuracy = ncorrect.item()/len(data)\n",
    "        #print('Training accuracy is ', accuracy)\n",
    "    # if the cross entropy loss falls down below 10^(-4), break the for loop\n",
    "    if loss.item() < 0.0001:\n",
    "        break\n",
    "    \n",
    "plot_decision_boundary(net, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 (c)\tBased on the decision boundaries, which network(s) do you think is/are performing better at the task, beyond its performance on the training set? (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the decision boundaries, I think the smaller network is performing better at the task because it has a narrower decision boundaries so it is easier to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\tClassification of Separable, Synthetic data (30 + 10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 File Feedforward_Data_ellipse.csv contains 13312 two-dimensional data points (feature values located in columns A and B) and their respective binary label (labels located in column C).  Create and train a network that separates the data.  Report your best cross-entropy and accuracy values.  Plot the decision boundaries of your best network by plotting the network outputs in a densely sampled region around [-1.0,1.0] x [-1.0,1.0].  Report the number of hidden layers, type of activation function and number of neurons per layer used.  (15 points).\n",
    "\n",
    "Best cross entropy: 0.18\n",
    "\n",
    "Best accuracy value: 0.961\n",
    "\n",
    "Number of hidden layers: 6\n",
    "\n",
    "Type of activation function: Linear\n",
    "\n",
    "Number of neurons per layer used: 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jungmin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss  0.6933558583259583\n",
      "Training accuracy is  0.44346780857937046\n",
      "Epoch  10 Loss  0.6902031302452087\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  20 Loss  0.6873288154602051\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  30 Loss  0.6866788268089294\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  40 Loss  0.6867349743843079\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  50 Loss  0.6867116689682007\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  60 Loss  0.6866965889930725\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  70 Loss  0.6866545677185059\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  80 Loss  0.6866300106048584\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  90 Loss  0.6866495013237\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  100 Loss  0.6866247057914734\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  110 Loss  0.6866018176078796\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  120 Loss  0.6866041421890259\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  130 Loss  0.6866183280944824\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  140 Loss  0.6866133809089661\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  150 Loss  0.6865991353988647\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  160 Loss  0.6865869164466858\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  170 Loss  0.6865781545639038\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  180 Loss  0.686566948890686\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  190 Loss  0.6865562200546265\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  200 Loss  0.686546266078949\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  210 Loss  0.686538815498352\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  220 Loss  0.6865241527557373\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  230 Loss  0.6865100860595703\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  240 Loss  0.6864992380142212\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  250 Loss  0.686488151550293\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  260 Loss  0.686473548412323\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  270 Loss  0.6864578723907471\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  280 Loss  0.6864442825317383\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  290 Loss  0.6864357590675354\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  300 Loss  0.6864267587661743\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  310 Loss  0.6864169239997864\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  320 Loss  0.6864070296287537\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  330 Loss  0.6863969564437866\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  340 Loss  0.6863886117935181\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  350 Loss  0.6863796710968018\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  360 Loss  0.686370849609375\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  370 Loss  0.6863609552383423\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  380 Loss  0.6863503456115723\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  390 Loss  0.6863395571708679\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  400 Loss  0.6863232254981995\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  410 Loss  0.6863080859184265\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  420 Loss  0.6862943172454834\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  430 Loss  0.6862748265266418\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  440 Loss  0.686251699924469\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  450 Loss  0.6862301230430603\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  460 Loss  0.686211347579956\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  470 Loss  0.6861928105354309\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  480 Loss  0.6861734986305237\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  490 Loss  0.6861526966094971\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  500 Loss  0.6861306428909302\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  510 Loss  0.6861090660095215\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  520 Loss  0.686089038848877\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  530 Loss  0.6860716342926025\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  540 Loss  0.6860480308532715\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  550 Loss  0.6860209107398987\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  560 Loss  0.6859897971153259\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  570 Loss  0.6859580874443054\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  580 Loss  0.6859233975410461\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  590 Loss  0.6858929991722107\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  600 Loss  0.6858574748039246\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  610 Loss  0.6858194470405579\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  620 Loss  0.6857827305793762\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  630 Loss  0.6857463717460632\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  640 Loss  0.68570476770401\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  650 Loss  0.6856551170349121\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  660 Loss  0.685604453086853\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  670 Loss  0.6855556964874268\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  680 Loss  0.6855030059814453\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  690 Loss  0.6854448318481445\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  700 Loss  0.6853777170181274\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  710 Loss  0.6853107810020447\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  720 Loss  0.6852412223815918\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  730 Loss  0.6851658821105957\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  740 Loss  0.6850783824920654\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  750 Loss  0.6849835515022278\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  760 Loss  0.684887707233429\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  770 Loss  0.6847882270812988\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  780 Loss  0.6846672296524048\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  790 Loss  0.6845442652702332\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  800 Loss  0.6844040751457214\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  810 Loss  0.6842523217201233\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  820 Loss  0.6840856075286865\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  830 Loss  0.6838985085487366\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  840 Loss  0.6836942434310913\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  850 Loss  0.6834658980369568\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  860 Loss  0.6832112073898315\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  870 Loss  0.6829238533973694\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  880 Loss  0.6825973987579346\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  890 Loss  0.682231605052948\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  900 Loss  0.6818121075630188\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  910 Loss  0.6813327670097351\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  920 Loss  0.6807747483253479\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  930 Loss  0.6801193356513977\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  940 Loss  0.6793503165245056\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  950 Loss  0.6784278750419617\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  960 Loss  0.6773053407669067\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  970 Loss  0.675929069519043\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  980 Loss  0.6742057204246521\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  990 Loss  0.672003984451294\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  1000 Loss  0.6691532731056213\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  1010 Loss  0.6653648018836975\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  1020 Loss  0.6601971983909607\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  1030 Loss  0.6529924273490906\n",
      "Training accuracy is  0.5565321914206296\n",
      "Epoch  1040 Loss  0.6427379846572876\n",
      "Training accuracy is  0.6052888588385545\n",
      "Epoch  1050 Loss  0.6275655627250671\n",
      "Training accuracy is  0.6837202313875742\n",
      "Epoch  1060 Loss  0.6043020486831665\n",
      "Training accuracy is  0.7597475771917963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1070 Loss  0.5684403777122498\n",
      "Training accuracy is  0.8106077680114191\n",
      "Epoch  1080 Loss  0.5161065459251404\n",
      "Training accuracy is  0.835173916309819\n",
      "Epoch  1090 Loss  0.44955047965049744\n",
      "Training accuracy is  0.8455412816467583\n",
      "Epoch  1100 Loss  0.3752749264240265\n",
      "Training accuracy is  0.852678236045376\n",
      "Epoch  1110 Loss  0.3087443709373474\n",
      "Training accuracy is  0.86342123056119\n",
      "Epoch  1120 Loss  0.25949418544769287\n",
      "Training accuracy is  0.8975283600030051\n",
      "Epoch  1130 Loss  0.23159444332122803\n",
      "Training accuracy is  0.896551724137931\n",
      "Epoch  1140 Loss  0.21766141057014465\n",
      "Training accuracy is  0.8971527308241304\n",
      "Epoch  1150 Loss  0.2100059986114502\n",
      "Training accuracy is  0.8975283600030051\n",
      "Epoch  1160 Loss  0.20566041767597198\n",
      "Training accuracy is  0.8979039891818796\n",
      "Epoch  1170 Loss  0.20287999510765076\n",
      "Training accuracy is  0.8982044925249794\n",
      "Epoch  1180 Loss  0.2009539008140564\n",
      "Training accuracy is  0.8982044925249794\n",
      "Epoch  1190 Loss  0.199529230594635\n",
      "Training accuracy is  0.8983547441965292\n",
      "Epoch  1200 Loss  0.19844651222229004\n",
      "Training accuracy is  0.8984298700323041\n",
      "Epoch  1210 Loss  0.19758804142475128\n",
      "Training accuracy is  0.8984298700323041\n",
      "Epoch  1220 Loss  0.196880042552948\n",
      "Training accuracy is  0.8984298700323041\n",
      "Epoch  1230 Loss  0.1962830275297165\n",
      "Training accuracy is  0.8984298700323041\n",
      "Epoch  1240 Loss  0.19576822221279144\n",
      "Training accuracy is  0.8985049958680791\n",
      "Epoch  1250 Loss  0.19531677663326263\n",
      "Training accuracy is  0.8986552475396289\n",
      "Epoch  1260 Loss  0.1949133574962616\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  1270 Loss  0.1945488303899765\n",
      "Training accuracy is  0.8988806250469537\n",
      "Epoch  1280 Loss  0.19421470165252686\n",
      "Training accuracy is  0.8989557508827286\n",
      "Epoch  1290 Loss  0.19479650259017944\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  1300 Loss  0.19791138172149658\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  1310 Loss  0.19526466727256775\n",
      "Training accuracy is  0.8991060025542784\n",
      "Epoch  1320 Loss  0.19420543313026428\n",
      "Training accuracy is  0.8990308767185035\n",
      "Epoch  1330 Loss  0.19402100145816803\n",
      "Training accuracy is  0.8990308767185035\n",
      "Epoch  1340 Loss  0.19605451822280884\n",
      "Training accuracy is  0.8982044925249794\n",
      "Epoch  1350 Loss  0.20276996493339539\n",
      "Training accuracy is  0.8978288633461047\n",
      "Epoch  1360 Loss  0.19375893473625183\n",
      "Training accuracy is  0.8989557508827286\n",
      "Epoch  1370 Loss  0.19386225938796997\n",
      "Training accuracy is  0.899556757568928\n",
      "Epoch  1380 Loss  0.22380495071411133\n",
      "Training accuracy is  0.8930208098565097\n",
      "Epoch  1390 Loss  0.1934327632188797\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  1400 Loss  0.19451995193958282\n",
      "Training accuracy is  0.8984298700323041\n",
      "Epoch  1410 Loss  0.2057999223470688\n",
      "Training accuracy is  0.8978288633461047\n",
      "Epoch  1420 Loss  0.19320820271968842\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  1430 Loss  0.19635966420173645\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  1440 Loss  0.20485076308250427\n",
      "Training accuracy is  0.9035384268649989\n",
      "Epoch  1450 Loss  0.193240225315094\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  1460 Loss  0.1937664896249771\n",
      "Training accuracy is  0.8986552475396289\n",
      "Epoch  1470 Loss  0.20939680933952332\n",
      "Training accuracy is  0.8976034858387799\n",
      "Epoch  1480 Loss  0.1928679347038269\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  1490 Loss  0.1954076588153839\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  1500 Loss  0.20129580795764923\n",
      "Training accuracy is  0.9039140560438735\n",
      "Epoch  1510 Loss  0.19673359394073486\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  1520 Loss  0.19337333738803864\n",
      "Training accuracy is  0.8987303733754038\n",
      "Epoch  1530 Loss  0.19806167483329773\n",
      "Training accuracy is  0.8981293666892044\n",
      "Epoch  1540 Loss  0.1983288675546646\n",
      "Training accuracy is  0.8984298700323041\n",
      "Epoch  1550 Loss  0.19384709000587463\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  1560 Loss  0.19457462430000305\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  1570 Loss  0.20260579884052277\n",
      "Training accuracy is  0.9051911952520472\n",
      "Epoch  1580 Loss  0.19404128193855286\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  1590 Loss  0.1945929229259491\n",
      "Training accuracy is  0.8985049958680791\n",
      "Epoch  1600 Loss  0.19302578270435333\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  1610 Loss  0.20409314334392548\n",
      "Training accuracy is  0.8976786116745549\n",
      "Epoch  1620 Loss  0.19253568351268768\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  1630 Loss  0.19459030032157898\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  1640 Loss  0.19414158165454865\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  1650 Loss  0.20748169720172882\n",
      "Training accuracy is  0.9060927052813462\n",
      "Epoch  1660 Loss  0.19220466911792755\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  1670 Loss  0.19411629438400269\n",
      "Training accuracy is  0.8985049958680791\n",
      "Epoch  1680 Loss  0.19629058241844177\n",
      "Training accuracy is  0.8985049958680791\n",
      "Epoch  1690 Loss  0.20044778287410736\n",
      "Training accuracy is  0.8981293666892044\n",
      "Epoch  1700 Loss  0.19223923981189728\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  1710 Loss  0.19380946457386017\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  1720 Loss  0.19708660244941711\n",
      "Training accuracy is  0.9012846517917512\n",
      "Epoch  1730 Loss  0.19632300734519958\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  1740 Loss  0.1940539926290512\n",
      "Training accuracy is  0.8986552475396289\n",
      "Epoch  1750 Loss  0.19158515334129333\n",
      "Training accuracy is  0.899481631733153\n",
      "Epoch  1760 Loss  0.19550450146198273\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  1770 Loss  0.19621047377586365\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  1780 Loss  0.19316068291664124\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  1790 Loss  0.1931789368391037\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  1800 Loss  0.19729897379875183\n",
      "Training accuracy is  0.8983547441965292\n",
      "Epoch  1810 Loss  0.19619794189929962\n",
      "Training accuracy is  0.8986552475396289\n",
      "Epoch  1820 Loss  0.19147975742816925\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  1830 Loss  0.197006493806839\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  1840 Loss  0.19837185740470886\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  1850 Loss  0.1925886571407318\n",
      "Training accuracy is  0.8988806250469537\n",
      "Epoch  1860 Loss  0.19286313652992249\n",
      "Training accuracy is  0.8988806250469537\n",
      "Epoch  1870 Loss  0.19738119840621948\n",
      "Training accuracy is  0.8983547441965292\n",
      "Epoch  1880 Loss  0.19495633244514465\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  1890 Loss  0.19294925034046173\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  1900 Loss  0.1928309053182602\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  1910 Loss  0.2009890079498291\n",
      "Training accuracy is  0.908271354518819\n",
      "Epoch  1920 Loss  0.19274212419986725\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  1930 Loss  0.1933457851409912\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  1940 Loss  0.19136056303977966\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  1950 Loss  0.19780926406383514\n",
      "Training accuracy is  0.8982044925249794\n",
      "Epoch  1960 Loss  0.19239290058612823\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  1970 Loss  0.19386179745197296\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  1980 Loss  0.19126036763191223\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  1990 Loss  0.1956566870212555\n",
      "Training accuracy is  0.9013597776275261\n",
      "Epoch  2000 Loss  0.19545035064220428\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  2010 Loss  0.1921735554933548\n",
      "Training accuracy is  0.8988806250469537\n",
      "Epoch  2020 Loss  0.19322527945041656\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  2030 Loss  0.1963503062725067\n",
      "Training accuracy is  0.8985049958680791\n",
      "Epoch  2040 Loss  0.19476009905338287\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  2050 Loss  0.19196754693984985\n",
      "Training accuracy is  0.8991060025542784\n",
      "Epoch  2060 Loss  0.19884589314460754\n",
      "Training accuracy is  0.8982044925249794\n",
      "Epoch  2070 Loss  0.1912660300731659\n",
      "Training accuracy is  0.899556757568928\n",
      "Epoch  2080 Loss  0.19194993376731873\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  2090 Loss  0.1907651424407959\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  2100 Loss  0.20589444041252136\n",
      "Training accuracy is  0.8979039891818796\n",
      "Epoch  2110 Loss  0.1904599666595459\n",
      "Training accuracy is  0.8998572609120277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2120 Loss  0.19177991151809692\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  2130 Loss  0.19034317135810852\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  2140 Loss  0.19590447843074799\n",
      "Training accuracy is  0.8985049958680791\n",
      "Epoch  2150 Loss  0.19172386825084686\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  2160 Loss  0.19214412569999695\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  2170 Loss  0.19294129312038422\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  2180 Loss  0.19808483123779297\n",
      "Training accuracy is  0.9018105326421757\n",
      "Epoch  2190 Loss  0.19394713640213013\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  2200 Loss  0.1901586949825287\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  2210 Loss  0.19265152513980865\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  2220 Loss  0.19563093781471252\n",
      "Training accuracy is  0.8988806250469537\n",
      "Epoch  2230 Loss  0.19223983585834503\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  2240 Loss  0.19102223217487335\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  2250 Loss  0.19315524399280548\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  2260 Loss  0.19968834519386292\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  2270 Loss  0.1901714950799942\n",
      "Training accuracy is  0.899481631733153\n",
      "Epoch  2280 Loss  0.19353631138801575\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  2290 Loss  0.195619136095047\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  2300 Loss  0.19312939047813416\n",
      "Training accuracy is  0.8988806250469537\n",
      "Epoch  2310 Loss  0.19111406803131104\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  2320 Loss  0.20599308609962463\n",
      "Training accuracy is  0.8981293666892044\n",
      "Epoch  2330 Loss  0.18998782336711884\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  2340 Loss  0.1899917870759964\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  2350 Loss  0.19084811210632324\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  2360 Loss  0.206298366189003\n",
      "Training accuracy is  0.8985049958680791\n",
      "Epoch  2370 Loss  0.19013841450214386\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  2380 Loss  0.19061271846294403\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  2390 Loss  0.19020460546016693\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  2400 Loss  0.22447119653224945\n",
      "Training accuracy is  0.9045901885658478\n",
      "Epoch  2410 Loss  0.18987485766410828\n",
      "Training accuracy is  0.899556757568928\n",
      "Epoch  2420 Loss  0.19156132638454437\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  2430 Loss  0.19153359532356262\n",
      "Training accuracy is  0.8991060025542784\n",
      "Epoch  2440 Loss  0.20311546325683594\n",
      "Training accuracy is  0.8985049958680791\n",
      "Epoch  2450 Loss  0.1899559199810028\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  2460 Loss  0.19125090539455414\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  2470 Loss  0.1915380209684372\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  2480 Loss  0.20742906630039215\n",
      "Training accuracy is  0.9107505070993914\n",
      "Epoch  2490 Loss  0.18998102843761444\n",
      "Training accuracy is  0.8994065058973781\n",
      "Epoch  2500 Loss  0.19146449863910675\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  2510 Loss  0.192655548453331\n",
      "Training accuracy is  0.8988806250469537\n",
      "Epoch  2520 Loss  0.19931305944919586\n",
      "Training accuracy is  0.8985801217038539\n",
      "Epoch  2530 Loss  0.18945518136024475\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  2540 Loss  0.19262582063674927\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  2550 Loss  0.19594451785087585\n",
      "Training accuracy is  0.9013597776275261\n",
      "Epoch  2560 Loss  0.19591520726680756\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  2570 Loss  0.19164136052131653\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  2580 Loss  0.1894400417804718\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  2590 Loss  0.18917974829673767\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  2600 Loss  0.20725473761558533\n",
      "Training accuracy is  0.8979039891818796\n",
      "Epoch  2610 Loss  0.19055920839309692\n",
      "Training accuracy is  0.899481631733153\n",
      "Epoch  2620 Loss  0.18939276039600372\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  2630 Loss  0.1894422471523285\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  2640 Loss  0.20673729479312897\n",
      "Training accuracy is  0.8982044925249794\n",
      "Epoch  2650 Loss  0.18934307992458344\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  2660 Loss  0.1896783709526062\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  2670 Loss  0.20264074206352234\n",
      "Training accuracy is  0.9117271429644654\n",
      "Epoch  2680 Loss  0.19148887693881989\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  2690 Loss  0.19311858713626862\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  2700 Loss  0.19682596623897552\n",
      "Training accuracy is  0.9028622943430246\n",
      "Epoch  2710 Loss  0.19241870939731598\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  2720 Loss  0.191002756357193\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  2730 Loss  0.1899607628583908\n",
      "Training accuracy is  0.899556757568928\n",
      "Epoch  2740 Loss  0.20022977888584137\n",
      "Training accuracy is  0.8984298700323041\n",
      "Epoch  2750 Loss  0.1892482042312622\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  2760 Loss  0.1907033771276474\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  2770 Loss  0.18896318972110748\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  2780 Loss  0.193498894572258\n",
      "Training accuracy is  0.9031627976861243\n",
      "Epoch  2790 Loss  0.1915593445301056\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  2800 Loss  0.18889056146144867\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  2810 Loss  0.1912618726491928\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  2820 Loss  0.19911454617977142\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  2830 Loss  0.1891815960407257\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  2840 Loss  0.19238661229610443\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  2850 Loss  0.1939699500799179\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  2860 Loss  0.20046931505203247\n",
      "Training accuracy is  0.906318082788671\n",
      "Epoch  2870 Loss  0.18874017894268036\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  2880 Loss  0.19046616554260254\n",
      "Training accuracy is  0.8994065058973781\n",
      "Epoch  2890 Loss  0.18993709981441498\n",
      "Training accuracy is  0.8994065058973781\n",
      "Epoch  2900 Loss  0.20311029255390167\n",
      "Training accuracy is  0.8987303733754038\n",
      "Epoch  2910 Loss  0.18921373784542084\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  2920 Loss  0.18969057500362396\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  2930 Loss  0.19060118496418\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  2940 Loss  0.20066095888614655\n",
      "Training accuracy is  0.9018856584779505\n",
      "Epoch  2950 Loss  0.18908967077732086\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  2960 Loss  0.19080057740211487\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  2970 Loss  0.19298484921455383\n",
      "Training accuracy is  0.8991060025542784\n",
      "Epoch  2980 Loss  0.19553646445274353\n",
      "Training accuracy is  0.8991060025542784\n",
      "Epoch  2990 Loss  0.19055089354515076\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  3000 Loss  0.18890996277332306\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  3010 Loss  0.1896272599697113\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  3020 Loss  0.20250572264194489\n",
      "Training accuracy is  0.9030125460145744\n",
      "Epoch  3030 Loss  0.18891304731369019\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  3040 Loss  0.19188007712364197\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  3050 Loss  0.19264300167560577\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  3060 Loss  0.19526827335357666\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  3070 Loss  0.18978357315063477\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  3080 Loss  0.18945224583148956\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  3090 Loss  0.20586645603179932\n",
      "Training accuracy is  0.9107505070993914\n",
      "Epoch  3100 Loss  0.18856269121170044\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  3110 Loss  0.18988794088363647\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  3120 Loss  0.18844833970069885\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  3130 Loss  0.2000015676021576\n",
      "Training accuracy is  0.8985049958680791\n",
      "Epoch  3140 Loss  0.18825602531433105\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  3150 Loss  0.19175995886325836\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  3160 Loss  0.18933714926242828\n",
      "Training accuracy is  0.900458267598227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3170 Loss  0.2048490047454834\n",
      "Training accuracy is  0.9165351964540606\n",
      "Epoch  3180 Loss  0.1884663701057434\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  3190 Loss  0.1902172714471817\n",
      "Training accuracy is  0.899481631733153\n",
      "Epoch  3200 Loss  0.18893122673034668\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  3210 Loss  0.20428979396820068\n",
      "Training accuracy is  0.8985049958680791\n",
      "Epoch  3220 Loss  0.18806497752666473\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  3230 Loss  0.18952961266040802\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  3240 Loss  0.18800216913223267\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  3250 Loss  0.1936427354812622\n",
      "Training accuracy is  0.9134550371872887\n",
      "Epoch  3260 Loss  0.18832124769687653\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  3270 Loss  0.19084323942661285\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  3280 Loss  0.19445274770259857\n",
      "Training accuracy is  0.8991060025542784\n",
      "Epoch  3290 Loss  0.18809683620929718\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  3300 Loss  0.18802866339683533\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  3310 Loss  0.20881111919879913\n",
      "Training accuracy is  0.8985801217038539\n",
      "Epoch  3320 Loss  0.18825294077396393\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  3330 Loss  0.18796654045581818\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  3340 Loss  0.19724918901920319\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  3350 Loss  0.189273864030838\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  3360 Loss  0.18789896368980408\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  3370 Loss  0.19313551485538483\n",
      "Training accuracy is  0.8991060025542784\n",
      "Epoch  3380 Loss  0.19081053137779236\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  3390 Loss  0.18773062527179718\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  3400 Loss  0.19171838462352753\n",
      "Training accuracy is  0.9012846517917512\n",
      "Epoch  3410 Loss  0.1935146152973175\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  3420 Loss  0.18767186999320984\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  3430 Loss  0.19029448926448822\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  3440 Loss  0.19497117400169373\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  3450 Loss  0.18764172494411469\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  3460 Loss  0.19238685071468353\n",
      "Training accuracy is  0.9012846517917512\n",
      "Epoch  3470 Loss  0.1949484646320343\n",
      "Training accuracy is  0.9012095259559763\n",
      "Epoch  3480 Loss  0.1881408840417862\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  3490 Loss  0.19373531639575958\n",
      "Training accuracy is  0.9027120426714748\n",
      "Epoch  3500 Loss  0.19291968643665314\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  3510 Loss  0.18935976922512054\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  3520 Loss  0.1897190362215042\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  3530 Loss  0.19360454380512238\n",
      "Training accuracy is  0.8991060025542784\n",
      "Epoch  3540 Loss  0.1924319714307785\n",
      "Training accuracy is  0.8994065058973781\n",
      "Epoch  3550 Loss  0.1896047741174698\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  3560 Loss  0.18885236978530884\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  3570 Loss  0.1972324699163437\n",
      "Training accuracy is  0.9178874614980091\n",
      "Epoch  3580 Loss  0.18847224116325378\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  3590 Loss  0.18991440534591675\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  3600 Loss  0.18766412138938904\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  3610 Loss  0.19637544453144073\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  3620 Loss  0.18807345628738403\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  3630 Loss  0.18928396701812744\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  3640 Loss  0.1929665356874466\n",
      "Training accuracy is  0.9012846517917512\n",
      "Epoch  3650 Loss  0.19756878912448883\n",
      "Training accuracy is  0.9060927052813462\n",
      "Epoch  3660 Loss  0.18760710954666138\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  3670 Loss  0.18942078948020935\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  3680 Loss  0.20322224497795105\n",
      "Training accuracy is  0.8986552475396289\n",
      "Epoch  3690 Loss  0.18730297684669495\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  3700 Loss  0.18836276233196259\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  3710 Loss  0.18731486797332764\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  3720 Loss  0.2198060303926468\n",
      "Training accuracy is  0.8176695965742619\n",
      "Epoch  3730 Loss  0.18735426664352417\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  3740 Loss  0.18954813480377197\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  3750 Loss  0.1872299313545227\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  3760 Loss  0.19362646341323853\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  3770 Loss  0.1900767683982849\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  3780 Loss  0.1873112916946411\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  3790 Loss  0.18698401749134064\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  3800 Loss  0.1894153207540512\n",
      "Training accuracy is  0.8994065058973781\n",
      "Epoch  3810 Loss  0.18816077709197998\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  3820 Loss  0.1901523619890213\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  3830 Loss  0.18857331573963165\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  3840 Loss  0.18714462220668793\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  3850 Loss  0.1881747990846634\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  3860 Loss  0.21360935270786285\n",
      "Training accuracy is  0.9314852377732702\n",
      "Epoch  3870 Loss  0.1873835176229477\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  3880 Loss  0.18764975666999817\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  3890 Loss  0.18731185793876648\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  3900 Loss  0.1981249749660492\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  3910 Loss  0.19118215143680573\n",
      "Training accuracy is  0.8994065058973781\n",
      "Epoch  3920 Loss  0.1872178316116333\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  3930 Loss  0.18701699376106262\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  3940 Loss  0.21664586663246155\n",
      "Training accuracy is  0.9177372098264593\n",
      "Epoch  3950 Loss  0.1889897733926773\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  3960 Loss  0.1914346069097519\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  3970 Loss  0.19088922441005707\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  3980 Loss  0.19336509704589844\n",
      "Training accuracy is  0.9012846517917512\n",
      "Epoch  3990 Loss  0.18863317370414734\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  4000 Loss  0.19694212079048157\n",
      "Training accuracy is  0.9216437532867553\n",
      "Epoch  4010 Loss  0.1873047798871994\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  4020 Loss  0.1879536658525467\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  4030 Loss  0.18717582523822784\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  4040 Loss  0.22198550403118134\n",
      "Training accuracy is  0.8514010968372023\n",
      "Epoch  4050 Loss  0.18734465539455414\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  4060 Loss  0.1869993507862091\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  4070 Loss  0.19479602575302124\n",
      "Training accuracy is  0.8991060025542784\n",
      "Epoch  4080 Loss  0.18879474699497223\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  4090 Loss  0.18735237419605255\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  4100 Loss  0.19592943787574768\n",
      "Training accuracy is  0.9080459770114943\n",
      "Epoch  4110 Loss  0.19269591569900513\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  4120 Loss  0.18734514713287354\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  4130 Loss  0.19017758965492249\n",
      "Training accuracy is  0.8996318834047029\n",
      "Epoch  4140 Loss  0.19604556262493134\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  4150 Loss  0.18787911534309387\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  4160 Loss  0.18686217069625854\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  4170 Loss  0.18637362122535706\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  4180 Loss  0.23280155658721924\n",
      "Training accuracy is  0.8046728269852003\n",
      "Epoch  4190 Loss  0.18934568762779236\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  4200 Loss  0.18703018128871918\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  4210 Loss  0.18631918728351593\n",
      "Training accuracy is  0.9002328900909022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4220 Loss  0.19681315124034882\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  4230 Loss  0.1963769942522049\n",
      "Training accuracy is  0.9235218991811284\n",
      "Epoch  4240 Loss  0.19158144295215607\n",
      "Training accuracy is  0.899481631733153\n",
      "Epoch  4250 Loss  0.18813572824001312\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  4260 Loss  0.18792875111103058\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  4270 Loss  0.19755631685256958\n",
      "Training accuracy is  0.8988054992111787\n",
      "Epoch  4280 Loss  0.18674905598163605\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  4290 Loss  0.18846271932125092\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  4300 Loss  0.18916934728622437\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  4310 Loss  0.19684860110282898\n",
      "Training accuracy is  0.901510029299076\n",
      "Epoch  4320 Loss  0.18678052723407745\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4330 Loss  0.1888074427843094\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  4340 Loss  0.1982736438512802\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  4350 Loss  0.18617646396160126\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  4360 Loss  0.1890985369682312\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  4370 Loss  0.20626211166381836\n",
      "Training accuracy is  0.9235218991811284\n",
      "Epoch  4380 Loss  0.18656429648399353\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4390 Loss  0.1870284080505371\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4400 Loss  0.18591700494289398\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  4410 Loss  0.25605979561805725\n",
      "Training accuracy is  0.9282548268349485\n",
      "Epoch  4420 Loss  0.19392050802707672\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4430 Loss  0.18981584906578064\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  4440 Loss  0.18690694868564606\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4450 Loss  0.18681539595127106\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  4460 Loss  0.19638299942016602\n",
      "Training accuracy is  0.9206671174216813\n",
      "Epoch  4470 Loss  0.18776659667491913\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  4480 Loss  0.18671827018260956\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4490 Loss  0.1984087973833084\n",
      "Training accuracy is  0.8991060025542784\n",
      "Epoch  4500 Loss  0.18597030639648438\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  4510 Loss  0.18798519670963287\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  4520 Loss  0.20413348078727722\n",
      "Training accuracy is  0.9377206821425889\n",
      "Epoch  4530 Loss  0.1861146092414856\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4540 Loss  0.18608824908733368\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  4550 Loss  0.18867510557174683\n",
      "Training accuracy is  0.9012846517917512\n",
      "Epoch  4560 Loss  0.1984456330537796\n",
      "Training accuracy is  0.903388175193449\n",
      "Epoch  4570 Loss  0.18876320123672485\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  4580 Loss  0.18591190874576569\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  4590 Loss  0.1856396198272705\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  4600 Loss  0.22303563356399536\n",
      "Training accuracy is  0.8032454361054767\n",
      "Epoch  4610 Loss  0.3605521023273468\n",
      "Training accuracy is  0.8982044925249794\n",
      "Epoch  4620 Loss  0.2539123594760895\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  4630 Loss  0.20635101199150085\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  4640 Loss  0.19546648859977722\n",
      "Training accuracy is  0.8996318834047029\n",
      "Epoch  4650 Loss  0.1940806657075882\n",
      "Training accuracy is  0.8987303733754038\n",
      "Epoch  4660 Loss  0.1937984824180603\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  4670 Loss  0.192729651927948\n",
      "Training accuracy is  0.899481631733153\n",
      "Epoch  4680 Loss  0.19232921302318573\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  4690 Loss  0.19187551736831665\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  4700 Loss  0.19149532914161682\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  4710 Loss  0.19118507206439972\n",
      "Training accuracy is  0.8994065058973781\n",
      "Epoch  4720 Loss  0.19090920686721802\n",
      "Training accuracy is  0.8994065058973781\n",
      "Epoch  4730 Loss  0.1906198263168335\n",
      "Training accuracy is  0.8996318834047029\n",
      "Epoch  4740 Loss  0.1903342753648758\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  4750 Loss  0.19009387493133545\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  4760 Loss  0.18986393511295319\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  4770 Loss  0.18964381515979767\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  4780 Loss  0.18944019079208374\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  4790 Loss  0.18924877047538757\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  4800 Loss  0.1890294998884201\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  4810 Loss  0.18882189691066742\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  4820 Loss  0.1886296421289444\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  4830 Loss  0.1884196549654007\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  4840 Loss  0.18823817372322083\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4850 Loss  0.18805909156799316\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4860 Loss  0.18788579106330872\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4870 Loss  0.18771107494831085\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4880 Loss  0.18753117322921753\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4890 Loss  0.1873350441455841\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  4900 Loss  0.187056764960289\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  4910 Loss  0.1868484765291214\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  4920 Loss  0.18666356801986694\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  4930 Loss  0.18649625778198242\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  4940 Loss  0.18632331490516663\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  4950 Loss  0.18614915013313293\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  4960 Loss  0.18597646057605743\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  4970 Loss  0.18580295145511627\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  4980 Loss  0.1856265664100647\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  4990 Loss  0.18779411911964417\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  5000 Loss  0.18922676146030426\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  5010 Loss  0.191686749458313\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  5020 Loss  0.18585780262947083\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  5030 Loss  0.19741806387901306\n",
      "Training accuracy is  0.9182630906768838\n",
      "Epoch  5040 Loss  0.18865135312080383\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  5050 Loss  0.19147369265556335\n",
      "Training accuracy is  0.9016602809706258\n",
      "Epoch  5060 Loss  0.19002607464790344\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  5070 Loss  0.18971797823905945\n",
      "Training accuracy is  0.9012095259559763\n",
      "Epoch  5080 Loss  0.19240203499794006\n",
      "Training accuracy is  0.9018105326421757\n",
      "Epoch  5090 Loss  0.18798372149467468\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  5100 Loss  0.19324035942554474\n",
      "Training accuracy is  0.9043648110585231\n",
      "Epoch  5110 Loss  0.1891147345304489\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  5120 Loss  0.1876661330461502\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  5130 Loss  0.19637128710746765\n",
      "Training accuracy is  0.9076703478326197\n",
      "Epoch  5140 Loss  0.18751849234104156\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  5150 Loss  0.1921016275882721\n",
      "Training accuracy is  0.9036886785365488\n",
      "Epoch  5160 Loss  0.18973785638809204\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  5170 Loss  0.188480406999588\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  5180 Loss  0.19384527206420898\n",
      "Training accuracy is  0.9034633010292239\n",
      "Epoch  5190 Loss  0.18774978816509247\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  5200 Loss  0.1921854466199875\n",
      "Training accuracy is  0.9042896852227481\n",
      "Epoch  5210 Loss  0.1902967244386673\n",
      "Training accuracy is  0.9021110359852753\n",
      "Epoch  5220 Loss  0.18632860481739044\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  5230 Loss  0.19715651869773865\n",
      "Training accuracy is  0.9163098189467358\n",
      "Epoch  5240 Loss  0.18812501430511475\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  5250 Loss  0.19013285636901855\n",
      "Training accuracy is  0.9185635940199834\n",
      "Epoch  5260 Loss  0.1897803097963333\n",
      "Training accuracy is  0.9110510104424911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5270 Loss  0.1898081749677658\n",
      "Training accuracy is  0.9197656073923822\n",
      "Epoch  5280 Loss  0.18877677619457245\n",
      "Training accuracy is  0.9096987453985426\n",
      "Epoch  5290 Loss  0.18889570236206055\n",
      "Training accuracy is  0.9122530238148899\n",
      "Epoch  5300 Loss  0.18971070647239685\n",
      "Training accuracy is  0.9051911952520472\n",
      "Epoch  5310 Loss  0.18973493576049805\n",
      "Training accuracy is  0.909323116219668\n",
      "Epoch  5320 Loss  0.19100192189216614\n",
      "Training accuracy is  0.9098489970700924\n",
      "Epoch  5330 Loss  0.1907278299331665\n",
      "Training accuracy is  0.9199158590639321\n",
      "Epoch  5340 Loss  0.1898963302373886\n",
      "Training accuracy is  0.9197656073923822\n",
      "Epoch  5350 Loss  0.18893329799175262\n",
      "Training accuracy is  0.9106753812636166\n",
      "Epoch  5360 Loss  0.18695540726184845\n",
      "Training accuracy is  0.9034633010292239\n",
      "Epoch  5370 Loss  0.18638859689235687\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  5380 Loss  0.19143559038639069\n",
      "Training accuracy is  0.9046653144016227\n",
      "Epoch  5390 Loss  0.19037620723247528\n",
      "Training accuracy is  0.9013597776275261\n",
      "Epoch  5400 Loss  0.18870282173156738\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  5410 Loss  0.1981906145811081\n",
      "Training accuracy is  0.9275786943129742\n",
      "Epoch  5420 Loss  0.18487772345542908\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  5430 Loss  0.18537382781505585\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  5440 Loss  0.20173053443431854\n",
      "Training accuracy is  0.8989557508827286\n",
      "Epoch  5450 Loss  0.19148662686347961\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  5460 Loss  0.19998294115066528\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  5470 Loss  0.19294291734695435\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  5480 Loss  0.18542510271072388\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  5490 Loss  0.18550081551074982\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  5500 Loss  0.18513795733451843\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  5510 Loss  0.18506598472595215\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  5520 Loss  0.2017061561346054\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  5530 Loss  0.19164609909057617\n",
      "Training accuracy is  0.8996318834047029\n",
      "Epoch  5540 Loss  0.18590621650218964\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  5550 Loss  0.18568287789821625\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  5560 Loss  0.19555561244487762\n",
      "Training accuracy is  0.8996318834047029\n",
      "Epoch  5570 Loss  0.1894075721502304\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  5580 Loss  0.18794381618499756\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  5590 Loss  0.18861551582813263\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  5600 Loss  0.19337071478366852\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  5610 Loss  0.18888942897319794\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  5620 Loss  0.1966574639081955\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  5630 Loss  0.20326635241508484\n",
      "Training accuracy is  0.8996318834047029\n",
      "Epoch  5640 Loss  0.19430772960186005\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  5650 Loss  0.18520504236221313\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  5660 Loss  0.18548843264579773\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  5670 Loss  0.18498918414115906\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  5680 Loss  0.18449465930461884\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  5690 Loss  0.1842600405216217\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  5700 Loss  0.20809319615364075\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  5710 Loss  0.19459892809391022\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  5720 Loss  0.18619181215763092\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  5730 Loss  0.18502174317836761\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  5740 Loss  0.1889059990644455\n",
      "Training accuracy is  0.9040643077154233\n",
      "Epoch  5750 Loss  0.18968798220157623\n",
      "Training accuracy is  0.9015851551348508\n",
      "Epoch  5760 Loss  0.19145037233829498\n",
      "Training accuracy is  0.9163098189467358\n",
      "Epoch  5770 Loss  0.18617761135101318\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  5780 Loss  0.1934659779071808\n",
      "Training accuracy is  0.903388175193449\n",
      "Epoch  5790 Loss  0.1902809739112854\n",
      "Training accuracy is  0.8958004657801818\n",
      "Epoch  5800 Loss  0.19289183616638184\n",
      "Training accuracy is  0.8680039065434603\n",
      "Epoch  5810 Loss  0.1889171451330185\n",
      "Training accuracy is  0.8699571782736083\n",
      "Epoch  5820 Loss  0.18713383376598358\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  5830 Loss  0.185836061835289\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  5840 Loss  0.18456342816352844\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  5850 Loss  0.1843559443950653\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  5860 Loss  0.18412630259990692\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  5870 Loss  0.1997804492712021\n",
      "Training accuracy is  0.8592893095935692\n",
      "Epoch  5880 Loss  0.2002549022436142\n",
      "Training accuracy is  0.9449327623769814\n",
      "Epoch  5890 Loss  0.18418258428573608\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  5900 Loss  0.18748493492603302\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  5910 Loss  0.18941323459148407\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  5920 Loss  0.1902756541967392\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  5930 Loss  0.18815568089485168\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  5940 Loss  0.1899930238723755\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  5950 Loss  0.18848194181919098\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  5960 Loss  0.1896972805261612\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  5970 Loss  0.18970640003681183\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  5980 Loss  0.1911693960428238\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  5990 Loss  0.1941758245229721\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  6000 Loss  0.20370641350746155\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  6010 Loss  0.20253321528434753\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  6020 Loss  0.18566115200519562\n",
      "Training accuracy is  0.90248666516415\n",
      "Epoch  6030 Loss  0.1854936182498932\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  6040 Loss  0.18491631746292114\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  6050 Loss  0.18422608077526093\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6060 Loss  0.18399326503276825\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  6070 Loss  0.1870320439338684\n",
      "Training accuracy is  0.9023364134926001\n",
      "Epoch  6080 Loss  0.19072790443897247\n",
      "Training accuracy is  0.9028622943430246\n",
      "Epoch  6090 Loss  0.18829341232776642\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  6100 Loss  0.18401101231575012\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  6110 Loss  0.18816182017326355\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  6120 Loss  0.18911872804164886\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  6130 Loss  0.19075918197631836\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  6140 Loss  0.1875702291727066\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  6150 Loss  0.19297416508197784\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  6160 Loss  0.19419610500335693\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  6170 Loss  0.1998327374458313\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  6180 Loss  0.19931459426879883\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  6190 Loss  0.18697082996368408\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6200 Loss  0.18425051867961884\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6210 Loss  0.18410056829452515\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6220 Loss  0.18383356928825378\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6230 Loss  0.18526405096054077\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  6240 Loss  0.1882796734571457\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  6250 Loss  0.18979156017303467\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  6260 Loss  0.18763785064220428\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  6270 Loss  0.18892104923725128\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  6280 Loss  0.19144001603126526\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  6290 Loss  0.19375742971897125\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  6300 Loss  0.2013956606388092\n",
      "Training accuracy is  0.8996318834047029\n",
      "Epoch  6310 Loss  0.2046830654144287\n",
      "Training accuracy is  0.9000826384193524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6320 Loss  0.18651869893074036\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6330 Loss  0.1847110241651535\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6340 Loss  0.18478086590766907\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  6350 Loss  0.1839628517627716\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  6360 Loss  0.1836322695016861\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  6370 Loss  0.1877930909395218\n",
      "Training accuracy is  0.9078205995041695\n",
      "Epoch  6380 Loss  0.19036245346069336\n",
      "Training accuracy is  0.9214183757794305\n",
      "Epoch  6390 Loss  0.1866462379693985\n",
      "Training accuracy is  0.9013597776275261\n",
      "Epoch  6400 Loss  0.18427349627017975\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  6410 Loss  0.1938285380601883\n",
      "Training accuracy is  0.9096236195627676\n",
      "Epoch  6420 Loss  0.18886420130729675\n",
      "Training accuracy is  0.9046653144016227\n",
      "Epoch  6430 Loss  0.18987612426280975\n",
      "Training accuracy is  0.876042370971377\n",
      "Epoch  6440 Loss  0.19005915522575378\n",
      "Training accuracy is  0.8705581849598076\n",
      "Epoch  6450 Loss  0.18653474748134613\n",
      "Training accuracy is  0.888813763053114\n",
      "Epoch  6460 Loss  0.18459486961364746\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  6470 Loss  0.18465344607830048\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  6480 Loss  0.18404708802700043\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  6490 Loss  0.1888616532087326\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  6500 Loss  0.18889421224594116\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  6510 Loss  0.18985342979431152\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  6520 Loss  0.18743565678596497\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  6530 Loss  0.192939892411232\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  6540 Loss  0.19788560271263123\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  6550 Loss  0.21131941676139832\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  6560 Loss  0.1918807178735733\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  6570 Loss  0.18473222851753235\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  6580 Loss  0.18524666130542755\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6590 Loss  0.18386872112751007\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6600 Loss  0.18366169929504395\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  6610 Loss  0.18340112268924713\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6620 Loss  0.18345192074775696\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  6630 Loss  0.1904030591249466\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  6640 Loss  0.19145478308200836\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  6650 Loss  0.18463808298110962\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  6660 Loss  0.18347331881523132\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  6670 Loss  0.1841352880001068\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  6680 Loss  0.19090533256530762\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  6690 Loss  0.18957683444023132\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6700 Loss  0.18996316194534302\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  6710 Loss  0.18801574409008026\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  6720 Loss  0.1907743215560913\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  6730 Loss  0.19076423346996307\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  6740 Loss  0.1931052953004837\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  6750 Loss  0.194726824760437\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  6760 Loss  0.19419263303279877\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  6770 Loss  0.1894727200269699\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  6780 Loss  0.18564000725746155\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  6790 Loss  0.1844361126422882\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  6800 Loss  0.19528305530548096\n",
      "Training accuracy is  0.8996318834047029\n",
      "Epoch  6810 Loss  0.18866482377052307\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  6820 Loss  0.19007454812526703\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  6830 Loss  0.19173090159893036\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  6840 Loss  0.20244576036930084\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  6850 Loss  0.21525456011295319\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  6860 Loss  0.18621017038822174\n",
      "Training accuracy is  0.9103748779205169\n",
      "Epoch  6870 Loss  0.18701693415641785\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  6880 Loss  0.1840219795703888\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  6890 Loss  0.1841743439435959\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6900 Loss  0.18356972932815552\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6910 Loss  0.18329891562461853\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6920 Loss  0.18303526937961578\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6930 Loss  0.18285948038101196\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  6940 Loss  0.18491508066654205\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  6950 Loss  0.23768627643585205\n",
      "Training accuracy is  0.9099992487416423\n",
      "Epoch  6960 Loss  0.1865973323583603\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  6970 Loss  0.18533217906951904\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  6980 Loss  0.18526609241962433\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  6990 Loss  0.18414711952209473\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  7000 Loss  0.18315637111663818\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7010 Loss  0.18351125717163086\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  7020 Loss  0.20023702085018158\n",
      "Training accuracy is  0.899481631733153\n",
      "Epoch  7030 Loss  0.19095176458358765\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  7040 Loss  0.18441486358642578\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  7050 Loss  0.18846701085567474\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  7060 Loss  0.18712368607521057\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  7070 Loss  0.18937337398529053\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  7080 Loss  0.18774157762527466\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  7090 Loss  0.1896638125181198\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  7100 Loss  0.19165226817131042\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  7110 Loss  0.1958247423171997\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  7120 Loss  0.20197923481464386\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  7130 Loss  0.19253280758857727\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  7140 Loss  0.1840357929468155\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7150 Loss  0.1831696331501007\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  7160 Loss  0.18289168179035187\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  7170 Loss  0.18409119546413422\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  7180 Loss  0.1900804340839386\n",
      "Training accuracy is  0.9030876718503493\n",
      "Epoch  7190 Loss  0.18989704549312592\n",
      "Training accuracy is  0.9021861618210503\n",
      "Epoch  7200 Loss  0.18280550837516785\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  7210 Loss  0.1827591359615326\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  7220 Loss  0.2049483358860016\n",
      "Training accuracy is  0.9261513034332507\n",
      "Epoch  7230 Loss  0.1961708515882492\n",
      "Training accuracy is  0.8912929156336864\n",
      "Epoch  7240 Loss  0.1837877780199051\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7250 Loss  0.18798859417438507\n",
      "Training accuracy is  0.926902561791\n",
      "Epoch  7260 Loss  0.1890205442905426\n",
      "Training accuracy is  0.9096987453985426\n",
      "Epoch  7270 Loss  0.19274002313613892\n",
      "Training accuracy is  0.871234317481782\n",
      "Epoch  7280 Loss  0.19599105417728424\n",
      "Training accuracy is  0.8593644354293442\n",
      "Epoch  7290 Loss  0.18637441098690033\n",
      "Training accuracy is  0.8941476973931335\n",
      "Epoch  7300 Loss  0.18904908001422882\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7310 Loss  0.18423347175121307\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7320 Loss  0.1839684695005417\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7330 Loss  0.1832895427942276\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7340 Loss  0.18306131660938263\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7350 Loss  0.18270514905452728\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7360 Loss  0.18241041898727417\n",
      "Training accuracy is  0.9006085192697769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7370 Loss  0.19126731157302856\n",
      "Training accuracy is  0.899556757568928\n",
      "Epoch  7380 Loss  0.1871071308851242\n",
      "Training accuracy is  0.924874164225077\n",
      "Epoch  7390 Loss  0.1832805573940277\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  7400 Loss  0.18361443281173706\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  7410 Loss  0.18809540569782257\n",
      "Training accuracy is  0.902411539328375\n",
      "Epoch  7420 Loss  0.19018711149692535\n",
      "Training accuracy is  0.907294718653745\n",
      "Epoch  7430 Loss  0.18716678023338318\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  7440 Loss  0.1972474455833435\n",
      "Training accuracy is  0.9427541131395086\n",
      "Epoch  7450 Loss  0.18610046803951263\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  7460 Loss  0.19026747345924377\n",
      "Training accuracy is  0.9175869581549094\n",
      "Epoch  7470 Loss  0.18741801381111145\n",
      "Training accuracy is  0.9048155660731726\n",
      "Epoch  7480 Loss  0.18800394237041473\n",
      "Training accuracy is  0.9214183757794305\n",
      "Epoch  7490 Loss  0.18862992525100708\n",
      "Training accuracy is  0.9166103222898355\n",
      "Epoch  7500 Loss  0.18820393085479736\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  7510 Loss  0.1855081021785736\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  7520 Loss  0.18664024770259857\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  7530 Loss  0.18955495953559875\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  7540 Loss  0.18443663418293\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7550 Loss  0.2023220807313919\n",
      "Training accuracy is  0.9090977387123432\n",
      "Epoch  7560 Loss  0.18518942594528198\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  7570 Loss  0.1909293532371521\n",
      "Training accuracy is  0.920892494929006\n",
      "Epoch  7580 Loss  0.18631315231323242\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  7590 Loss  0.18976040184497833\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  7600 Loss  0.18516860902309418\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  7610 Loss  0.18734952807426453\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  7620 Loss  0.18848419189453125\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  7630 Loss  0.18671143054962158\n",
      "Training accuracy is  0.9319359927879197\n",
      "Epoch  7640 Loss  0.18597455322742462\n",
      "Training accuracy is  0.9021861618210503\n",
      "Epoch  7650 Loss  0.18631157279014587\n",
      "Training accuracy is  0.9033130493576741\n",
      "Epoch  7660 Loss  0.19090481102466583\n",
      "Training accuracy is  0.9128540305010894\n",
      "Epoch  7670 Loss  0.18581368029117584\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  7680 Loss  0.19066469371318817\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  7690 Loss  0.18388232588768005\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  7700 Loss  0.19323574006557465\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  7710 Loss  0.18569394946098328\n",
      "Training accuracy is  0.9044399368942979\n",
      "Epoch  7720 Loss  0.19302016496658325\n",
      "Training accuracy is  0.9220945083014048\n",
      "Epoch  7730 Loss  0.18367043137550354\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  7740 Loss  0.1965150386095047\n",
      "Training accuracy is  0.9193148523777327\n",
      "Epoch  7750 Loss  0.18623584508895874\n",
      "Training accuracy is  0.9018856584779505\n",
      "Epoch  7760 Loss  0.1908818781375885\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  7770 Loss  0.184353768825531\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7780 Loss  0.18343165516853333\n",
      "Training accuracy is  0.901510029299076\n",
      "Epoch  7790 Loss  0.20168091356754303\n",
      "Training accuracy is  0.9232965216738036\n",
      "Epoch  7800 Loss  0.18440034985542297\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  7810 Loss  0.18568891286849976\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  7820 Loss  0.18510404229164124\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  7830 Loss  0.19021360576152802\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  7840 Loss  0.19077828526496887\n",
      "Training accuracy is  0.90736984448952\n",
      "Epoch  7850 Loss  0.18357796967029572\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  7860 Loss  0.18440072238445282\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  7870 Loss  0.21044230461120605\n",
      "Training accuracy is  0.8737134700623544\n",
      "Epoch  7880 Loss  0.18611037731170654\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  7890 Loss  0.18313659727573395\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  7900 Loss  0.18417654931545258\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  7910 Loss  0.19398944079875946\n",
      "Training accuracy is  0.9441815040192322\n",
      "Epoch  7920 Loss  0.18521438539028168\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  7930 Loss  0.18817636370658875\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  7940 Loss  0.18204116821289062\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  7950 Loss  0.18296578526496887\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  7960 Loss  0.19828268885612488\n",
      "Training accuracy is  0.8988806250469537\n",
      "Epoch  7970 Loss  0.1846705973148346\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  7980 Loss  0.18624870479106903\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  7990 Loss  0.1830141246318817\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  8000 Loss  0.18428663909435272\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  8010 Loss  0.20561106503009796\n",
      "Training accuracy is  0.9319359927879197\n",
      "Epoch  8020 Loss  0.18236948549747467\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  8030 Loss  0.18447789549827576\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  8040 Loss  0.19549433887004852\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  8050 Loss  0.18269138038158417\n",
      "Training accuracy is  0.9032379235218991\n",
      "Epoch  8060 Loss  0.19410757720470428\n",
      "Training accuracy is  0.9259259259259259\n",
      "Epoch  8070 Loss  0.19266214966773987\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  8080 Loss  0.1843682825565338\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  8090 Loss  0.1826164722442627\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  8100 Loss  0.2191041111946106\n",
      "Training accuracy is  0.8905416572759371\n",
      "Epoch  8110 Loss  0.183613121509552\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  8120 Loss  0.18847711384296417\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  8130 Loss  0.18871991336345673\n",
      "Training accuracy is  0.924874164225077\n",
      "Epoch  8140 Loss  0.1865822970867157\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  8150 Loss  0.19345234334468842\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  8160 Loss  0.18658752739429474\n",
      "Training accuracy is  0.9078957253399444\n",
      "Epoch  8170 Loss  0.18247726559638977\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  8180 Loss  0.1910897046327591\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  8190 Loss  0.18345320224761963\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  8200 Loss  0.18822863698005676\n",
      "Training accuracy is  0.915107805574337\n",
      "Epoch  8210 Loss  0.18379896879196167\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  8220 Loss  0.1836685985326767\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  8230 Loss  0.1983027458190918\n",
      "Training accuracy is  0.9296822177146721\n",
      "Epoch  8240 Loss  0.19035589694976807\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  8250 Loss  0.18614782392978668\n",
      "Training accuracy is  0.9027871685072496\n",
      "Epoch  8260 Loss  0.18404991924762726\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  8270 Loss  0.1837780624628067\n",
      "Training accuracy is  0.9021110359852753\n",
      "Epoch  8280 Loss  0.1917094886302948\n",
      "Training accuracy is  0.9292314627000225\n",
      "Epoch  8290 Loss  0.1911238133907318\n",
      "Training accuracy is  0.9206671174216813\n",
      "Epoch  8300 Loss  0.19863706827163696\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  8310 Loss  0.18423575162887573\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  8320 Loss  0.18460369110107422\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  8330 Loss  0.18280427157878876\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  8340 Loss  0.18891391158103943\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  8350 Loss  0.18739661574363708\n",
      "Training accuracy is  0.86830440988656\n",
      "Epoch  8360 Loss  0.18523165583610535\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  8370 Loss  0.18209323287010193\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  8380 Loss  0.18216928839683533\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  8390 Loss  0.18357528746128082\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  8400 Loss  0.20096221566200256\n",
      "Training accuracy is  0.8801742919389978\n",
      "Epoch  8410 Loss  0.20102477073669434\n",
      "Training accuracy is  0.899481631733153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8420 Loss  0.18696527183055878\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  8430 Loss  0.18284691870212555\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  8440 Loss  0.18585117161273956\n",
      "Training accuracy is  0.9037638043723236\n",
      "Epoch  8450 Loss  0.1896492838859558\n",
      "Training accuracy is  0.9284050785064983\n",
      "Epoch  8460 Loss  0.18684518337249756\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  8470 Loss  0.19835442304611206\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  8480 Loss  0.18198846280574799\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  8490 Loss  0.18233592808246613\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  8500 Loss  0.1818711906671524\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  8510 Loss  0.18124842643737793\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  8520 Loss  0.18302671611309052\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  8530 Loss  0.18330800533294678\n",
      "Training accuracy is  0.9308842310870709\n",
      "Epoch  8540 Loss  0.19998261332511902\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  8550 Loss  0.18210221827030182\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  8560 Loss  0.18457387387752533\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  8570 Loss  0.18259002268314362\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  8580 Loss  0.1810520589351654\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  8590 Loss  0.22333671152591705\n",
      "Training accuracy is  0.9361430395913155\n",
      "Epoch  8600 Loss  0.20605185627937317\n",
      "Training accuracy is  0.906393208624446\n",
      "Epoch  8610 Loss  0.1840522438287735\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  8620 Loss  0.18291862308979034\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  8630 Loss  0.1898912787437439\n",
      "Training accuracy is  0.9225452633160544\n",
      "Epoch  8640 Loss  0.18833434581756592\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  8650 Loss  0.18890628218650818\n",
      "Training accuracy is  0.917061077304485\n",
      "Epoch  8660 Loss  0.1853863000869751\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  8670 Loss  0.18296368420124054\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  8680 Loss  0.18173643946647644\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  8690 Loss  0.19528625905513763\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  8700 Loss  0.18701568245887756\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  8710 Loss  0.18309564888477325\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  8720 Loss  0.18780618906021118\n",
      "Training accuracy is  0.923897528360003\n",
      "Epoch  8730 Loss  0.21023550629615784\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  8740 Loss  0.19074630737304688\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  8750 Loss  0.18493136763572693\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  8760 Loss  0.18160384893417358\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  8770 Loss  0.18128608167171478\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  8780 Loss  0.18446342647075653\n",
      "Training accuracy is  0.9084216061903688\n",
      "Epoch  8790 Loss  0.1882620006799698\n",
      "Training accuracy is  0.9060927052813462\n",
      "Epoch  8800 Loss  0.18607766926288605\n",
      "Training accuracy is  0.9030125460145744\n",
      "Epoch  8810 Loss  0.1840447187423706\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  8820 Loss  0.1896640509366989\n",
      "Training accuracy is  0.8568101570129968\n",
      "Epoch  8830 Loss  0.18493936955928802\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  8840 Loss  0.18200528621673584\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  8850 Loss  0.18150754272937775\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  8860 Loss  0.18305350840091705\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  8870 Loss  0.1951046735048294\n",
      "Training accuracy is  0.9328375028172189\n",
      "Epoch  8880 Loss  0.18429572880268097\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  8890 Loss  0.18371067941188812\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  8900 Loss  0.1926029920578003\n",
      "Training accuracy is  0.9281797009991736\n",
      "Epoch  8910 Loss  0.19463391602039337\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  8920 Loss  0.2000652402639389\n",
      "Training accuracy is  0.8816016828187213\n",
      "Epoch  8930 Loss  0.18192704021930695\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  8940 Loss  0.1820019632577896\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  8950 Loss  0.18618273735046387\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  8960 Loss  0.1871068775653839\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  8970 Loss  0.18889999389648438\n",
      "Training accuracy is  0.8737134700623544\n",
      "Epoch  8980 Loss  0.20457829535007477\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  8990 Loss  0.18252982199192047\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  9000 Loss  0.18389199674129486\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  9010 Loss  0.18257275223731995\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  9020 Loss  0.1831243932247162\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  9030 Loss  0.1886577010154724\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  9040 Loss  0.18423035740852356\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  9050 Loss  0.2072180062532425\n",
      "Training accuracy is  0.8616182105025918\n",
      "Epoch  9060 Loss  0.1957942694425583\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  9070 Loss  0.18787460029125214\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  9080 Loss  0.1815168708562851\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  9090 Loss  0.1809980869293213\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  9100 Loss  0.1873282492160797\n",
      "Training accuracy is  0.9126286529937646\n",
      "Epoch  9110 Loss  0.18992726504802704\n",
      "Training accuracy is  0.9270528134625498\n",
      "Epoch  9120 Loss  0.1842908263206482\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  9130 Loss  0.19136692583560944\n",
      "Training accuracy is  0.9172113289760349\n",
      "Epoch  9140 Loss  0.18452587723731995\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  9150 Loss  0.18435530364513397\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  9160 Loss  0.1813870370388031\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  9170 Loss  0.1820380836725235\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  9180 Loss  0.20328396558761597\n",
      "Training accuracy is  0.9540229885057471\n",
      "Epoch  9190 Loss  0.191719189286232\n",
      "Training accuracy is  0.9353166553977913\n",
      "Epoch  9200 Loss  0.18346871435642242\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  9210 Loss  0.18601833283901215\n",
      "Training accuracy is  0.9081962286830441\n",
      "Epoch  9220 Loss  0.18816959857940674\n",
      "Training accuracy is  0.9062429569528961\n",
      "Epoch  9230 Loss  0.18886040151119232\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  9240 Loss  0.2108347862958908\n",
      "Training accuracy is  0.8612425813237172\n",
      "Epoch  9250 Loss  0.18176239728927612\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  9260 Loss  0.18335779011249542\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  9270 Loss  0.18133926391601562\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  9280 Loss  0.18984639644622803\n",
      "Training accuracy is  0.9393734505296372\n",
      "Epoch  9290 Loss  0.18792204558849335\n",
      "Training accuracy is  0.9137555405303884\n",
      "Epoch  9300 Loss  0.18604609370231628\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  9310 Loss  0.20039688050746918\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  9320 Loss  0.19339005649089813\n",
      "Training accuracy is  0.8925700548418601\n",
      "Epoch  9330 Loss  0.18235579133033752\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  9340 Loss  0.18345744907855988\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  9350 Loss  0.18099932372570038\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  9360 Loss  0.20141051709651947\n",
      "Training accuracy is  0.9298324693862219\n",
      "Epoch  9370 Loss  0.18564245104789734\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  9380 Loss  0.19642017781734467\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  9390 Loss  0.18201981484889984\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  9400 Loss  0.18241839110851288\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  9410 Loss  0.18218445777893066\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  9420 Loss  0.18767336010932922\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  9430 Loss  0.18245160579681396\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  9440 Loss  0.19851581752300262\n",
      "Training accuracy is  0.9188640973630832\n",
      "Epoch  9450 Loss  0.19232036173343658\n",
      "Training accuracy is  0.9154083089174367\n",
      "Epoch  9460 Loss  0.18172243237495422\n",
      "Training accuracy is  0.9009841484486515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9470 Loss  0.1829163283109665\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  9480 Loss  0.18242086470127106\n",
      "Training accuracy is  0.9012846517917512\n",
      "Epoch  9490 Loss  0.19236186146736145\n",
      "Training accuracy is  0.9445571331981069\n",
      "Epoch  9500 Loss  0.18755702674388885\n",
      "Training accuracy is  0.9067688378033205\n",
      "Epoch  9510 Loss  0.20022493600845337\n",
      "Training accuracy is  0.899556757568928\n",
      "Epoch  9520 Loss  0.18712736666202545\n",
      "Training accuracy is  0.9163098189467358\n",
      "Epoch  9530 Loss  0.18307241797447205\n",
      "Training accuracy is  0.9057170761024717\n",
      "Epoch  9540 Loss  0.18364949524402618\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  9550 Loss  0.18058738112449646\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  9560 Loss  0.20404452085494995\n",
      "Training accuracy is  0.9030876718503493\n",
      "Epoch  9570 Loss  0.18539851903915405\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  9580 Loss  0.19905667006969452\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  9590 Loss  0.19748671352863312\n",
      "Training accuracy is  0.8777702651942003\n",
      "Epoch  9600 Loss  0.18216535449028015\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  9610 Loss  0.1835864633321762\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  9620 Loss  0.1809842884540558\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  9630 Loss  0.19843542575836182\n",
      "Training accuracy is  0.9281045751633987\n",
      "Epoch  9640 Loss  0.1845659464597702\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  9650 Loss  0.18854816257953644\n",
      "Training accuracy is  0.8759672451356021\n",
      "Epoch  9660 Loss  0.1886904537677765\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  9670 Loss  0.18156151473522186\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  9680 Loss  0.18238107860088348\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  9690 Loss  0.18103180825710297\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  9700 Loss  0.19403959810733795\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  9710 Loss  0.18266063928604126\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  9720 Loss  0.20812484622001648\n",
      "Training accuracy is  0.8635714822327398\n",
      "Epoch  9730 Loss  0.18996085226535797\n",
      "Training accuracy is  0.901434903463301\n",
      "Epoch  9740 Loss  0.18347805738449097\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  9750 Loss  0.18331634998321533\n",
      "Training accuracy is  0.9018856584779505\n",
      "Epoch  9760 Loss  0.1819959282875061\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  9770 Loss  0.19083650410175323\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  9780 Loss  0.18129916489124298\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  9790 Loss  0.19982922077178955\n",
      "Training accuracy is  0.896551724137931\n",
      "Epoch  9800 Loss  0.1885492354631424\n",
      "Training accuracy is  0.9299827210577718\n",
      "Epoch  9810 Loss  0.1833619922399521\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  9820 Loss  0.18069392442703247\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  9830 Loss  0.1829909384250641\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  9840 Loss  0.1915411651134491\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  9850 Loss  0.18272967636585236\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  9860 Loss  0.20378553867340088\n",
      "Training accuracy is  0.8650739989482383\n",
      "Epoch  9870 Loss  0.20104685425758362\n",
      "Training accuracy is  0.9021110359852753\n",
      "Epoch  9880 Loss  0.1878947615623474\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  9890 Loss  0.18181836605072021\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  9900 Loss  0.18219530582427979\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  9910 Loss  0.181696817278862\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  9920 Loss  0.19236698746681213\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  9930 Loss  0.17999950051307678\n",
      "Training accuracy is  0.9054916985951469\n",
      "Epoch  9940 Loss  0.1932181864976883\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  9950 Loss  0.18915247917175293\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  9960 Loss  0.18375755846500397\n",
      "Training accuracy is  0.9039140560438735\n",
      "Epoch  9970 Loss  0.18180526793003082\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  9980 Loss  0.18236294388771057\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  9990 Loss  0.19611483812332153\n",
      "Training accuracy is  0.9350912778904665\n",
      "Epoch  10000 Loss  0.18534277379512787\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  10010 Loss  0.19740821421146393\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  10020 Loss  0.19141514599323273\n",
      "Training accuracy is  0.8997070092404778\n",
      "Epoch  10030 Loss  0.1814614087343216\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  10040 Loss  0.18280060589313507\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  10050 Loss  0.18068259954452515\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  10060 Loss  0.18357214331626892\n",
      "Training accuracy is  0.9031627976861243\n",
      "Epoch  10070 Loss  0.1915029138326645\n",
      "Training accuracy is  0.9331380061603185\n",
      "Epoch  10080 Loss  0.18308085203170776\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  10090 Loss  0.18812428414821625\n",
      "Training accuracy is  0.9112012621140411\n",
      "Epoch  10100 Loss  0.191592738032341\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  10110 Loss  0.18248699605464935\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  10120 Loss  0.18141096830368042\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  10130 Loss  0.1801292449235916\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  10140 Loss  0.19021907448768616\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  10150 Loss  0.18770146369934082\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  10160 Loss  0.18308542668819427\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  10170 Loss  0.18340586125850677\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  10180 Loss  0.18868041038513184\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  10190 Loss  0.18438871204853058\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  10200 Loss  0.1854238361120224\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  10210 Loss  0.18416909873485565\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  10220 Loss  0.20627492666244507\n",
      "Training accuracy is  0.8631958530538653\n",
      "Epoch  10230 Loss  0.1903492957353592\n",
      "Training accuracy is  0.9193148523777327\n",
      "Epoch  10240 Loss  0.18389904499053955\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  10250 Loss  0.18090015649795532\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  10260 Loss  0.1813526451587677\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  10270 Loss  0.17997200787067413\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  10280 Loss  0.22877363860607147\n",
      "Training accuracy is  0.8630456013823153\n",
      "Epoch  10290 Loss  0.2004949003458023\n",
      "Training accuracy is  0.9072195928179702\n",
      "Epoch  10300 Loss  0.1965622752904892\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  10310 Loss  0.18105483055114746\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  10320 Loss  0.18309663236141205\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  10330 Loss  0.1828290820121765\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  10340 Loss  0.18326611816883087\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  10350 Loss  0.18779289722442627\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  10360 Loss  0.21273642778396606\n",
      "Training accuracy is  0.8607167004732927\n",
      "Epoch  10370 Loss  0.18928781151771545\n",
      "Training accuracy is  0.9309593569228458\n",
      "Epoch  10380 Loss  0.1847604513168335\n",
      "Training accuracy is  0.9096987453985426\n",
      "Epoch  10390 Loss  0.18247339129447937\n",
      "Training accuracy is  0.9012846517917512\n",
      "Epoch  10400 Loss  0.18038542568683624\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  10410 Loss  0.1798820048570633\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  10420 Loss  0.18506111204624176\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  10430 Loss  0.18638461828231812\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  10440 Loss  0.18059878051280975\n",
      "Training accuracy is  0.903388175193449\n",
      "Epoch  10450 Loss  0.1919131875038147\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  10460 Loss  0.1881924867630005\n",
      "Training accuracy is  0.9294568402073473\n",
      "Epoch  10470 Loss  0.17997056245803833\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  10480 Loss  0.18045561015605927\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  10490 Loss  0.1849045604467392\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  10500 Loss  0.1859055459499359\n",
      "Training accuracy is  0.900533393434002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10510 Loss  0.19582535326480865\n",
      "Training accuracy is  0.864397866426264\n",
      "Epoch  10520 Loss  0.19998960196971893\n",
      "Training accuracy is  0.9189392231988581\n",
      "Epoch  10530 Loss  0.18428866565227509\n",
      "Training accuracy is  0.9017354068064007\n",
      "Epoch  10540 Loss  0.1813766062259674\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  10550 Loss  0.18059206008911133\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  10560 Loss  0.1804000288248062\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  10570 Loss  0.18040618300437927\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  10580 Loss  0.19836655259132385\n",
      "Training accuracy is  0.9374201787994891\n",
      "Epoch  10590 Loss  0.19094884395599365\n",
      "Training accuracy is  0.9390729471865374\n",
      "Epoch  10600 Loss  0.18332868814468384\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  10610 Loss  0.18495267629623413\n",
      "Training accuracy is  0.8606415746375179\n",
      "Epoch  10620 Loss  0.18943840265274048\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  10630 Loss  0.1815812587738037\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  10640 Loss  0.18063703179359436\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  10650 Loss  0.19219078123569489\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  10660 Loss  0.18734444677829742\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  10670 Loss  0.18218758702278137\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  10680 Loss  0.18132512271404266\n",
      "Training accuracy is  0.9018105326421757\n",
      "Epoch  10690 Loss  0.18969005346298218\n",
      "Training accuracy is  0.9025617909999248\n",
      "Epoch  10700 Loss  0.19401976466178894\n",
      "Training accuracy is  0.8576365412065209\n",
      "Epoch  10710 Loss  0.18038292229175568\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  10720 Loss  0.18177078664302826\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  10730 Loss  0.18011046946048737\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  10740 Loss  0.1800309717655182\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  10750 Loss  0.1904905140399933\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  10760 Loss  0.18843571841716766\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  10770 Loss  0.1795448213815689\n",
      "Training accuracy is  0.9019607843137255\n",
      "Epoch  10780 Loss  0.1857144832611084\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  10790 Loss  0.18550395965576172\n",
      "Training accuracy is  0.8744647284201037\n",
      "Epoch  10800 Loss  0.1840180605649948\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  10810 Loss  0.18116599321365356\n",
      "Training accuracy is  0.9009841484486515\n",
      "Epoch  10820 Loss  0.18024280667304993\n",
      "Training accuracy is  0.9010592742844264\n",
      "Epoch  10830 Loss  0.19125999510288239\n",
      "Training accuracy is  0.9311847344301706\n",
      "Epoch  10840 Loss  0.19037625193595886\n",
      "Training accuracy is  0.9146570505596875\n",
      "Epoch  10850 Loss  0.19779574871063232\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  10860 Loss  0.19236911833286285\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  10870 Loss  0.1854645162820816\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  10880 Loss  0.18240559101104736\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  10890 Loss  0.180441215634346\n",
      "Training accuracy is  0.9006085192697769\n",
      "Epoch  10900 Loss  0.17983810603618622\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  10910 Loss  0.19168250262737274\n",
      "Training accuracy is  0.9537976109984223\n",
      "Epoch  10920 Loss  0.1876518279314041\n",
      "Training accuracy is  0.915182931410112\n",
      "Epoch  10930 Loss  0.1813971847295761\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  10940 Loss  0.19124504923820496\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  10950 Loss  0.2613435387611389\n",
      "Training accuracy is  0.86830440988656\n",
      "Epoch  10960 Loss  0.1899021565914154\n",
      "Training accuracy is  0.8977537375103298\n",
      "Epoch  10970 Loss  0.19518011808395386\n",
      "Training accuracy is  0.8538051235819999\n",
      "Epoch  10980 Loss  0.20422406494617462\n",
      "Training accuracy is  0.8954999624370821\n",
      "Epoch  10990 Loss  0.19866414368152618\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  11000 Loss  0.1960233747959137\n",
      "Training accuracy is  0.8994065058973781\n",
      "Epoch  11010 Loss  0.19483183324337006\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  11020 Loss  0.19396349787712097\n",
      "Training accuracy is  0.8993313800616032\n",
      "Epoch  11030 Loss  0.19324322044849396\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  11040 Loss  0.19262830913066864\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  11050 Loss  0.19208243489265442\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  11060 Loss  0.1916319578886032\n",
      "Training accuracy is  0.899481631733153\n",
      "Epoch  11070 Loss  0.19119256734848022\n",
      "Training accuracy is  0.899481631733153\n",
      "Epoch  11080 Loss  0.19085438549518585\n",
      "Training accuracy is  0.899556757568928\n",
      "Epoch  11090 Loss  0.19056236743927002\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  11100 Loss  0.1902744621038437\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  11110 Loss  0.1900084763765335\n",
      "Training accuracy is  0.8999323867478025\n",
      "Epoch  11120 Loss  0.18972378969192505\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  11130 Loss  0.18944457173347473\n",
      "Training accuracy is  0.9000075125835775\n",
      "Epoch  11140 Loss  0.18908600509166718\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  11150 Loss  0.18877573311328888\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  11160 Loss  0.1885174959897995\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  11170 Loss  0.18825897574424744\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  11180 Loss  0.1879929006099701\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  11190 Loss  0.18775483965873718\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  11200 Loss  0.18746443092823029\n",
      "Training accuracy is  0.9000826384193524\n",
      "Epoch  11210 Loss  0.18714992702007294\n",
      "Training accuracy is  0.9001577642551274\n",
      "Epoch  11220 Loss  0.18690785765647888\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  11230 Loss  0.18665489554405212\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  11240 Loss  0.18636208772659302\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  11250 Loss  0.18611633777618408\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  11260 Loss  0.18589352071285248\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  11270 Loss  0.18568585813045502\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  11280 Loss  0.18546612560749054\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  11290 Loss  0.18524496257305145\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  11300 Loss  0.18500785529613495\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  11310 Loss  0.184718057513237\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  11320 Loss  0.18448182940483093\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  11330 Loss  0.18423406779766083\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  11340 Loss  0.18396319448947906\n",
      "Training accuracy is  0.9003831417624522\n",
      "Epoch  11350 Loss  0.1836872547864914\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  11360 Loss  0.18340744078159332\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  11370 Loss  0.18308277428150177\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  11380 Loss  0.18280000984668732\n",
      "Training accuracy is  0.9007587709413267\n",
      "Epoch  11390 Loss  0.18253526091575623\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  11400 Loss  0.1822614073753357\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  11410 Loss  0.18198290467262268\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  11420 Loss  0.18170714378356934\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  11430 Loss  0.18141944706439972\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  11440 Loss  0.18112194538116455\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  11450 Loss  0.18080048263072968\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  11460 Loss  0.18044763803482056\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  11470 Loss  0.18010927736759186\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  11480 Loss  0.17976470291614532\n",
      "Training accuracy is  0.9008338967771017\n",
      "Epoch  11490 Loss  0.18127325177192688\n",
      "Training accuracy is  0.9026369168356998\n",
      "Epoch  11500 Loss  0.1886061578989029\n",
      "Training accuracy is  0.9315603636090452\n",
      "Epoch  11510 Loss  0.18241572380065918\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  11520 Loss  0.180796280503273\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  11530 Loss  0.1948576718568802\n",
      "Training accuracy is  0.9392231988580872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  11540 Loss  0.1889059841632843\n",
      "Training accuracy is  0.9241229058673278\n",
      "Epoch  11550 Loss  0.1833207905292511\n",
      "Training accuracy is  0.9018105326421757\n",
      "Epoch  11560 Loss  0.18997399508953094\n",
      "Training accuracy is  0.9293065885357975\n",
      "Epoch  11570 Loss  0.18614806234836578\n",
      "Training accuracy is  0.9069190894748704\n",
      "Epoch  11580 Loss  0.18739058077335358\n",
      "Training accuracy is  0.910224626248967\n",
      "Epoch  11590 Loss  0.18636834621429443\n",
      "Training accuracy is  0.9087972353692435\n",
      "Epoch  11600 Loss  0.1875249445438385\n",
      "Training accuracy is  0.9112763879498159\n",
      "Epoch  11610 Loss  0.1863400638103485\n",
      "Training accuracy is  0.9079708511757193\n",
      "Epoch  11620 Loss  0.1878538727760315\n",
      "Training accuracy is  0.914131169709263\n",
      "Epoch  11630 Loss  0.18567362427711487\n",
      "Training accuracy is  0.9055668244309218\n",
      "Epoch  11640 Loss  0.1889200210571289\n",
      "Training accuracy is  0.9221696341371798\n",
      "Epoch  11650 Loss  0.1852525919675827\n",
      "Training accuracy is  0.9046653144016227\n",
      "Epoch  11660 Loss  0.18852321803569794\n",
      "Training accuracy is  0.9229960183307039\n",
      "Epoch  11670 Loss  0.18604819476604462\n",
      "Training accuracy is  0.9056419502666967\n",
      "Epoch  11680 Loss  0.18683426082134247\n",
      "Training accuracy is  0.9142814213808128\n",
      "Epoch  11690 Loss  0.18746896088123322\n",
      "Training accuracy is  0.9103748779205169\n",
      "Epoch  11700 Loss  0.18577814102172852\n",
      "Training accuracy is  0.9078957253399444\n",
      "Epoch  11710 Loss  0.1887158453464508\n",
      "Training accuracy is  0.9196904815566073\n",
      "Epoch  11720 Loss  0.18511849641799927\n",
      "Training accuracy is  0.9049658177447224\n",
      "Epoch  11730 Loss  0.18932916224002838\n",
      "Training accuracy is  0.9261513034332507\n",
      "Epoch  11740 Loss  0.1853487342596054\n",
      "Training accuracy is  0.9048906919089474\n",
      "Epoch  11750 Loss  0.1881447285413742\n",
      "Training accuracy is  0.9224701374802795\n",
      "Epoch  11760 Loss  0.18641246855258942\n",
      "Training accuracy is  0.9072195928179702\n",
      "Epoch  11770 Loss  0.18654681742191315\n",
      "Training accuracy is  0.9123281496506649\n",
      "Epoch  11780 Loss  0.1879195123910904\n",
      "Training accuracy is  0.914206295545038\n",
      "Epoch  11790 Loss  0.18549984693527222\n",
      "Training accuracy is  0.9069942153106453\n",
      "Epoch  11800 Loss  0.18910165131092072\n",
      "Training accuracy is  0.9230711441664788\n",
      "Epoch  11810 Loss  0.18505670130252838\n",
      "Training accuracy is  0.9050409435804974\n",
      "Epoch  11820 Loss  0.1893351525068283\n",
      "Training accuracy is  0.9280294493276238\n",
      "Epoch  11830 Loss  0.18533040583133698\n",
      "Training accuracy is  0.9051160694162722\n",
      "Epoch  11840 Loss  0.18820668756961823\n",
      "Training accuracy is  0.9244234092104274\n",
      "Epoch  11850 Loss  0.1864662617444992\n",
      "Training accuracy is  0.9078205995041695\n",
      "Epoch  11860 Loss  0.1865663379430771\n",
      "Training accuracy is  0.9136052888588385\n",
      "Epoch  11870 Loss  0.1874997764825821\n",
      "Training accuracy is  0.9122530238148899\n",
      "Epoch  11880 Loss  0.18557173013687134\n",
      "Training accuracy is  0.9085718578619187\n",
      "Epoch  11890 Loss  0.1891080141067505\n",
      "Training accuracy is  0.921042746600556\n",
      "Epoch  11900 Loss  0.18467353284358978\n",
      "Training accuracy is  0.9051160694162722\n",
      "Epoch  11910 Loss  0.1902238130569458\n",
      "Training accuracy is  0.9304334760724213\n",
      "Epoch  11920 Loss  0.18485140800476074\n",
      "Training accuracy is  0.9050409435804974\n",
      "Epoch  11930 Loss  0.18956825137138367\n",
      "Training accuracy is  0.9306588535797461\n",
      "Epoch  11940 Loss  0.18511778116226196\n",
      "Training accuracy is  0.9051911952520472\n",
      "Epoch  11950 Loss  0.18856577575206757\n",
      "Training accuracy is  0.9282548268349485\n",
      "Epoch  11960 Loss  0.18592776358127594\n",
      "Training accuracy is  0.9065434602959958\n",
      "Epoch  11970 Loss  0.18693393468856812\n",
      "Training accuracy is  0.9184133423484336\n",
      "Epoch  11980 Loss  0.1872626394033432\n",
      "Training accuracy is  0.9121027721433401\n",
      "Epoch  11990 Loss  0.185618594288826\n",
      "Training accuracy is  0.9097738712343175\n",
      "Epoch  12000 Loss  0.18868598341941833\n",
      "Training accuracy is  0.9199158590639321\n",
      "Epoch  12010 Loss  0.1847042590379715\n",
      "Training accuracy is  0.906393208624446\n",
      "Epoch  12020 Loss  0.19158992171287537\n",
      "Training accuracy is  0.9425287356321839\n",
      "Epoch  12030 Loss  0.18342968821525574\n",
      "Training accuracy is  0.902411539328375\n",
      "Epoch  12040 Loss  0.18750065565109253\n",
      "Training accuracy is  0.9378709338141387\n",
      "Epoch  12050 Loss  0.18545469641685486\n",
      "Training accuracy is  0.9048906919089474\n",
      "Epoch  12060 Loss  0.1859263777732849\n",
      "Training accuracy is  0.912177897979115\n",
      "Epoch  12070 Loss  0.1885770857334137\n",
      "Training accuracy is  0.9205919915859064\n",
      "Epoch  12080 Loss  0.18340496718883514\n",
      "Training accuracy is  0.9028622943430246\n",
      "Epoch  12090 Loss  0.19550968706607819\n",
      "Training accuracy is  0.9616858237547893\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 70)\n",
    "        self.fc2 = nn.Linear(70, 70)\n",
    "        self.fc3 = nn.Linear(70, 70)\n",
    "        self.fc4 = nn.Linear(70, 70)\n",
    "        self.fc5 = nn.Linear(70, 70)\n",
    "        self.fc6 = nn.Linear(70, 70)\n",
    "        self.fc7 = nn.Linear(70, 70)\n",
    "        self.fc8 = nn.Linear(70, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = self.fc8(x)\n",
    "        return F.log_softmax(x)\n",
    "        #return F.softmax(x)\n",
    "\n",
    "#%% plot function\n",
    "        \n",
    "def plot_data(X, y, filename):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "        \n",
    "def plot_decision_boundary(clf, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    #x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    #y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    x_min, x_max = -1, 1\n",
    "    y_min, y_max = -1, 1\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    X_out = net(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype = torch.float))\n",
    "    Z = X_out.data.max(1)[1]\n",
    "    # Z.shape\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    #plt.show()\n",
    "    #plt.savefig(filename)\n",
    "    #plt.close()\n",
    "\n",
    "#%% read data\n",
    "\n",
    "data = pd.read_csv('FeedForward_Data_ellipse.csv')\n",
    "X = data.values[:, 0:2]  # Take only the first two features.     \n",
    "X = torch.tensor(X, dtype = torch.float)   \n",
    "y = data.values[:, 2]\n",
    "y = torch.tensor(y, dtype = torch.long)\n",
    "\n",
    "#%% train\n",
    "net = Net()\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = .01\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# create a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "nepochs = 20000\n",
    "data, target = X, y\n",
    "\n",
    "# run the main training loop\n",
    "for epoch in range(nepochs):\n",
    "#    adjust learning rate if desired\n",
    "#    if epoch % 3000 == 0 and epoch <= 24000:\n",
    "#        for g in optimizer.param_groups:\n",
    "#            g['lr'] = g['lr']/2\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagate\n",
    "    net_out = net(data)\n",
    "    # compute loss\n",
    "    loss = criterion(net_out, target)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step() \n",
    "    # print out report\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correctidx = pred.eq(target.data) \n",
    "        ncorrect = correctidx.sum()\n",
    "        accuracy = ncorrect.item()/len(data)\n",
    "        print('Training accuracy is ', accuracy)\n",
    "    if accuracy > 0.96:\n",
    "        break\n",
    "        \n",
    "plot_decision_boundary(net, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.\tFile Feedforward_Data_hexa.csv contains 13312 two-dimensional data points (feature values located in columns A and B) and their respective binary label (labels located in column C).  Create and train a network that separates the data.  Report your best cross-entropy and accuracy values.  Plot the decision boundaries of your best network by plotting the network outputs in a densely sampled region around.  Report the number of hidden layers, type of activation function and number of neurons per layer used.   [-1.0,1.0] x [-1.0,1.0].  (15 points).\n",
    "\n",
    "Best cross entropy: 0.011\n",
    "\n",
    "Best accuracy value: 0.997\n",
    "\n",
    "Number of hidden layers: 7\n",
    "\n",
    "Type of activation function: Linear\n",
    "\n",
    "number of neurons per layer used: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jungmin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss  0.6334953904151917\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  10 Loss  0.5601906776428223\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  20 Loss  0.47978219389915466\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  30 Loss  0.29575586318969727\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  40 Loss  0.2484484612941742\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  50 Loss  0.21491394937038422\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  60 Loss  0.21079519391059875\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  70 Loss  0.20637430250644684\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  80 Loss  0.19976583123207092\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  90 Loss  0.1926809847354889\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  100 Loss  0.1843128204345703\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  110 Loss  0.17401005327701569\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  120 Loss  0.1614667922258377\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  130 Loss  0.1464928835630417\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  140 Loss  0.12987928092479706\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  150 Loss  0.11419281363487244\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  160 Loss  0.09996958076953888\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  170 Loss  0.08841579407453537\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  180 Loss  0.0814678817987442\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  190 Loss  0.07462413609027863\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  200 Loss  0.06932783871889114\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  210 Loss  0.06613988429307938\n",
      "Training accuracy is  0.940575463902036\n",
      "Epoch  220 Loss  0.06251982599496841\n",
      "Training accuracy is  0.9738562091503268\n",
      "Epoch  230 Loss  0.05761101841926575\n",
      "Training accuracy is  0.9750582225227256\n",
      "Epoch  240 Loss  0.05599769577383995\n",
      "Training accuracy is  0.9737810833145518\n",
      "Epoch  250 Loss  0.05352363362908363\n",
      "Training accuracy is  0.9743069641649763\n",
      "Epoch  260 Loss  0.05213630571961403\n",
      "Training accuracy is  0.9743069641649763\n",
      "Epoch  270 Loss  0.05176625773310661\n",
      "Training accuracy is  0.9753587258658253\n",
      "Epoch  280 Loss  0.051260292530059814\n",
      "Training accuracy is  0.9745323416723011\n",
      "Epoch  290 Loss  0.05130916088819504\n",
      "Training accuracy is  0.9733303282999023\n",
      "Epoch  300 Loss  0.05275031179189682\n",
      "Training accuracy is  0.974682593343851\n",
      "Epoch  310 Loss  0.05100877210497856\n",
      "Training accuracy is  0.9739313349861017\n",
      "Epoch  320 Loss  0.05290669575333595\n",
      "Training accuracy is  0.9752836000300503\n",
      "Epoch  330 Loss  0.05072677135467529\n",
      "Training accuracy is  0.9748328450154008\n",
      "Epoch  340 Loss  0.049687460064888\n",
      "Training accuracy is  0.9760348583877996\n",
      "Epoch  350 Loss  0.04944328963756561\n",
      "Training accuracy is  0.9762602358951243\n",
      "Epoch  360 Loss  0.04982742294669151\n",
      "Training accuracy is  0.9759597325520246\n",
      "Epoch  370 Loss  0.05006810650229454\n",
      "Training accuracy is  0.9751333483585005\n",
      "Epoch  380 Loss  0.05033589154481888\n",
      "Training accuracy is  0.9759597325520246\n",
      "Epoch  390 Loss  0.05770157277584076\n",
      "Training accuracy is  0.9699496656900308\n",
      "Epoch  400 Loss  0.05506047606468201\n",
      "Training accuracy is  0.9719780632559537\n",
      "Epoch  410 Loss  0.05022609606385231\n",
      "Training accuracy is  0.9747577191796258\n",
      "Epoch  420 Loss  0.05032382160425186\n",
      "Training accuracy is  0.9752084741942754\n",
      "Epoch  430 Loss  0.04859689250588417\n",
      "Training accuracy is  0.9750582225227256\n",
      "Epoch  440 Loss  0.04804207757115364\n",
      "Training accuracy is  0.9763353617308993\n",
      "Epoch  450 Loss  0.04737132415175438\n",
      "Training accuracy is  0.9770866200886484\n",
      "Epoch  460 Loss  0.05000782757997513\n",
      "Training accuracy is  0.9770866200886484\n",
      "Epoch  470 Loss  0.07332207262516022\n",
      "Training accuracy is  0.9702501690331304\n",
      "Epoch  480 Loss  0.059230536222457886\n",
      "Training accuracy is  0.9690481556607318\n",
      "Epoch  490 Loss  0.05307546257972717\n",
      "Training accuracy is  0.9747577191796258\n",
      "Epoch  500 Loss  0.05124465748667717\n",
      "Training accuracy is  0.9754338517016001\n",
      "Epoch  510 Loss  0.04825480282306671\n",
      "Training accuracy is  0.9758846067162498\n",
      "Epoch  520 Loss  0.047600407153367996\n",
      "Training accuracy is  0.9756592292089249\n",
      "Epoch  530 Loss  0.04697052016854286\n",
      "Training accuracy is  0.9758094808804748\n",
      "Epoch  540 Loss  0.046448055654764175\n",
      "Training accuracy is  0.9758846067162498\n",
      "Epoch  550 Loss  0.04602110758423805\n",
      "Training accuracy is  0.9761851100593494\n",
      "Epoch  560 Loss  0.0457376204431057\n",
      "Training accuracy is  0.9763353617308993\n",
      "Epoch  570 Loss  0.04545238986611366\n",
      "Training accuracy is  0.9764104875666741\n",
      "Epoch  580 Loss  0.04580751433968544\n",
      "Training accuracy is  0.9764856134024491\n",
      "Epoch  590 Loss  0.04550449177622795\n",
      "Training accuracy is  0.9767861167455488\n",
      "Epoch  600 Loss  0.0453454814851284\n",
      "Training accuracy is  0.9769363684170986\n",
      "Epoch  610 Loss  0.04503358528017998\n",
      "Training accuracy is  0.9766358650739989\n",
      "Epoch  620 Loss  0.04735048860311508\n",
      "Training accuracy is  0.9700247915258057\n",
      "Epoch  630 Loss  0.057244546711444855\n",
      "Training accuracy is  0.9709263015551048\n",
      "Epoch  640 Loss  0.049847111105918884\n",
      "Training accuracy is  0.9762602358951243\n",
      "Epoch  650 Loss  0.04641159996390343\n",
      "Training accuracy is  0.9754338517016001\n",
      "Epoch  660 Loss  0.04503924027085304\n",
      "Training accuracy is  0.9764856134024491\n",
      "Epoch  670 Loss  0.0444340743124485\n",
      "Training accuracy is  0.9769363684170986\n",
      "Epoch  680 Loss  0.044176265597343445\n",
      "Training accuracy is  0.9767109909097739\n",
      "Epoch  690 Loss  0.04378073289990425\n",
      "Training accuracy is  0.9770866200886484\n",
      "Epoch  700 Loss  0.04573289304971695\n",
      "Training accuracy is  0.9765607392382241\n",
      "Epoch  710 Loss  0.04377701133489609\n",
      "Training accuracy is  0.9767109909097739\n",
      "Epoch  720 Loss  0.04314617067575455\n",
      "Training accuracy is  0.9765607392382241\n",
      "Epoch  730 Loss  0.043620944023132324\n",
      "Training accuracy is  0.9764104875666741\n",
      "Epoch  740 Loss  0.047360870987176895\n",
      "Training accuracy is  0.9770866200886484\n",
      "Epoch  750 Loss  0.046286359429359436\n",
      "Training accuracy is  0.9733303282999023\n",
      "Epoch  760 Loss  0.04565140977501869\n",
      "Training accuracy is  0.9764104875666741\n",
      "Epoch  770 Loss  0.04359212517738342\n",
      "Training accuracy is  0.9757343550446999\n",
      "Epoch  780 Loss  0.0418037548661232\n",
      "Training accuracy is  0.9764856134024491\n",
      "Epoch  790 Loss  0.04374637082219124\n",
      "Training accuracy is  0.9780632559537225\n",
      "Epoch  800 Loss  0.04104089364409447\n",
      "Training accuracy is  0.9772368717601984\n",
      "Epoch  810 Loss  0.04212960973381996\n",
      "Training accuracy is  0.9782886334610472\n",
      "Epoch  820 Loss  0.0434793159365654\n",
      "Training accuracy is  0.9796408985049959\n",
      "Epoch  830 Loss  0.0403093658387661\n",
      "Training accuracy is  0.9784388851325971\n",
      "Epoch  840 Loss  0.040368903428316116\n",
      "Training accuracy is  0.9809931635489445\n",
      "Epoch  850 Loss  0.04203391820192337\n",
      "Training accuracy is  0.9818946735782436\n",
      "Epoch  860 Loss  0.04395086690783501\n",
      "Training accuracy is  0.9819697994140185\n",
      "Epoch  870 Loss  0.04574817046523094\n",
      "Training accuracy is  0.9704004207046804\n",
      "Epoch  880 Loss  0.04406303912401199\n",
      "Training accuracy is  0.981443918563594\n",
      "Epoch  890 Loss  0.04050416126847267\n",
      "Training accuracy is  0.9771617459244234\n",
      "Epoch  900 Loss  0.03707791119813919\n",
      "Training accuracy is  0.9791901434903463\n",
      "Epoch  910 Loss  0.04081173986196518\n",
      "Training accuracy is  0.9698745398542559\n",
      "Epoch  920 Loss  0.03824992850422859\n",
      "Training accuracy is  0.9752084741942754\n",
      "Epoch  930 Loss  0.03837962821125984\n",
      "Training accuracy is  0.9783637592968222\n",
      "Epoch  940 Loss  0.03808102384209633\n",
      "Training accuracy is  0.9779130042821726\n",
      "Epoch  950 Loss  0.04593911021947861\n",
      "Training accuracy is  0.9744572158365262\n",
      "Epoch  960 Loss  0.0500154010951519\n",
      "Training accuracy is  0.9839981969799414\n",
      "Epoch  970 Loss  0.039026785641908646\n",
      "Training accuracy is  0.9830215611148674\n",
      "Epoch  980 Loss  0.036451779305934906\n",
      "Training accuracy is  0.9767109909097739\n",
      "Epoch  990 Loss  0.05247247964143753\n",
      "Training accuracy is  0.9834723161295169\n",
      "Epoch  1000 Loss  0.036882732063531876\n",
      "Training accuracy is  0.9837728194726166\n",
      "Epoch  1010 Loss  0.04360617697238922\n",
      "Training accuracy is  0.9764104875666741\n",
      "Epoch  1020 Loss  0.03879657760262489\n",
      "Training accuracy is  0.9762602358951243\n",
      "Epoch  1030 Loss  0.03745370730757713\n",
      "Training accuracy is  0.9840733228157164\n",
      "Epoch  1040 Loss  0.033677518367767334\n",
      "Training accuracy is  0.9847494553376906\n",
      "Epoch  1050 Loss  0.03382623568177223\n",
      "Training accuracy is  0.9845240778303659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1060 Loss  0.03492460027337074\n",
      "Training accuracy is  0.9860265945458643\n",
      "Epoch  1070 Loss  0.033514998853206635\n",
      "Training accuracy is  0.9839981969799414\n",
      "Epoch  1080 Loss  0.03291120380163193\n",
      "Training accuracy is  0.986327097888964\n",
      "Epoch  1090 Loss  0.040331657975912094\n",
      "Training accuracy is  0.9773119975959732\n",
      "Epoch  1100 Loss  0.03658825904130936\n",
      "Training accuracy is  0.9864773495605138\n",
      "Epoch  1110 Loss  0.036197613924741745\n",
      "Training accuracy is  0.9803170310269702\n",
      "Epoch  1120 Loss  0.04973900690674782\n",
      "Training accuracy is  0.9845240778303659\n",
      "Epoch  1130 Loss  0.03295407071709633\n",
      "Training accuracy is  0.9865524753962888\n",
      "Epoch  1140 Loss  0.03675605729222298\n",
      "Training accuracy is  0.9786642626399219\n",
      "Epoch  1150 Loss  0.056809332221746445\n",
      "Training accuracy is  0.9837728194726166\n",
      "Epoch  1160 Loss  0.03933703154325485\n",
      "Training accuracy is  0.9740815866576515\n",
      "Epoch  1170 Loss  0.03547819331288338\n",
      "Training accuracy is  0.9855758395312147\n",
      "Epoch  1180 Loss  0.03268827870488167\n",
      "Training accuracy is  0.9790398918187965\n",
      "Epoch  1190 Loss  0.043294161558151245\n",
      "Training accuracy is  0.9786642626399219\n",
      "Epoch  1200 Loss  0.043095044791698456\n",
      "Training accuracy is  0.9754338517016001\n",
      "Epoch  1210 Loss  0.03789493814110756\n",
      "Training accuracy is  0.9773871234317482\n",
      "Epoch  1220 Loss  0.03227190673351288\n",
      "Training accuracy is  0.9790398918187965\n",
      "Epoch  1230 Loss  0.036609042435884476\n",
      "Training accuracy is  0.981519044399369\n",
      "Epoch  1240 Loss  0.030735203996300697\n",
      "Training accuracy is  0.9812936668920442\n",
      "Epoch  1250 Loss  0.05834043398499489\n",
      "Training accuracy is  0.9878296146044625\n",
      "Epoch  1260 Loss  0.05242983251810074\n",
      "Training accuracy is  0.9786642626399219\n",
      "Epoch  1270 Loss  0.03596989065408707\n",
      "Training accuracy is  0.9750582225227256\n",
      "Epoch  1280 Loss  0.03870858624577522\n",
      "Training accuracy is  0.9819697994140185\n",
      "Epoch  1290 Loss  0.03543141111731529\n",
      "Training accuracy is  0.9860265945458643\n",
      "Epoch  1300 Loss  0.03290450572967529\n",
      "Training accuracy is  0.9824956802644429\n",
      "Epoch  1310 Loss  0.03105941042304039\n",
      "Training accuracy is  0.9867027270678387\n",
      "Epoch  1320 Loss  0.03207910433411598\n",
      "Training accuracy is  0.979565772669221\n",
      "Epoch  1330 Loss  0.03935907408595085\n",
      "Training accuracy is  0.978514010968372\n",
      "Epoch  1340 Loss  0.03358009457588196\n",
      "Training accuracy is  0.9807677860416197\n",
      "Epoch  1350 Loss  0.03514565899968147\n",
      "Training accuracy is  0.978514010968372\n",
      "Epoch  1360 Loss  0.03163062036037445\n",
      "Training accuracy is  0.9802419051911953\n",
      "Epoch  1370 Loss  0.031999774277210236\n",
      "Training accuracy is  0.98046728269852\n",
      "Epoch  1380 Loss  0.02985205128788948\n",
      "Training accuracy is  0.98535046202389\n",
      "Epoch  1390 Loss  0.035583242774009705\n",
      "Training accuracy is  0.9807677860416197\n",
      "Epoch  1400 Loss  0.03979789465665817\n",
      "Training accuracy is  0.9782135076252724\n",
      "Epoch  1410 Loss  0.030236294493079185\n",
      "Training accuracy is  0.9810682893847193\n",
      "Epoch  1420 Loss  0.0286005437374115\n",
      "Training accuracy is  0.9890316279768613\n",
      "Epoch  1430 Loss  0.029972108080983162\n",
      "Training accuracy is  0.9887311246337616\n",
      "Epoch  1440 Loss  0.036604829132556915\n",
      "Training accuracy is  0.9859514687100894\n",
      "Epoch  1450 Loss  0.03700141981244087\n",
      "Training accuracy is  0.9800165276838705\n",
      "Epoch  1460 Loss  0.028514914214611053\n",
      "Training accuracy is  0.9891818796484111\n",
      "Epoch  1470 Loss  0.03148341178894043\n",
      "Training accuracy is  0.9884306212906618\n",
      "Epoch  1480 Loss  0.03173123672604561\n",
      "Training accuracy is  0.9885808729622118\n",
      "Epoch  1490 Loss  0.04041338339447975\n",
      "Training accuracy is  0.9788896401472467\n",
      "Epoch  1500 Loss  0.028355881571769714\n",
      "Training accuracy is  0.9849748328450154\n",
      "Epoch  1510 Loss  0.02847554162144661\n",
      "Training accuracy is  0.9861768462174142\n",
      "Epoch  1520 Loss  0.02854740060865879\n",
      "Training accuracy is  0.9866276012320637\n",
      "Epoch  1530 Loss  0.028510788455605507\n",
      "Training accuracy is  0.9876793629329126\n",
      "Epoch  1540 Loss  0.027808960527181625\n",
      "Training accuracy is  0.9845240778303659\n",
      "Epoch  1550 Loss  0.027383554726839066\n",
      "Training accuracy is  0.9878296146044625\n",
      "Epoch  1560 Loss  0.04198186472058296\n",
      "Training accuracy is  0.9816692960709188\n",
      "Epoch  1570 Loss  0.03279155492782593\n",
      "Training accuracy is  0.9887311246337616\n",
      "Epoch  1580 Loss  0.03816511109471321\n",
      "Training accuracy is  0.9776876267748479\n",
      "Epoch  1590 Loss  0.03437875583767891\n",
      "Training accuracy is  0.9803921568627451\n",
      "Epoch  1600 Loss  0.032117001712322235\n",
      "Training accuracy is  0.9821951769213433\n",
      "Epoch  1610 Loss  0.030296778306365013\n",
      "Training accuracy is  0.9877544887686875\n",
      "Epoch  1620 Loss  0.03202834725379944\n",
      "Training accuracy is  0.9855007136954399\n",
      "Epoch  1630 Loss  0.032413505017757416\n",
      "Training accuracy is  0.9856509653669897\n",
      "Epoch  1640 Loss  0.02853587456047535\n",
      "Training accuracy is  0.9894072571557359\n",
      "Epoch  1650 Loss  0.02933623269200325\n",
      "Training accuracy is  0.9881301179475621\n",
      "Epoch  1660 Loss  0.035065095871686935\n",
      "Training accuracy is  0.9861017203816392\n",
      "Epoch  1670 Loss  0.030444176867604256\n",
      "Training accuracy is  0.9840733228157164\n",
      "Epoch  1680 Loss  0.04342333972454071\n",
      "Training accuracy is  0.9821200510855683\n",
      "Epoch  1690 Loss  0.02683291770517826\n",
      "Training accuracy is  0.9884306212906618\n",
      "Epoch  1700 Loss  0.028850577771663666\n",
      "Training accuracy is  0.9845240778303659\n",
      "Epoch  1710 Loss  0.028861165046691895\n",
      "Training accuracy is  0.986402223724739\n",
      "Epoch  1720 Loss  0.03315994143486023\n",
      "Training accuracy is  0.984373826158816\n",
      "Epoch  1730 Loss  0.03737695887684822\n",
      "Training accuracy is  0.98046728269852\n",
      "Epoch  1740 Loss  0.031064538285136223\n",
      "Training accuracy is  0.9822703027571181\n",
      "Epoch  1750 Loss  0.02754855342209339\n",
      "Training accuracy is  0.9872286079182631\n",
      "Epoch  1760 Loss  0.029990393668413162\n",
      "Training accuracy is  0.9861017203816392\n",
      "Epoch  1770 Loss  0.03922384977340698\n",
      "Training accuracy is  0.9803170310269702\n",
      "Epoch  1780 Loss  0.0303812138736248\n",
      "Training accuracy is  0.9825708061002179\n",
      "Epoch  1790 Loss  0.027374984696507454\n",
      "Training accuracy is  0.9876042370971377\n",
      "Epoch  1800 Loss  0.0418875627219677\n",
      "Training accuracy is  0.9799414018480955\n",
      "Epoch  1810 Loss  0.028707778081297874\n",
      "Training accuracy is  0.9852753361881151\n",
      "Epoch  1820 Loss  0.0305744931101799\n",
      "Training accuracy is  0.9817444219066938\n",
      "Epoch  1830 Loss  0.027105746790766716\n",
      "Training accuracy is  0.9858763428743145\n",
      "Epoch  1840 Loss  0.027913400903344154\n",
      "Training accuracy is  0.9870783562467133\n",
      "Epoch  1850 Loss  0.031377051025629044\n",
      "Training accuracy is  0.9856509653669897\n",
      "Epoch  1860 Loss  0.03509967774152756\n",
      "Training accuracy is  0.9812185410562693\n",
      "Epoch  1870 Loss  0.029751107096672058\n",
      "Training accuracy is  0.9832469386221921\n",
      "Epoch  1880 Loss  0.026342211291193962\n",
      "Training accuracy is  0.9869281045751634\n",
      "Epoch  1890 Loss  0.028137970715761185\n",
      "Training accuracy is  0.9871534820824882\n",
      "Epoch  1900 Loss  0.039733413606882095\n",
      "Training accuracy is  0.981443918563594\n",
      "Epoch  1910 Loss  0.0278768427670002\n",
      "Training accuracy is  0.98535046202389\n",
      "Epoch  1920 Loss  0.02705482952296734\n",
      "Training accuracy is  0.9876793629329126\n",
      "Epoch  1930 Loss  0.03687717765569687\n",
      "Training accuracy is  0.9831718127864173\n",
      "Epoch  1940 Loss  0.028821226209402084\n",
      "Training accuracy is  0.9867778529036135\n",
      "Epoch  1950 Loss  0.03463579714298248\n",
      "Training accuracy is  0.9841484486514912\n",
      "Epoch  1960 Loss  0.03335895761847496\n",
      "Training accuracy is  0.9842235744872662\n",
      "Epoch  1970 Loss  0.02589181438088417\n",
      "Training accuracy is  0.9897077604988356\n",
      "Epoch  1980 Loss  0.02606024779379368\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  1990 Loss  0.02763882465660572\n",
      "Training accuracy is  0.9895575088272857\n",
      "Epoch  2000 Loss  0.031513530761003494\n",
      "Training accuracy is  0.978514010968372\n",
      "Epoch  2010 Loss  0.036621078848838806\n",
      "Training accuracy is  0.9855007136954399\n",
      "Epoch  2020 Loss  0.02559940330684185\n",
      "Training accuracy is  0.9864773495605138\n",
      "Epoch  2030 Loss  0.02773798257112503\n",
      "Training accuracy is  0.9867027270678387\n",
      "Epoch  2040 Loss  0.027995727956295013\n",
      "Training accuracy is  0.986402223724739\n",
      "Epoch  2050 Loss  0.025498950853943825\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  2060 Loss  0.025304684415459633\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  2070 Loss  0.029420485720038414\n",
      "Training accuracy is  0.9884306212906618\n",
      "Epoch  2080 Loss  0.030552810057997704\n",
      "Training accuracy is  0.988355495454887\n",
      "Epoch  2090 Loss  0.0319533497095108\n",
      "Training accuracy is  0.980542408534295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2100 Loss  0.024816490709781647\n",
      "Training accuracy is  0.9890316279768613\n",
      "Epoch  2110 Loss  0.02629195898771286\n",
      "Training accuracy is  0.9874539854255878\n",
      "Epoch  2120 Loss  0.025795776396989822\n",
      "Training accuracy is  0.9894072571557359\n",
      "Epoch  2130 Loss  0.03799540922045708\n",
      "Training accuracy is  0.9818195477424686\n",
      "Epoch  2140 Loss  0.025614118203520775\n",
      "Training accuracy is  0.9894823829915108\n",
      "Epoch  2150 Loss  0.025005443021655083\n",
      "Training accuracy is  0.9899331380061603\n",
      "Epoch  2160 Loss  0.024719687178730965\n",
      "Training accuracy is  0.9897077604988356\n",
      "Epoch  2170 Loss  0.02627989836037159\n",
      "Training accuracy is  0.989257005484186\n",
      "Epoch  2180 Loss  0.02534947171807289\n",
      "Training accuracy is  0.9899331380061603\n",
      "Epoch  2190 Loss  0.03323736786842346\n",
      "Training accuracy is  0.9855007136954399\n",
      "Epoch  2200 Loss  0.035491958260536194\n",
      "Training accuracy is  0.9836225678010668\n",
      "Epoch  2210 Loss  0.026573989540338516\n",
      "Training accuracy is  0.9858763428743145\n",
      "Epoch  2220 Loss  0.02522253803908825\n",
      "Training accuracy is  0.9900082638419352\n",
      "Epoch  2230 Loss  0.025005171075463295\n",
      "Training accuracy is  0.9889565021410863\n",
      "Epoch  2240 Loss  0.02717878855764866\n",
      "Training accuracy is  0.9891067538126361\n",
      "Epoch  2250 Loss  0.030864669010043144\n",
      "Training accuracy is  0.9893321313199609\n",
      "Epoch  2260 Loss  0.028701191768050194\n",
      "Training accuracy is  0.9881301179475621\n",
      "Epoch  2270 Loss  0.02978294901549816\n",
      "Training accuracy is  0.9894823829915108\n",
      "Epoch  2280 Loss  0.03785500302910805\n",
      "Training accuracy is  0.9842235744872662\n",
      "Epoch  2290 Loss  0.0330667719244957\n",
      "Training accuracy is  0.9844489519945909\n",
      "Epoch  2300 Loss  0.025025000795722008\n",
      "Training accuracy is  0.9876042370971377\n",
      "Epoch  2310 Loss  0.025309670716524124\n",
      "Training accuracy is  0.9888813763053114\n",
      "Epoch  2320 Loss  0.03054075315594673\n",
      "Training accuracy is  0.9875291112613628\n",
      "Epoch  2330 Loss  0.025847183540463448\n",
      "Training accuracy is  0.9870783562467133\n",
      "Epoch  2340 Loss  0.03569214418530464\n",
      "Training accuracy is  0.9812936668920442\n",
      "Epoch  2350 Loss  0.02510809153318405\n",
      "Training accuracy is  0.9899331380061603\n",
      "Epoch  2360 Loss  0.024331241846084595\n",
      "Training accuracy is  0.9885808729622118\n",
      "Epoch  2370 Loss  0.024674005806446075\n",
      "Training accuracy is  0.9902336413492601\n",
      "Epoch  2380 Loss  0.024219615384936333\n",
      "Training accuracy is  0.9891067538126361\n",
      "Epoch  2390 Loss  0.02581673674285412\n",
      "Training accuracy is  0.9885057471264368\n",
      "Epoch  2400 Loss  0.026828903704881668\n",
      "Training accuracy is  0.9859514687100894\n",
      "Epoch  2410 Loss  0.030345071107149124\n",
      "Training accuracy is  0.9801667793554203\n",
      "Epoch  2420 Loss  0.03213931620121002\n",
      "Training accuracy is  0.9835474419652919\n",
      "Epoch  2430 Loss  0.029317671433091164\n",
      "Training accuracy is  0.9833220644579671\n",
      "Epoch  2440 Loss  0.024082303047180176\n",
      "Training accuracy is  0.9906092705281346\n",
      "Epoch  2450 Loss  0.03003854863345623\n",
      "Training accuracy is  0.9894072571557359\n",
      "Epoch  2460 Loss  0.027435598894953728\n",
      "Training accuracy is  0.9884306212906618\n",
      "Epoch  2470 Loss  0.032733168452978134\n",
      "Training accuracy is  0.9777627526106228\n",
      "Epoch  2480 Loss  0.03474422171711922\n",
      "Training accuracy is  0.982420554428668\n",
      "Epoch  2490 Loss  0.032442402094602585\n",
      "Training accuracy is  0.98535046202389\n",
      "Epoch  2500 Loss  0.026719121262431145\n",
      "Training accuracy is  0.9871534820824882\n",
      "Epoch  2510 Loss  0.02722088247537613\n",
      "Training accuracy is  0.9885057471264368\n",
      "Epoch  2520 Loss  0.03338204324245453\n",
      "Training accuracy is  0.9771617459244234\n",
      "Epoch  2530 Loss  0.03150187060236931\n",
      "Training accuracy is  0.9832469386221921\n",
      "Epoch  2540 Loss  0.031050987541675568\n",
      "Training accuracy is  0.9839230711441664\n",
      "Epoch  2550 Loss  0.02399652637541294\n",
      "Training accuracy is  0.9893321313199609\n",
      "Epoch  2560 Loss  0.026921967044472694\n",
      "Training accuracy is  0.9882052437833371\n",
      "Epoch  2570 Loss  0.02798999287188053\n",
      "Training accuracy is  0.9874539854255878\n",
      "Epoch  2580 Loss  0.027587583288550377\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  2590 Loss  0.026514915749430656\n",
      "Training accuracy is  0.9880549921117873\n",
      "Epoch  2600 Loss  0.024626392871141434\n",
      "Training accuracy is  0.9901585155134851\n",
      "Epoch  2610 Loss  0.03148038685321808\n",
      "Training accuracy is  0.9849748328450154\n",
      "Epoch  2620 Loss  0.027939248830080032\n",
      "Training accuracy is  0.9845240778303659\n",
      "Epoch  2630 Loss  0.02439791150391102\n",
      "Training accuracy is  0.9895575088272857\n",
      "Epoch  2640 Loss  0.03619363531470299\n",
      "Training accuracy is  0.9755089775373751\n",
      "Epoch  2650 Loss  0.025590701028704643\n",
      "Training accuracy is  0.9902336413492601\n",
      "Epoch  2660 Loss  0.024605050683021545\n",
      "Training accuracy is  0.9877544887686875\n",
      "Epoch  2670 Loss  0.023756608366966248\n",
      "Training accuracy is  0.9904590188565848\n",
      "Epoch  2680 Loss  0.032863959670066833\n",
      "Training accuracy is  0.981519044399369\n",
      "Epoch  2690 Loss  0.02660193480551243\n",
      "Training accuracy is  0.9857260912027647\n",
      "Epoch  2700 Loss  0.032335635274648666\n",
      "Training accuracy is  0.9782135076252724\n",
      "Epoch  2710 Loss  0.02504422515630722\n",
      "Training accuracy is  0.9902336413492601\n",
      "Epoch  2720 Loss  0.02649555169045925\n",
      "Training accuracy is  0.9896326346630606\n",
      "Epoch  2730 Loss  0.024590475484728813\n",
      "Training accuracy is  0.9876042370971377\n",
      "Epoch  2740 Loss  0.02390066720545292\n",
      "Training accuracy is  0.9897828863346104\n",
      "Epoch  2750 Loss  0.03363138437271118\n",
      "Training accuracy is  0.9832469386221921\n",
      "Epoch  2760 Loss  0.024157579988241196\n",
      "Training accuracy is  0.9875291112613628\n",
      "Epoch  2770 Loss  0.027790091931819916\n",
      "Training accuracy is  0.9875291112613628\n",
      "Epoch  2780 Loss  0.027832288295030594\n",
      "Training accuracy is  0.9866276012320637\n",
      "Epoch  2790 Loss  0.025428054854273796\n",
      "Training accuracy is  0.9882052437833371\n",
      "Epoch  2800 Loss  0.03557325527071953\n",
      "Training accuracy is  0.984373826158816\n",
      "Epoch  2810 Loss  0.023743735626339912\n",
      "Training accuracy is  0.9897828863346104\n",
      "Epoch  2820 Loss  0.043375980108976364\n",
      "Training accuracy is  0.9840733228157164\n",
      "Epoch  2830 Loss  0.03336123004555702\n",
      "Training accuracy is  0.9764104875666741\n",
      "Epoch  2840 Loss  0.032831933349370956\n",
      "Training accuracy is  0.9880549921117873\n",
      "Epoch  2850 Loss  0.023892350494861603\n",
      "Training accuracy is  0.9894823829915108\n",
      "Epoch  2860 Loss  0.023672550916671753\n",
      "Training accuracy is  0.9909848997070092\n",
      "Epoch  2870 Loss  0.02499411627650261\n",
      "Training accuracy is  0.9906843963639096\n",
      "Epoch  2880 Loss  0.025393517687916756\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  2890 Loss  0.023665446788072586\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  2900 Loss  0.023518050089478493\n",
      "Training accuracy is  0.9903838930208099\n",
      "Epoch  2910 Loss  0.02341805398464203\n",
      "Training accuracy is  0.9897828863346104\n",
      "Epoch  2920 Loss  0.02362990379333496\n",
      "Training accuracy is  0.9903087671850349\n",
      "Epoch  2930 Loss  0.028621777892112732\n",
      "Training accuracy is  0.988355495454887\n",
      "Epoch  2940 Loss  0.023140951991081238\n",
      "Training accuracy is  0.9904590188565848\n",
      "Epoch  2950 Loss  0.026302887126803398\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  2960 Loss  0.03166576102375984\n",
      "Training accuracy is  0.9827210577717677\n",
      "Epoch  2970 Loss  0.03214389085769653\n",
      "Training accuracy is  0.9841484486514912\n",
      "Epoch  2980 Loss  0.0254575926810503\n",
      "Training accuracy is  0.988280369619112\n",
      "Epoch  2990 Loss  0.026476018130779266\n",
      "Training accuracy is  0.9882052437833371\n",
      "Epoch  3000 Loss  0.02902926132082939\n",
      "Training accuracy is  0.9835474419652919\n",
      "Epoch  3010 Loss  0.029079869389533997\n",
      "Training accuracy is  0.9852753361881151\n",
      "Epoch  3020 Loss  0.02362849749624729\n",
      "Training accuracy is  0.9894072571557359\n",
      "Epoch  3030 Loss  0.029997823759913445\n",
      "Training accuracy is  0.9878296146044625\n",
      "Epoch  3040 Loss  0.02449975721538067\n",
      "Training accuracy is  0.9887311246337616\n",
      "Epoch  3050 Loss  0.023614434525370598\n",
      "Training accuracy is  0.9897077604988356\n",
      "Epoch  3060 Loss  0.024313919246196747\n",
      "Training accuracy is  0.9897077604988356\n",
      "Epoch  3070 Loss  0.02306426130235195\n",
      "Training accuracy is  0.9897828863346104\n",
      "Epoch  3080 Loss  0.02405819110572338\n",
      "Training accuracy is  0.9895575088272857\n",
      "Epoch  3090 Loss  0.023142917081713676\n",
      "Training accuracy is  0.9902336413492601\n",
      "Epoch  3100 Loss  0.03865838050842285\n",
      "Training accuracy is  0.9846743295019157\n",
      "Epoch  3110 Loss  0.030390148982405663\n",
      "Training accuracy is  0.98046728269852\n",
      "Epoch  3120 Loss  0.026800598949193954\n",
      "Training accuracy is  0.9869281045751634\n",
      "Epoch  3130 Loss  0.02293795719742775\n",
      "Training accuracy is  0.9909848997070092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3140 Loss  0.028377892449498177\n",
      "Training accuracy is  0.9893321313199609\n",
      "Epoch  3150 Loss  0.02408057264983654\n",
      "Training accuracy is  0.9901585155134851\n",
      "Epoch  3160 Loss  0.026748014613986015\n",
      "Training accuracy is  0.9866276012320637\n",
      "Epoch  3170 Loss  0.023214023560285568\n",
      "Training accuracy is  0.9908346480354594\n",
      "Epoch  3180 Loss  0.03018411062657833\n",
      "Training accuracy is  0.9870032304109383\n",
      "Epoch  3190 Loss  0.026089372113347054\n",
      "Training accuracy is  0.9869281045751634\n",
      "Epoch  3200 Loss  0.024825967848300934\n",
      "Training accuracy is  0.9891818796484111\n",
      "Epoch  3210 Loss  0.030088601633906364\n",
      "Training accuracy is  0.9885057471264368\n",
      "Epoch  3220 Loss  0.025515438988804817\n",
      "Training accuracy is  0.9885808729622118\n",
      "Epoch  3230 Loss  0.02415747195482254\n",
      "Training accuracy is  0.9887311246337616\n",
      "Epoch  3240 Loss  0.05461592227220535\n",
      "Training accuracy is  0.9900082638419352\n",
      "Epoch  3250 Loss  0.08883858472108841\n",
      "Training accuracy is  0.9722785665990534\n",
      "Epoch  3260 Loss  0.0505482442677021\n",
      "Training accuracy is  0.9686725264818571\n",
      "Epoch  3270 Loss  0.035620156675577164\n",
      "Training accuracy is  0.9851250845165652\n",
      "Epoch  3280 Loss  0.03225046768784523\n",
      "Training accuracy is  0.9851250845165652\n",
      "Epoch  3290 Loss  0.027821045368909836\n",
      "Training accuracy is  0.9885808729622118\n",
      "Epoch  3300 Loss  0.0251676794141531\n",
      "Training accuracy is  0.989257005484186\n",
      "Epoch  3310 Loss  0.028410565108060837\n",
      "Training accuracy is  0.9839981969799414\n",
      "Epoch  3320 Loss  0.03475387394428253\n",
      "Training accuracy is  0.9708511757193299\n",
      "Epoch  3330 Loss  0.03039751574397087\n",
      "Training accuracy is  0.9769363684170986\n",
      "Epoch  3340 Loss  0.03466081619262695\n",
      "Training accuracy is  0.978514010968372\n",
      "Epoch  3350 Loss  0.029175378382205963\n",
      "Training accuracy is  0.9849748328450154\n",
      "Epoch  3360 Loss  0.026448126882314682\n",
      "Training accuracy is  0.9850499586807904\n",
      "Epoch  3370 Loss  0.025972556322813034\n",
      "Training accuracy is  0.9900082638419352\n",
      "Epoch  3380 Loss  0.024407340213656425\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  3390 Loss  0.02358384057879448\n",
      "Training accuracy is  0.9903838930208099\n",
      "Epoch  3400 Loss  0.025783399119973183\n",
      "Training accuracy is  0.9874539854255878\n",
      "Epoch  3410 Loss  0.026141349226236343\n",
      "Training accuracy is  0.9875291112613628\n",
      "Epoch  3420 Loss  0.02338865026831627\n",
      "Training accuracy is  0.9894072571557359\n",
      "Epoch  3430 Loss  0.02506271004676819\n",
      "Training accuracy is  0.9887311246337616\n",
      "Epoch  3440 Loss  0.028099214658141136\n",
      "Training accuracy is  0.9824956802644429\n",
      "Epoch  3450 Loss  0.03115338273346424\n",
      "Training accuracy is  0.9710014273908797\n",
      "Epoch  3460 Loss  0.025634579360485077\n",
      "Training accuracy is  0.9827961836075426\n",
      "Epoch  3470 Loss  0.034085292369127274\n",
      "Training accuracy is  0.9850499586807904\n",
      "Epoch  3480 Loss  0.026286376640200615\n",
      "Training accuracy is  0.9871534820824882\n",
      "Epoch  3490 Loss  0.02601795643568039\n",
      "Training accuracy is  0.9891818796484111\n",
      "Epoch  3500 Loss  0.0273086279630661\n",
      "Training accuracy is  0.9891067538126361\n",
      "Epoch  3510 Loss  0.023540694266557693\n",
      "Training accuracy is  0.9912854030501089\n",
      "Epoch  3520 Loss  0.024292346090078354\n",
      "Training accuracy is  0.9891818796484111\n",
      "Epoch  3530 Loss  0.025652889162302017\n",
      "Training accuracy is  0.9878296146044625\n",
      "Epoch  3540 Loss  0.02309051901102066\n",
      "Training accuracy is  0.9897828863346104\n",
      "Epoch  3550 Loss  0.02436489798128605\n",
      "Training accuracy is  0.9900082638419352\n",
      "Epoch  3560 Loss  0.03353884443640709\n",
      "Training accuracy is  0.9842987003230411\n",
      "Epoch  3570 Loss  0.0283487681299448\n",
      "Training accuracy is  0.9842987003230411\n",
      "Epoch  3580 Loss  0.027287185192108154\n",
      "Training accuracy is  0.987378859589813\n",
      "Epoch  3590 Loss  0.02261182852089405\n",
      "Training accuracy is  0.9912854030501089\n",
      "Epoch  3600 Loss  0.024541359394788742\n",
      "Training accuracy is  0.9874539854255878\n",
      "Epoch  3610 Loss  0.043464045971632004\n",
      "Training accuracy is  0.988280369619112\n",
      "Epoch  3620 Loss  0.024293171241879463\n",
      "Training accuracy is  0.9860265945458643\n",
      "Epoch  3630 Loss  0.02291484735906124\n",
      "Training accuracy is  0.9906843963639096\n",
      "Epoch  3640 Loss  0.025486132130026817\n",
      "Training accuracy is  0.988280369619112\n",
      "Epoch  3650 Loss  0.02458307519555092\n",
      "Training accuracy is  0.9885808729622118\n",
      "Epoch  3660 Loss  0.025513555854558945\n",
      "Training accuracy is  0.989257005484186\n",
      "Epoch  3670 Loss  0.029501402750611305\n",
      "Training accuracy is  0.9854255878596649\n",
      "Epoch  3680 Loss  0.030735941603779793\n",
      "Training accuracy is  0.9812936668920442\n",
      "Epoch  3690 Loss  0.026212938129901886\n",
      "Training accuracy is  0.9884306212906618\n",
      "Epoch  3700 Loss  0.023346714675426483\n",
      "Training accuracy is  0.9891818796484111\n",
      "Epoch  3710 Loss  0.024412086233496666\n",
      "Training accuracy is  0.9896326346630606\n",
      "Epoch  3720 Loss  0.022595399990677834\n",
      "Training accuracy is  0.9896326346630606\n",
      "Epoch  3730 Loss  0.022445831447839737\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  3740 Loss  0.029712334275245667\n",
      "Training accuracy is  0.9855007136954399\n",
      "Epoch  3750 Loss  0.022606385871767998\n",
      "Training accuracy is  0.9908346480354594\n",
      "Epoch  3760 Loss  0.028310520574450493\n",
      "Training accuracy is  0.9884306212906618\n",
      "Epoch  3770 Loss  0.02884690836071968\n",
      "Training accuracy is  0.987378859589813\n",
      "Epoch  3780 Loss  0.02258329652249813\n",
      "Training accuracy is  0.9911351513785591\n",
      "Epoch  3790 Loss  0.03393536061048508\n",
      "Training accuracy is  0.9856509653669897\n",
      "Epoch  3800 Loss  0.035273417830467224\n",
      "Training accuracy is  0.9852002103523402\n",
      "Epoch  3810 Loss  0.026961486786603928\n",
      "Training accuracy is  0.9870783562467133\n",
      "Epoch  3820 Loss  0.023558765649795532\n",
      "Training accuracy is  0.9891067538126361\n",
      "Epoch  3830 Loss  0.03131403028964996\n",
      "Training accuracy is  0.9882052437833371\n",
      "Epoch  3840 Loss  0.027686530724167824\n",
      "Training accuracy is  0.9866276012320637\n",
      "Epoch  3850 Loss  0.026417488232254982\n",
      "Training accuracy is  0.9871534820824882\n",
      "Epoch  3860 Loss  0.022342123091220856\n",
      "Training accuracy is  0.9906092705281346\n",
      "Epoch  3870 Loss  0.02632707543671131\n",
      "Training accuracy is  0.9874539854255878\n",
      "Epoch  3880 Loss  0.030082624405622482\n",
      "Training accuracy is  0.9798662760123207\n",
      "Epoch  3890 Loss  0.02475302666425705\n",
      "Training accuracy is  0.9879047404402374\n",
      "Epoch  3900 Loss  0.02203129418194294\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  3910 Loss  0.029471751302480698\n",
      "Training accuracy is  0.9885808729622118\n",
      "Epoch  3920 Loss  0.025576649233698845\n",
      "Training accuracy is  0.9902336413492601\n",
      "Epoch  3930 Loss  0.021916519850492477\n",
      "Training accuracy is  0.9900833896777101\n",
      "Epoch  3940 Loss  0.02180934138596058\n",
      "Training accuracy is  0.9915107805574337\n",
      "Epoch  3950 Loss  0.02226766012609005\n",
      "Training accuracy is  0.9910600255427842\n",
      "Epoch  3960 Loss  0.02248990349471569\n",
      "Training accuracy is  0.9906843963639096\n",
      "Epoch  3970 Loss  0.03388205170631409\n",
      "Training accuracy is  0.9776125009390729\n",
      "Epoch  3980 Loss  0.03922242298722267\n",
      "Training accuracy is  0.9870783562467133\n",
      "Epoch  3990 Loss  0.022152842953801155\n",
      "Training accuracy is  0.9913605288858839\n",
      "Epoch  4000 Loss  0.028252972289919853\n",
      "Training accuracy is  0.9889565021410863\n",
      "Epoch  4010 Loss  0.028229862451553345\n",
      "Training accuracy is  0.9849748328450154\n",
      "Epoch  4020 Loss  0.02294049598276615\n",
      "Training accuracy is  0.9889565021410863\n",
      "Epoch  4030 Loss  0.02166173979640007\n",
      "Training accuracy is  0.9897828863346104\n",
      "Epoch  4040 Loss  0.021159419789910316\n",
      "Training accuracy is  0.9920366614078582\n",
      "Epoch  4050 Loss  0.02665986865758896\n",
      "Training accuracy is  0.9893321313199609\n",
      "Epoch  4060 Loss  0.020916296169161797\n",
      "Training accuracy is  0.9918112839005334\n",
      "Epoch  4070 Loss  0.023093020543456078\n",
      "Training accuracy is  0.9917361580647585\n",
      "Epoch  4080 Loss  0.021820873022079468\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  4090 Loss  0.023917805403470993\n",
      "Training accuracy is  0.9885808729622118\n",
      "Epoch  4100 Loss  0.021527821198105812\n",
      "Training accuracy is  0.9916610322289835\n",
      "Epoch  4110 Loss  0.022956697270274162\n",
      "Training accuracy is  0.9903087671850349\n",
      "Epoch  4120 Loss  0.03091174177825451\n",
      "Training accuracy is  0.986327097888964\n",
      "Epoch  4130 Loss  0.023155104368925095\n",
      "Training accuracy is  0.9918864097363083\n",
      "Epoch  4140 Loss  0.022690987214446068\n",
      "Training accuracy is  0.9909097738712344\n",
      "Epoch  4150 Loss  0.03534792736172676\n",
      "Training accuracy is  0.9809931635489445\n",
      "Epoch  4160 Loss  0.03185087442398071\n",
      "Training accuracy is  0.9870032304109383\n",
      "Epoch  4170 Loss  0.026284826919436455\n",
      "Training accuracy is  0.9899331380061603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4180 Loss  0.032537683844566345\n",
      "Training accuracy is  0.9856509653669897\n",
      "Epoch  4190 Loss  0.02155385911464691\n",
      "Training accuracy is  0.9902336413492601\n",
      "Epoch  4200 Loss  0.028812186792492867\n",
      "Training accuracy is  0.9900082638419352\n",
      "Epoch  4210 Loss  0.02502656914293766\n",
      "Training accuracy is  0.9909848997070092\n",
      "Epoch  4220 Loss  0.023019781336188316\n",
      "Training accuracy is  0.9906843963639096\n",
      "Epoch  4230 Loss  0.03499525412917137\n",
      "Training accuracy is  0.9819697994140185\n",
      "Epoch  4240 Loss  0.027396157383918762\n",
      "Training accuracy is  0.9878296146044625\n",
      "Epoch  4250 Loss  0.02523569017648697\n",
      "Training accuracy is  0.9900833896777101\n",
      "Epoch  4260 Loss  0.028755560517311096\n",
      "Training accuracy is  0.984373826158816\n",
      "Epoch  4270 Loss  0.025684785097837448\n",
      "Training accuracy is  0.9871534820824882\n",
      "Epoch  4280 Loss  0.02543794922530651\n",
      "Training accuracy is  0.9894823829915108\n",
      "Epoch  4290 Loss  0.02076209895312786\n",
      "Training accuracy is  0.9909097738712344\n",
      "Epoch  4300 Loss  0.02503923885524273\n",
      "Training accuracy is  0.9803170310269702\n",
      "Epoch  4310 Loss  0.021109268069267273\n",
      "Training accuracy is  0.9911351513785591\n",
      "Epoch  4320 Loss  0.020887399092316628\n",
      "Training accuracy is  0.9918112839005334\n",
      "Epoch  4330 Loss  0.024992458522319794\n",
      "Training accuracy is  0.9900082638419352\n",
      "Epoch  4340 Loss  0.020637480542063713\n",
      "Training accuracy is  0.9919615355720832\n",
      "Epoch  4350 Loss  0.021547742187976837\n",
      "Training accuracy is  0.9918112839005334\n",
      "Epoch  4360 Loss  0.0379197932779789\n",
      "Training accuracy is  0.9872286079182631\n",
      "Epoch  4370 Loss  0.02784563973546028\n",
      "Training accuracy is  0.9837728194726166\n",
      "Epoch  4380 Loss  0.02636398933827877\n",
      "Training accuracy is  0.9855007136954399\n",
      "Epoch  4390 Loss  0.023904528468847275\n",
      "Training accuracy is  0.9903087671850349\n",
      "Epoch  4400 Loss  0.021361112594604492\n",
      "Training accuracy is  0.9906092705281346\n",
      "Epoch  4410 Loss  0.04319996014237404\n",
      "Training accuracy is  0.9833971902937421\n",
      "Epoch  4420 Loss  0.022145990282297134\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  4430 Loss  0.021420473232865334\n",
      "Training accuracy is  0.9914356547216587\n",
      "Epoch  4440 Loss  0.031015340238809586\n",
      "Training accuracy is  0.9857260912027647\n",
      "Epoch  4450 Loss  0.028244413435459137\n",
      "Training accuracy is  0.9870032304109383\n",
      "Epoch  4460 Loss  0.026217838749289513\n",
      "Training accuracy is  0.9866276012320637\n",
      "Epoch  4470 Loss  0.021831369027495384\n",
      "Training accuracy is  0.9888062504695365\n",
      "Epoch  4480 Loss  0.02080952562391758\n",
      "Training accuracy is  0.9914356547216587\n",
      "Epoch  4490 Loss  0.020168719813227654\n",
      "Training accuracy is  0.9915859063932086\n",
      "Epoch  4500 Loss  0.026851192116737366\n",
      "Training accuracy is  0.9848245811734656\n",
      "Epoch  4510 Loss  0.02161647193133831\n",
      "Training accuracy is  0.9895575088272857\n",
      "Epoch  4520 Loss  0.02063753269612789\n",
      "Training accuracy is  0.9910600255427842\n",
      "Epoch  4530 Loss  0.020794857293367386\n",
      "Training accuracy is  0.9918112839005334\n",
      "Epoch  4540 Loss  0.026349129155278206\n",
      "Training accuracy is  0.9885808729622118\n",
      "Epoch  4550 Loss  0.025344325229525566\n",
      "Training accuracy is  0.9856509653669897\n",
      "Epoch  4560 Loss  0.020988712087273598\n",
      "Training accuracy is  0.9915107805574337\n",
      "Epoch  4570 Loss  0.029313387349247932\n",
      "Training accuracy is  0.9885057471264368\n",
      "Epoch  4580 Loss  0.028423462063074112\n",
      "Training accuracy is  0.982420554428668\n",
      "Epoch  4590 Loss  0.03172871097922325\n",
      "Training accuracy is  0.9895575088272857\n",
      "Epoch  4600 Loss  0.024321556091308594\n",
      "Training accuracy is  0.989257005484186\n",
      "Epoch  4610 Loss  0.0216902457177639\n",
      "Training accuracy is  0.9917361580647585\n",
      "Epoch  4620 Loss  0.023498300462961197\n",
      "Training accuracy is  0.9905341446923597\n",
      "Epoch  4630 Loss  0.030215561389923096\n",
      "Training accuracy is  0.9851250845165652\n",
      "Epoch  4640 Loss  0.023728225380182266\n",
      "Training accuracy is  0.9890316279768613\n",
      "Epoch  4650 Loss  0.02135584130883217\n",
      "Training accuracy is  0.9900833896777101\n",
      "Epoch  4660 Loss  0.027404598891735077\n",
      "Training accuracy is  0.9900833896777101\n",
      "Epoch  4670 Loss  0.022597920149564743\n",
      "Training accuracy is  0.9915859063932086\n",
      "Epoch  4680 Loss  0.032088231295347214\n",
      "Training accuracy is  0.9826459319359928\n",
      "Epoch  4690 Loss  0.02875153161585331\n",
      "Training accuracy is  0.9856509653669897\n",
      "Epoch  4700 Loss  0.022870244458317757\n",
      "Training accuracy is  0.9911351513785591\n",
      "Epoch  4710 Loss  0.02975655533373356\n",
      "Training accuracy is  0.9823454285928931\n",
      "Epoch  4720 Loss  0.020395027473568916\n",
      "Training accuracy is  0.9905341446923597\n",
      "Epoch  4730 Loss  0.023827429860830307\n",
      "Training accuracy is  0.9907595221996844\n",
      "Epoch  4740 Loss  0.020058779045939445\n",
      "Training accuracy is  0.992186913079408\n",
      "Epoch  4750 Loss  0.029334545135498047\n",
      "Training accuracy is  0.9910600255427842\n",
      "Epoch  4760 Loss  0.023979032412171364\n",
      "Training accuracy is  0.986251972053189\n",
      "Epoch  4770 Loss  0.04393887147307396\n",
      "Training accuracy is  0.9908346480354594\n",
      "Epoch  4780 Loss  0.023177456110715866\n",
      "Training accuracy is  0.9918864097363083\n",
      "Epoch  4790 Loss  0.022080807015299797\n",
      "Training accuracy is  0.9907595221996844\n",
      "Epoch  4800 Loss  0.021304458379745483\n",
      "Training accuracy is  0.9913605288858839\n",
      "Epoch  4810 Loss  0.020693516358733177\n",
      "Training accuracy is  0.9914356547216587\n",
      "Epoch  4820 Loss  0.02051853947341442\n",
      "Training accuracy is  0.9915107805574337\n",
      "Epoch  4830 Loss  0.026389749720692635\n",
      "Training accuracy is  0.9887311246337616\n",
      "Epoch  4840 Loss  0.030342785641551018\n",
      "Training accuracy is  0.9869281045751634\n",
      "Epoch  4850 Loss  0.02094346098601818\n",
      "Training accuracy is  0.9914356547216587\n",
      "Epoch  4860 Loss  0.02826027013361454\n",
      "Training accuracy is  0.9870032304109383\n",
      "Epoch  4870 Loss  0.022370101884007454\n",
      "Training accuracy is  0.9902336413492601\n",
      "Epoch  4880 Loss  0.021972643211483955\n",
      "Training accuracy is  0.9911351513785591\n",
      "Epoch  4890 Loss  0.03915448486804962\n",
      "Training accuracy is  0.9823454285928931\n",
      "Epoch  4900 Loss  0.027457451447844505\n",
      "Training accuracy is  0.986251972053189\n",
      "Epoch  4910 Loss  0.023652423173189163\n",
      "Training accuracy is  0.9907595221996844\n",
      "Epoch  4920 Loss  0.02813284657895565\n",
      "Training accuracy is  0.984373826158816\n",
      "Epoch  4930 Loss  0.019963471218943596\n",
      "Training accuracy is  0.9909097738712344\n",
      "Epoch  4940 Loss  0.028607117012143135\n",
      "Training accuracy is  0.9861017203816392\n",
      "Epoch  4950 Loss  0.026473475620150566\n",
      "Training accuracy is  0.9859514687100894\n",
      "Epoch  4960 Loss  0.028194569051265717\n",
      "Training accuracy is  0.9875291112613628\n",
      "Epoch  4970 Loss  0.02323843352496624\n",
      "Training accuracy is  0.9894823829915108\n",
      "Epoch  4980 Loss  0.02067243494093418\n",
      "Training accuracy is  0.9916610322289835\n",
      "Epoch  4990 Loss  0.035499535501003265\n",
      "Training accuracy is  0.9787393884756967\n",
      "Epoch  5000 Loss  0.025744562968611717\n",
      "Training accuracy is  0.9906843963639096\n",
      "Epoch  5010 Loss  0.02140595205128193\n",
      "Training accuracy is  0.9900082638419352\n",
      "Epoch  5020 Loss  0.024944178760051727\n",
      "Training accuracy is  0.9870032304109383\n",
      "Epoch  5030 Loss  0.01990954577922821\n",
      "Training accuracy is  0.9913605288858839\n",
      "Epoch  5040 Loss  0.03738050162792206\n",
      "Training accuracy is  0.9870032304109383\n",
      "Epoch  5050 Loss  0.0224860031157732\n",
      "Training accuracy is  0.9913605288858839\n",
      "Epoch  5060 Loss  0.020079007372260094\n",
      "Training accuracy is  0.9918864097363083\n",
      "Epoch  5070 Loss  0.042738836258649826\n",
      "Training accuracy is  0.9706257982120051\n",
      "Epoch  5080 Loss  0.026957528665661812\n",
      "Training accuracy is  0.972729321613703\n",
      "Epoch  5090 Loss  0.1423785239458084\n",
      "Training accuracy is  0.9686725264818571\n",
      "Epoch  5100 Loss  0.05928932502865791\n",
      "Training accuracy is  0.9693486590038314\n",
      "Epoch  5110 Loss  0.056822579354047775\n",
      "Training accuracy is  0.9653669897077605\n",
      "Epoch  5120 Loss  0.05751998350024223\n",
      "Training accuracy is  0.96581774472241\n",
      "Epoch  5130 Loss  0.0520983450114727\n",
      "Training accuracy is  0.9693486590038314\n",
      "Epoch  5140 Loss  0.03887453302741051\n",
      "Training accuracy is  0.9832469386221921\n",
      "Epoch  5150 Loss  0.03299008309841156\n",
      "Training accuracy is  0.9879798662760123\n",
      "Epoch  5160 Loss  0.028801023960113525\n",
      "Training accuracy is  0.9891067538126361\n",
      "Epoch  5170 Loss  0.025695456191897392\n",
      "Training accuracy is  0.9900833896777101\n",
      "Epoch  5180 Loss  0.023060431703925133\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  5190 Loss  0.02177923172712326\n",
      "Training accuracy is  0.9909848997070092\n",
      "Epoch  5200 Loss  0.032320376485586166\n",
      "Training accuracy is  0.9842987003230411\n",
      "Epoch  5210 Loss  0.026765722781419754\n",
      "Training accuracy is  0.9901585155134851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5220 Loss  0.02703239396214485\n",
      "Training accuracy is  0.9869281045751634\n",
      "Epoch  5230 Loss  0.020975111052393913\n",
      "Training accuracy is  0.9912854030501089\n",
      "Epoch  5240 Loss  0.030692914500832558\n",
      "Training accuracy is  0.986251972053189\n",
      "Epoch  5250 Loss  0.024747781455516815\n",
      "Training accuracy is  0.9900833896777101\n",
      "Epoch  5260 Loss  0.02071112021803856\n",
      "Training accuracy is  0.9921117872436331\n",
      "Epoch  5270 Loss  0.02778046950697899\n",
      "Training accuracy is  0.9914356547216587\n",
      "Epoch  5280 Loss  0.024744508787989616\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  5290 Loss  0.021522289142012596\n",
      "Training accuracy is  0.9915107805574337\n",
      "Epoch  5300 Loss  0.020160308107733727\n",
      "Training accuracy is  0.9908346480354594\n",
      "Epoch  5310 Loss  0.021576400846242905\n",
      "Training accuracy is  0.9915107805574337\n",
      "Epoch  5320 Loss  0.022256607189774513\n",
      "Training accuracy is  0.9899331380061603\n",
      "Epoch  5330 Loss  0.020083274692296982\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  5340 Loss  0.019963683560490608\n",
      "Training accuracy is  0.9920366614078582\n",
      "Epoch  5350 Loss  0.02428027056157589\n",
      "Training accuracy is  0.9914356547216587\n",
      "Epoch  5360 Loss  0.02330009452998638\n",
      "Training accuracy is  0.9904590188565848\n",
      "Epoch  5370 Loss  0.02276536636054516\n",
      "Training accuracy is  0.9917361580647585\n",
      "Epoch  5380 Loss  0.025979923084378242\n",
      "Training accuracy is  0.9870032304109383\n",
      "Epoch  5390 Loss  0.020721467211842537\n",
      "Training accuracy is  0.9913605288858839\n",
      "Epoch  5400 Loss  0.026377243921160698\n",
      "Training accuracy is  0.9861768462174142\n",
      "Epoch  5410 Loss  0.021369613707065582\n",
      "Training accuracy is  0.9899331380061603\n",
      "Epoch  5420 Loss  0.020258508622646332\n",
      "Training accuracy is  0.9920366614078582\n",
      "Epoch  5430 Loss  0.02614622935652733\n",
      "Training accuracy is  0.9904590188565848\n",
      "Epoch  5440 Loss  0.024044379591941833\n",
      "Training accuracy is  0.9891067538126361\n",
      "Epoch  5450 Loss  0.022266758605837822\n",
      "Training accuracy is  0.9900082638419352\n",
      "Epoch  5460 Loss  0.026414670050144196\n",
      "Training accuracy is  0.9906092705281346\n",
      "Epoch  5470 Loss  0.02279413864016533\n",
      "Training accuracy is  0.9919615355720832\n",
      "Epoch  5480 Loss  0.020541729405522346\n",
      "Training accuracy is  0.9918864097363083\n",
      "Epoch  5490 Loss  0.019619902595877647\n",
      "Training accuracy is  0.9915107805574337\n",
      "Epoch  5500 Loss  0.021847831085324287\n",
      "Training accuracy is  0.9914356547216587\n",
      "Epoch  5510 Loss  0.019849292933940887\n",
      "Training accuracy is  0.9910600255427842\n",
      "Epoch  5520 Loss  0.0247353482991457\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  5530 Loss  0.020155319944024086\n",
      "Training accuracy is  0.992186913079408\n",
      "Epoch  5540 Loss  0.023739619180560112\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  5550 Loss  0.022296365350484848\n",
      "Training accuracy is  0.9896326346630606\n",
      "Epoch  5560 Loss  0.02450522780418396\n",
      "Training accuracy is  0.9909848997070092\n",
      "Epoch  5570 Loss  0.0203386377543211\n",
      "Training accuracy is  0.9923371647509579\n",
      "Epoch  5580 Loss  0.034077566117048264\n",
      "Training accuracy is  0.9800916535196454\n",
      "Epoch  5590 Loss  0.02349291555583477\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  5600 Loss  0.02214718423783779\n",
      "Training accuracy is  0.9909097738712344\n",
      "Epoch  5610 Loss  0.0195467546582222\n",
      "Training accuracy is  0.9915859063932086\n",
      "Epoch  5620 Loss  0.024449989199638367\n",
      "Training accuracy is  0.9918112839005334\n",
      "Epoch  5630 Loss  0.01941007375717163\n",
      "Training accuracy is  0.9908346480354594\n",
      "Epoch  5640 Loss  0.020381642505526543\n",
      "Training accuracy is  0.992186913079408\n",
      "Epoch  5650 Loss  0.02572924830019474\n",
      "Training accuracy is  0.9908346480354594\n",
      "Epoch  5660 Loss  0.020206358283758163\n",
      "Training accuracy is  0.9916610322289835\n",
      "Epoch  5670 Loss  0.02902906760573387\n",
      "Training accuracy is  0.9825708061002179\n",
      "Epoch  5680 Loss  0.021780410781502724\n",
      "Training accuracy is  0.9899331380061603\n",
      "Epoch  5690 Loss  0.022053148597478867\n",
      "Training accuracy is  0.9917361580647585\n",
      "Epoch  5700 Loss  0.018982041627168655\n",
      "Training accuracy is  0.9918864097363083\n",
      "Epoch  5710 Loss  0.023275911808013916\n",
      "Training accuracy is  0.992186913079408\n",
      "Epoch  5720 Loss  0.02507287636399269\n",
      "Training accuracy is  0.9866276012320637\n",
      "Epoch  5730 Loss  0.019136058166623116\n",
      "Training accuracy is  0.9913605288858839\n",
      "Epoch  5740 Loss  0.01969205215573311\n",
      "Training accuracy is  0.9925625422582827\n",
      "Epoch  5750 Loss  0.02567136473953724\n",
      "Training accuracy is  0.9894072571557359\n",
      "Epoch  5760 Loss  0.021227186545729637\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  5770 Loss  0.026357825845479965\n",
      "Training accuracy is  0.9852753361881151\n",
      "Epoch  5780 Loss  0.02296828292310238\n",
      "Training accuracy is  0.989257005484186\n",
      "Epoch  5790 Loss  0.020705388858914375\n",
      "Training accuracy is  0.9918112839005334\n",
      "Epoch  5800 Loss  0.027444327250123024\n",
      "Training accuracy is  0.9855007136954399\n",
      "Epoch  5810 Loss  0.01984739862382412\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  5820 Loss  0.020605862140655518\n",
      "Training accuracy is  0.9922620389151829\n",
      "Epoch  5830 Loss  0.037380412220954895\n",
      "Training accuracy is  0.9800165276838705\n",
      "Epoch  5840 Loss  0.022522784769535065\n",
      "Training accuracy is  0.9909848997070092\n",
      "Epoch  5850 Loss  0.01871080882847309\n",
      "Training accuracy is  0.9927879197656074\n",
      "Epoch  5860 Loss  0.033019404858350754\n",
      "Training accuracy is  0.9803170310269702\n",
      "Epoch  5870 Loss  0.02638702280819416\n",
      "Training accuracy is  0.9891818796484111\n",
      "Epoch  5880 Loss  0.019278334453701973\n",
      "Training accuracy is  0.9924122905867327\n",
      "Epoch  5890 Loss  0.025901786983013153\n",
      "Training accuracy is  0.9869281045751634\n",
      "Epoch  5900 Loss  0.01878191903233528\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  5910 Loss  0.019687509164214134\n",
      "Training accuracy is  0.9926376680940575\n",
      "Epoch  5920 Loss  0.03290000185370445\n",
      "Training accuracy is  0.9893321313199609\n",
      "Epoch  5930 Loss  0.01904282532632351\n",
      "Training accuracy is  0.9924874164225077\n",
      "Epoch  5940 Loss  0.021222082898020744\n",
      "Training accuracy is  0.9910600255427842\n",
      "Epoch  5950 Loss  0.018404142931103706\n",
      "Training accuracy is  0.9921117872436331\n",
      "Epoch  5960 Loss  0.04635428264737129\n",
      "Training accuracy is  0.9769363684170986\n",
      "Epoch  5970 Loss  0.025377072393894196\n",
      "Training accuracy is  0.9919615355720832\n",
      "Epoch  5980 Loss  0.02154974266886711\n",
      "Training accuracy is  0.9918864097363083\n",
      "Epoch  5990 Loss  0.021504225209355354\n",
      "Training accuracy is  0.9910600255427842\n",
      "Epoch  6000 Loss  0.020621003583073616\n",
      "Training accuracy is  0.9906843963639096\n",
      "Epoch  6010 Loss  0.03454691171646118\n",
      "Training accuracy is  0.9852002103523402\n",
      "Epoch  6020 Loss  0.019251160323619843\n",
      "Training accuracy is  0.9930132972729322\n",
      "Epoch  6030 Loss  0.020097171887755394\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  6040 Loss  0.023798687383532524\n",
      "Training accuracy is  0.9916610322289835\n",
      "Epoch  6050 Loss  0.01857633888721466\n",
      "Training accuracy is  0.9915859063932086\n",
      "Epoch  6060 Loss  0.019268646836280823\n",
      "Training accuracy is  0.9924122905867327\n",
      "Epoch  6070 Loss  0.021056609228253365\n",
      "Training accuracy is  0.9927127939298325\n",
      "Epoch  6080 Loss  0.018430210649967194\n",
      "Training accuracy is  0.9924874164225077\n",
      "Epoch  6090 Loss  0.020302949473261833\n",
      "Training accuracy is  0.9903087671850349\n",
      "Epoch  6100 Loss  0.02729681506752968\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  6110 Loss  0.018016943708062172\n",
      "Training accuracy is  0.9916610322289835\n",
      "Epoch  6120 Loss  0.018606849014759064\n",
      "Training accuracy is  0.9926376680940575\n",
      "Epoch  6130 Loss  0.018901292234659195\n",
      "Training accuracy is  0.9929381714371572\n",
      "Epoch  6140 Loss  0.019184866920113564\n",
      "Training accuracy is  0.9918112839005334\n",
      "Epoch  6150 Loss  0.020701758563518524\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  6160 Loss  0.024825934320688248\n",
      "Training accuracy is  0.9908346480354594\n",
      "Epoch  6170 Loss  0.018363820388913155\n",
      "Training accuracy is  0.9915859063932086\n",
      "Epoch  6180 Loss  0.019237859174609184\n",
      "Training accuracy is  0.9923371647509579\n",
      "Epoch  6190 Loss  0.01830371469259262\n",
      "Training accuracy is  0.9926376680940575\n",
      "Epoch  6200 Loss  0.01993541046977043\n",
      "Training accuracy is  0.9919615355720832\n",
      "Epoch  6210 Loss  0.02130924165248871\n",
      "Training accuracy is  0.9898580121703854\n",
      "Epoch  6220 Loss  0.028360968455672264\n",
      "Training accuracy is  0.9896326346630606\n",
      "Epoch  6230 Loss  0.017562663182616234\n",
      "Training accuracy is  0.9918112839005334\n",
      "Epoch  6240 Loss  0.018131572753190994\n",
      "Training accuracy is  0.993088423108707\n",
      "Epoch  6250 Loss  0.03092191554605961\n",
      "Training accuracy is  0.9909848997070092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6260 Loss  0.01795375905930996\n",
      "Training accuracy is  0.9929381714371572\n",
      "Epoch  6270 Loss  0.01973334699869156\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  6280 Loss  0.03880027309060097\n",
      "Training accuracy is  0.979490646833446\n",
      "Epoch  6290 Loss  0.021986080333590508\n",
      "Training accuracy is  0.9927879197656074\n",
      "Epoch  6300 Loss  0.017364587634801865\n",
      "Training accuracy is  0.9933889264518068\n",
      "Epoch  6310 Loss  0.021661797538399696\n",
      "Training accuracy is  0.9903838930208099\n",
      "Epoch  6320 Loss  0.01733352057635784\n",
      "Training accuracy is  0.9922620389151829\n",
      "Epoch  6330 Loss  0.02065296098589897\n",
      "Training accuracy is  0.9926376680940575\n",
      "Epoch  6340 Loss  0.021059926599264145\n",
      "Training accuracy is  0.9899331380061603\n",
      "Epoch  6350 Loss  0.025987662374973297\n",
      "Training accuracy is  0.9909848997070092\n",
      "Epoch  6360 Loss  0.018148984760046005\n",
      "Training accuracy is  0.9910600255427842\n",
      "Epoch  6370 Loss  0.01906416192650795\n",
      "Training accuracy is  0.9929381714371572\n",
      "Epoch  6380 Loss  0.032049600034952164\n",
      "Training accuracy is  0.9897828863346104\n",
      "Epoch  6390 Loss  0.01700299046933651\n",
      "Training accuracy is  0.9933889264518068\n",
      "Epoch  6400 Loss  0.018819071352481842\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  6410 Loss  0.030521968379616737\n",
      "Training accuracy is  0.9891818796484111\n",
      "Epoch  6420 Loss  0.01658068224787712\n",
      "Training accuracy is  0.9924874164225077\n",
      "Epoch  6430 Loss  0.018038025125861168\n",
      "Training accuracy is  0.9933889264518068\n",
      "Epoch  6440 Loss  0.033504318445920944\n",
      "Training accuracy is  0.9889565021410863\n",
      "Epoch  6450 Loss  0.016512252390384674\n",
      "Training accuracy is  0.9934640522875817\n",
      "Epoch  6460 Loss  0.01846436597406864\n",
      "Training accuracy is  0.9909848997070092\n",
      "Epoch  6470 Loss  0.031031174585223198\n",
      "Training accuracy is  0.9889565021410863\n",
      "Epoch  6480 Loss  0.016315963119268417\n",
      "Training accuracy is  0.9929381714371572\n",
      "Epoch  6490 Loss  0.016771512106060982\n",
      "Training accuracy is  0.9936894297949065\n",
      "Epoch  6500 Loss  0.033392708748579025\n",
      "Training accuracy is  0.9906092705281346\n",
      "Epoch  6510 Loss  0.016541965305805206\n",
      "Training accuracy is  0.993238674780257\n",
      "Epoch  6520 Loss  0.01863187365233898\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  6530 Loss  0.0292658694088459\n",
      "Training accuracy is  0.9821951769213433\n",
      "Epoch  6540 Loss  0.020587271079421043\n",
      "Training accuracy is  0.9915107805574337\n",
      "Epoch  6550 Loss  0.01704447716474533\n",
      "Training accuracy is  0.9940650589737811\n",
      "Epoch  6560 Loss  0.03376763314008713\n",
      "Training accuracy is  0.9778378784463977\n",
      "Epoch  6570 Loss  0.021496828645467758\n",
      "Training accuracy is  0.9899331380061603\n",
      "Epoch  6580 Loss  0.017598319798707962\n",
      "Training accuracy is  0.9938396814664563\n",
      "Epoch  6590 Loss  0.03204002603888512\n",
      "Training accuracy is  0.9787393884756967\n",
      "Epoch  6600 Loss  0.024003492668271065\n",
      "Training accuracy is  0.9909848997070092\n",
      "Epoch  6610 Loss  0.015862563624978065\n",
      "Training accuracy is  0.9949665690030801\n",
      "Epoch  6620 Loss  0.026287121698260307\n",
      "Training accuracy is  0.9846743295019157\n",
      "Epoch  6630 Loss  0.01716100051999092\n",
      "Training accuracy is  0.9909097738712344\n",
      "Epoch  6640 Loss  0.01811032183468342\n",
      "Training accuracy is  0.9939148073022313\n",
      "Epoch  6650 Loss  0.0197282824665308\n",
      "Training accuracy is  0.9893321313199609\n",
      "Epoch  6660 Loss  0.02591089718043804\n",
      "Training accuracy is  0.9845992036661407\n",
      "Epoch  6670 Loss  0.01608709618449211\n",
      "Training accuracy is  0.9944406881526557\n",
      "Epoch  6680 Loss  0.016000021249055862\n",
      "Training accuracy is  0.9939148073022313\n",
      "Epoch  6690 Loss  0.0383097380399704\n",
      "Training accuracy is  0.9782886334610472\n",
      "Epoch  6700 Loss  0.02077324315905571\n",
      "Training accuracy is  0.9914356547216587\n",
      "Epoch  6710 Loss  0.01655944250524044\n",
      "Training accuracy is  0.994140184809556\n",
      "Epoch  6720 Loss  0.015042669139802456\n",
      "Training accuracy is  0.9937645556306814\n",
      "Epoch  6730 Loss  0.02348221279680729\n",
      "Training accuracy is  0.9775373751032981\n",
      "Epoch  6740 Loss  0.016524391248822212\n",
      "Training accuracy is  0.9934640522875817\n",
      "Epoch  6750 Loss  0.01580854505300522\n",
      "Training accuracy is  0.9948163173315303\n",
      "Epoch  6760 Loss  0.017263513058423996\n",
      "Training accuracy is  0.9919615355720832\n",
      "Epoch  6770 Loss  0.01522115059196949\n",
      "Training accuracy is  0.9946660656599805\n",
      "Epoch  6780 Loss  0.03473829850554466\n",
      "Training accuracy is  0.9773871234317482\n",
      "Epoch  6790 Loss  0.03590943664312363\n",
      "Training accuracy is  0.9830215611148674\n",
      "Epoch  6800 Loss  0.01661924459040165\n",
      "Training accuracy is  0.9948914431673053\n",
      "Epoch  6810 Loss  0.01615002751350403\n",
      "Training accuracy is  0.9947411914957554\n",
      "Epoch  6820 Loss  0.018681688234210014\n",
      "Training accuracy is  0.988280369619112\n",
      "Epoch  6830 Loss  0.01643747091293335\n",
      "Training accuracy is  0.9927127939298325\n",
      "Epoch  6840 Loss  0.014796347357332706\n",
      "Training accuracy is  0.9940650589737811\n",
      "Epoch  6850 Loss  0.0186684001237154\n",
      "Training accuracy is  0.9915107805574337\n",
      "Epoch  6860 Loss  0.020574213936924934\n",
      "Training accuracy is  0.9879798662760123\n",
      "Epoch  6870 Loss  0.014896603301167488\n",
      "Training accuracy is  0.9940650589737811\n",
      "Epoch  6880 Loss  0.01729470118880272\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  6890 Loss  0.01659434847533703\n",
      "Training accuracy is  0.9918112839005334\n",
      "Epoch  6900 Loss  0.025082863867282867\n",
      "Training accuracy is  0.9911351513785591\n",
      "Epoch  6910 Loss  0.014962666667997837\n",
      "Training accuracy is  0.9925625422582827\n",
      "Epoch  6920 Loss  0.01562931016087532\n",
      "Training accuracy is  0.9940650589737811\n",
      "Epoch  6930 Loss  0.02708689123392105\n",
      "Training accuracy is  0.9920366614078582\n",
      "Epoch  6940 Loss  0.016975004225969315\n",
      "Training accuracy is  0.9939899331380062\n",
      "Epoch  6950 Loss  0.024157091975212097\n",
      "Training accuracy is  0.986327097888964\n",
      "Epoch  6960 Loss  0.014519148506224155\n",
      "Training accuracy is  0.993163548944482\n",
      "Epoch  6970 Loss  0.0153523413464427\n",
      "Training accuracy is  0.9939148073022313\n",
      "Epoch  6980 Loss  0.04558335244655609\n",
      "Training accuracy is  0.9768612425813237\n",
      "Epoch  6990 Loss  0.019172580912709236\n",
      "Training accuracy is  0.9933889264518068\n",
      "Epoch  7000 Loss  0.014765871688723564\n",
      "Training accuracy is  0.993163548944482\n",
      "Epoch  7010 Loss  0.028479168191552162\n",
      "Training accuracy is  0.9849748328450154\n",
      "Epoch  7020 Loss  0.01745706982910633\n",
      "Training accuracy is  0.993163548944482\n",
      "Epoch  7030 Loss  0.016664354130625725\n",
      "Training accuracy is  0.9906092705281346\n",
      "Epoch  7040 Loss  0.014223739504814148\n",
      "Training accuracy is  0.9936143039591315\n",
      "Epoch  7050 Loss  0.018355611711740494\n",
      "Training accuracy is  0.993238674780257\n",
      "Epoch  7060 Loss  0.013899553567171097\n",
      "Training accuracy is  0.9954924498535046\n",
      "Epoch  7070 Loss  0.0386800616979599\n",
      "Training accuracy is  0.9774622492675231\n",
      "Epoch  7080 Loss  0.022648276761174202\n",
      "Training accuracy is  0.9923371647509579\n",
      "Epoch  7090 Loss  0.013848261907696724\n",
      "Training accuracy is  0.9953421981819548\n",
      "Epoch  7100 Loss  0.023371966555714607\n",
      "Training accuracy is  0.9896326346630606\n",
      "Epoch  7110 Loss  0.014036289416253567\n",
      "Training accuracy is  0.9955675756892796\n",
      "Epoch  7120 Loss  0.030454622581601143\n",
      "Training accuracy is  0.9791901434903463\n",
      "Epoch  7130 Loss  0.026642750948667526\n",
      "Training accuracy is  0.9912854030501089\n",
      "Epoch  7140 Loss  0.016189351677894592\n",
      "Training accuracy is  0.9935391781233566\n",
      "Epoch  7150 Loss  0.01732025109231472\n",
      "Training accuracy is  0.9918864097363083\n",
      "Epoch  7160 Loss  0.024602055549621582\n",
      "Training accuracy is  0.9852002103523402\n",
      "Epoch  7170 Loss  0.015155749395489693\n",
      "Training accuracy is  0.9935391781233566\n",
      "Epoch  7180 Loss  0.017105117440223694\n",
      "Training accuracy is  0.9917361580647585\n",
      "Epoch  7190 Loss  0.03831424564123154\n",
      "Training accuracy is  0.9776125009390729\n",
      "Epoch  7200 Loss  0.019242186099290848\n",
      "Training accuracy is  0.9947411914957554\n",
      "Epoch  7210 Loss  0.016406970098614693\n",
      "Training accuracy is  0.9939899331380062\n",
      "Epoch  7220 Loss  0.016635173931717873\n",
      "Training accuracy is  0.9908346480354594\n",
      "Epoch  7230 Loss  0.013846748508512974\n",
      "Training accuracy is  0.9946660656599805\n",
      "Epoch  7240 Loss  0.017124773934483528\n",
      "Training accuracy is  0.9947411914957554\n",
      "Epoch  7250 Loss  0.015163094736635685\n",
      "Training accuracy is  0.9926376680940575\n",
      "Epoch  7260 Loss  0.01308378204703331\n",
      "Training accuracy is  0.9955675756892796\n",
      "Epoch  7270 Loss  0.058122824877500534\n",
      "Training accuracy is  0.9847494553376906\n",
      "Epoch  7280 Loss  0.01966279186308384\n",
      "Training accuracy is  0.9871534820824882\n",
      "Epoch  7290 Loss  0.017643185332417488\n",
      "Training accuracy is  0.992186913079408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7300 Loss  0.01336634811013937\n",
      "Training accuracy is  0.9956427015250545\n",
      "Epoch  7310 Loss  0.013248204253613949\n",
      "Training accuracy is  0.9957929531966043\n",
      "Epoch  7320 Loss  0.025059010833501816\n",
      "Training accuracy is  0.9786642626399219\n",
      "Epoch  7330 Loss  0.017938395962119102\n",
      "Training accuracy is  0.994215310645331\n",
      "Epoch  7340 Loss  0.01605122908949852\n",
      "Training accuracy is  0.9938396814664563\n",
      "Epoch  7350 Loss  0.01397798303514719\n",
      "Training accuracy is  0.9944406881526557\n",
      "Epoch  7360 Loss  0.015217923559248447\n",
      "Training accuracy is  0.9955675756892796\n",
      "Epoch  7370 Loss  0.01539404597133398\n",
      "Training accuracy is  0.9936894297949065\n",
      "Epoch  7380 Loss  0.01570681296288967\n",
      "Training accuracy is  0.9915859063932086\n",
      "Epoch  7390 Loss  0.014217859134078026\n",
      "Training accuracy is  0.99511682067463\n",
      "Epoch  7400 Loss  0.0185158159583807\n",
      "Training accuracy is  0.9919615355720832\n",
      "Epoch  7410 Loss  0.013578959740698338\n",
      "Training accuracy is  0.9960183307039291\n",
      "Epoch  7420 Loss  0.03090345859527588\n",
      "Training accuracy is  0.9787393884756967\n",
      "Epoch  7430 Loss  0.03062860667705536\n",
      "Training accuracy is  0.9899331380061603\n",
      "Epoch  7440 Loss  0.015658775344491005\n",
      "Training accuracy is  0.9933889264518068\n",
      "Epoch  7450 Loss  0.015477500855922699\n",
      "Training accuracy is  0.9943655623168808\n",
      "Epoch  7460 Loss  0.018922269344329834\n",
      "Training accuracy is  0.9903087671850349\n",
      "Epoch  7470 Loss  0.013463594019412994\n",
      "Training accuracy is  0.9918864097363083\n",
      "Epoch  7480 Loss  0.017318375408649445\n",
      "Training accuracy is  0.9950416948388551\n",
      "Epoch  7490 Loss  0.012622231617569923\n",
      "Training accuracy is  0.9957929531966043\n",
      "Epoch  7500 Loss  0.028179988265037537\n",
      "Training accuracy is  0.980542408534295\n",
      "Epoch  7510 Loss  0.02354833483695984\n",
      "Training accuracy is  0.9871534820824882\n",
      "Epoch  7520 Loss  0.013144074939191341\n",
      "Training accuracy is  0.9938396814664563\n",
      "Epoch  7530 Loss  0.016051851212978363\n",
      "Training accuracy is  0.9942904364811058\n",
      "Epoch  7540 Loss  0.012436488643288612\n",
      "Training accuracy is  0.9956427015250545\n",
      "Epoch  7550 Loss  0.020784813910722733\n",
      "Training accuracy is  0.9834723161295169\n",
      "Epoch  7560 Loss  0.1218084916472435\n",
      "Training accuracy is  0.9834723161295169\n",
      "Epoch  7570 Loss  0.07001595944166183\n",
      "Training accuracy is  0.9787393884756967\n",
      "Epoch  7580 Loss  0.04401756823062897\n",
      "Training accuracy is  0.9752084741942754\n",
      "Epoch  7590 Loss  0.031073497608304024\n",
      "Training accuracy is  0.9821951769213433\n",
      "Epoch  7600 Loss  0.02714616246521473\n",
      "Training accuracy is  0.9884306212906618\n",
      "Epoch  7610 Loss  0.025189049541950226\n",
      "Training accuracy is  0.9924874164225077\n",
      "Epoch  7620 Loss  0.0224543996155262\n",
      "Training accuracy is  0.9930132972729322\n",
      "Epoch  7630 Loss  0.0212930329144001\n",
      "Training accuracy is  0.9943655623168808\n",
      "Epoch  7640 Loss  0.019990503787994385\n",
      "Training accuracy is  0.9950416948388551\n",
      "Epoch  7650 Loss  0.018972592428326607\n",
      "Training accuracy is  0.9948914431673053\n",
      "Epoch  7660 Loss  0.018050050362944603\n",
      "Training accuracy is  0.9949665690030801\n",
      "Epoch  7670 Loss  0.017227180302143097\n",
      "Training accuracy is  0.9952670723461798\n",
      "Epoch  7680 Loss  0.01645953580737114\n",
      "Training accuracy is  0.9954924498535046\n",
      "Epoch  7690 Loss  0.015781065449118614\n",
      "Training accuracy is  0.9956427015250545\n",
      "Epoch  7700 Loss  0.015147057361900806\n",
      "Training accuracy is  0.9956427015250545\n",
      "Epoch  7710 Loss  0.014520774595439434\n",
      "Training accuracy is  0.9956427015250545\n",
      "Epoch  7720 Loss  0.013938101939857006\n",
      "Training accuracy is  0.9956427015250545\n",
      "Epoch  7730 Loss  0.013462932780385017\n",
      "Training accuracy is  0.9959432048681541\n",
      "Epoch  7740 Loss  0.013194031082093716\n",
      "Training accuracy is  0.9954924498535046\n",
      "Epoch  7750 Loss  0.029145892709493637\n",
      "Training accuracy is  0.9915107805574337\n",
      "Epoch  7760 Loss  0.025715088471770287\n",
      "Training accuracy is  0.9872286079182631\n",
      "Epoch  7770 Loss  0.016269564628601074\n",
      "Training accuracy is  0.9924874164225077\n",
      "Epoch  7780 Loss  0.012783455662429333\n",
      "Training accuracy is  0.9952670723461798\n",
      "Epoch  7790 Loss  0.014752346090972424\n",
      "Training accuracy is  0.9956427015250545\n",
      "Epoch  7800 Loss  0.027005910873413086\n",
      "Training accuracy is  0.991210277214334\n",
      "Epoch  7810 Loss  0.02128666266798973\n",
      "Training accuracy is  0.9879047404402374\n",
      "Epoch  7820 Loss  0.01255076751112938\n",
      "Training accuracy is  0.9957929531966043\n",
      "Epoch  7830 Loss  0.031743865460157394\n",
      "Training accuracy is  0.9896326346630606\n",
      "Epoch  7840 Loss  0.021112803369760513\n",
      "Training accuracy is  0.9890316279768613\n",
      "Epoch  7850 Loss  0.012902108021080494\n",
      "Training accuracy is  0.9960183307039291\n",
      "Epoch  7860 Loss  0.027627581730484962\n",
      "Training accuracy is  0.9917361580647585\n",
      "Epoch  7870 Loss  0.02206241339445114\n",
      "Training accuracy is  0.9888062504695365\n",
      "Epoch  7880 Loss  0.01407673116773367\n",
      "Training accuracy is  0.9945909398242055\n",
      "Epoch  7890 Loss  0.01722189411520958\n",
      "Training accuracy is  0.9958680790323793\n",
      "Epoch  7900 Loss  0.013176276348531246\n",
      "Training accuracy is  0.9958680790323793\n",
      "Epoch  7910 Loss  0.016685662791132927\n",
      "Training accuracy is  0.9952670723461798\n",
      "Epoch  7920 Loss  0.01615607924759388\n",
      "Training accuracy is  0.9904590188565848\n",
      "Epoch  7930 Loss  0.012473958544433117\n",
      "Training accuracy is  0.9949665690030801\n",
      "Epoch  7940 Loss  0.012245241552591324\n",
      "Training accuracy is  0.9954924498535046\n",
      "Epoch  7950 Loss  0.014706057496368885\n",
      "Training accuracy is  0.9945158139884306\n",
      "Epoch  7960 Loss  0.012746055610477924\n",
      "Training accuracy is  0.9954924498535046\n",
      "Epoch  7970 Loss  0.013442656956613064\n",
      "Training accuracy is  0.9955675756892796\n",
      "Epoch  7980 Loss  0.01713416911661625\n",
      "Training accuracy is  0.99511682067463\n",
      "Epoch  7990 Loss  0.01988832838833332\n",
      "Training accuracy is  0.9935391781233566\n",
      "Epoch  8000 Loss  0.016798341646790504\n",
      "Training accuracy is  0.9908346480354594\n",
      "Epoch  8010 Loss  0.017977111041545868\n",
      "Training accuracy is  0.9938396814664563\n",
      "Epoch  8020 Loss  0.019148750230669975\n",
      "Training accuracy is  0.9924122905867327\n",
      "Epoch  8030 Loss  0.01988201029598713\n",
      "Training accuracy is  0.9918864097363083\n",
      "Epoch  8040 Loss  0.014786124229431152\n",
      "Training accuracy is  0.9957178273608294\n",
      "Epoch  8050 Loss  0.022591790184378624\n",
      "Training accuracy is  0.9838479453083916\n",
      "Epoch  8060 Loss  0.015477309934794903\n",
      "Training accuracy is  0.9934640522875817\n",
      "Epoch  8070 Loss  0.013626394793391228\n",
      "Training accuracy is  0.9936143039591315\n",
      "Epoch  8080 Loss  0.02063002996146679\n",
      "Training accuracy is  0.9894823829915108\n",
      "Epoch  8090 Loss  0.011602728627622128\n",
      "Training accuracy is  0.9962437082112539\n",
      "Epoch  8100 Loss  0.04769632965326309\n",
      "Training accuracy is  0.9753587258658253\n",
      "Epoch  8110 Loss  0.024933312088251114\n",
      "Training accuracy is  0.9904590188565848\n",
      "Epoch  8120 Loss  0.011890394613146782\n",
      "Training accuracy is  0.9948914431673053\n",
      "Epoch  8130 Loss  0.011557530611753464\n",
      "Training accuracy is  0.9961685823754789\n",
      "Epoch  8140 Loss  0.046660199761390686\n",
      "Training accuracy is  0.9762602358951243\n",
      "Epoch  8150 Loss  0.02630617842078209\n",
      "Training accuracy is  0.9891818796484111\n",
      "Epoch  8160 Loss  0.012756875716149807\n",
      "Training accuracy is  0.9964690857185786\n",
      "Epoch  8170 Loss  0.013656610623002052\n",
      "Training accuracy is  0.9949665690030801\n",
      "Epoch  8180 Loss  0.011387655511498451\n",
      "Training accuracy is  0.9961685823754789\n",
      "Epoch  8190 Loss  0.012467184104025364\n",
      "Training accuracy is  0.9908346480354594\n",
      "Epoch  8200 Loss  0.04916888847947121\n",
      "Training accuracy is  0.9950416948388551\n",
      "Epoch  8210 Loss  0.032833635807037354\n",
      "Training accuracy is  0.9874539854255878\n",
      "Epoch  8220 Loss  0.01814311556518078\n",
      "Training accuracy is  0.9902336413492601\n",
      "Epoch  8230 Loss  0.01299371663480997\n",
      "Training accuracy is  0.9942904364811058\n",
      "Epoch  8240 Loss  0.015302862972021103\n",
      "Training accuracy is  0.9945158139884306\n",
      "Epoch  8250 Loss  0.013187968172132969\n",
      "Training accuracy is  0.9957929531966043\n",
      "Epoch  8260 Loss  0.011731862090528011\n",
      "Training accuracy is  0.9963939598828037\n",
      "Epoch  8270 Loss  0.011561947874724865\n",
      "Training accuracy is  0.9964690857185786\n",
      "Epoch  8280 Loss  0.015545922331511974\n",
      "Training accuracy is  0.9897077604988356\n",
      "Epoch  8290 Loss  0.022473784163594246\n",
      "Training accuracy is  0.9829464352790925\n",
      "Epoch  8300 Loss  0.016974546015262604\n",
      "Training accuracy is  0.9954924498535046\n",
      "Epoch  8310 Loss  0.013028263114392757\n",
      "Training accuracy is  0.993238674780257\n",
      "Epoch  8320 Loss  0.01321677677333355\n",
      "Training accuracy is  0.9957178273608294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8330 Loss  0.030276035889983177\n",
      "Training accuracy is  0.9797911501765457\n",
      "Epoch  8340 Loss  0.0182131789624691\n",
      "Training accuracy is  0.9903838930208099\n",
      "Epoch  8350 Loss  0.015010900795459747\n",
      "Training accuracy is  0.9954924498535046\n",
      "Epoch  8360 Loss  0.01311680767685175\n",
      "Training accuracy is  0.9937645556306814\n",
      "Epoch  8370 Loss  0.015486226417124271\n",
      "Training accuracy is  0.9962437082112539\n",
      "Epoch  8380 Loss  0.01149218250066042\n",
      "Training accuracy is  0.9947411914957554\n",
      "Epoch  8390 Loss  0.012111927382647991\n",
      "Training accuracy is  0.9955675756892796\n",
      "Epoch  8400 Loss  0.02641999162733555\n",
      "Training accuracy is  0.9846743295019157\n",
      "Epoch  8410 Loss  0.01573779620230198\n",
      "Training accuracy is  0.9909097738712344\n",
      "Epoch  8420 Loss  0.015405365265905857\n",
      "Training accuracy is  0.9945158139884306\n",
      "Epoch  8430 Loss  0.011928548105061054\n",
      "Training accuracy is  0.9948163173315303\n",
      "Epoch  8440 Loss  0.02845548279583454\n",
      "Training accuracy is  0.9912854030501089\n",
      "Epoch  8450 Loss  0.011388160288333893\n",
      "Training accuracy is  0.9944406881526557\n",
      "Epoch  8460 Loss  0.015964945778250694\n",
      "Training accuracy is  0.9943655623168808\n",
      "Epoch  8470 Loss  0.013161920011043549\n",
      "Training accuracy is  0.9949665690030801\n",
      "Epoch  8480 Loss  0.01068587601184845\n",
      "Training accuracy is  0.9969949665690031\n",
      "Epoch  8490 Loss  0.01719154790043831\n",
      "Training accuracy is  0.9861768462174142\n",
      "Epoch  8500 Loss  0.01580345444381237\n",
      "Training accuracy is  0.9953421981819548\n",
      "Epoch  8510 Loss  0.01782871037721634\n",
      "Training accuracy is  0.9951919465104049\n",
      "Epoch  8520 Loss  0.014273026026785374\n",
      "Training accuracy is  0.9958680790323793\n",
      "Epoch  8530 Loss  0.012879217974841595\n",
      "Training accuracy is  0.9951919465104049\n",
      "Epoch  8540 Loss  0.011995472013950348\n",
      "Training accuracy is  0.9962437082112539\n",
      "Epoch  8550 Loss  0.011200587265193462\n",
      "Training accuracy is  0.9963939598828037\n",
      "Epoch  8560 Loss  0.014837105758488178\n",
      "Training accuracy is  0.9955675756892796\n",
      "Epoch  8570 Loss  0.0343962088227272\n",
      "Training accuracy is  0.9745323416723011\n",
      "Epoch  8580 Loss  0.04043615981936455\n",
      "Training accuracy is  0.9759597325520246\n",
      "Epoch  8590 Loss  0.06127587705850601\n",
      "Training accuracy is  0.9907595221996844\n",
      "Epoch  8600 Loss  0.02976558357477188\n",
      "Training accuracy is  0.9944406881526557\n",
      "Epoch  8610 Loss  0.018189547583460808\n",
      "Training accuracy is  0.9946660656599805\n",
      "Epoch  8620 Loss  0.014883163385093212\n",
      "Training accuracy is  0.99511682067463\n",
      "Epoch  8630 Loss  0.014852053485810757\n",
      "Training accuracy is  0.9963188340470288\n",
      "Epoch  8640 Loss  0.013742209412157536\n",
      "Training accuracy is  0.9966193373901284\n",
      "Epoch  8650 Loss  0.013279931619763374\n",
      "Training accuracy is  0.9966944632259034\n",
      "Epoch  8660 Loss  0.012793567031621933\n",
      "Training accuracy is  0.997070092404778\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 50)\n",
    "        self.fc4 = nn.Linear(50, 50)\n",
    "        self.fc5 = nn.Linear(50, 50)\n",
    "        self.fc6 = nn.Linear(50, 50)\n",
    "        self.fc7 = nn.Linear(50, 50)\n",
    "        self.fc8 = nn.Linear(50, 50)\n",
    "        self.fc9 = nn.Linear(50, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.relu(self.fc8(x))\n",
    "        x = self.fc9(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "#%% plot function\n",
    "        \n",
    "def plot_data(X, y, filename):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "        \n",
    "def plot_decision_boundary(clf, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    #x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    #y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    x_min, x_max = -1, 1\n",
    "    y_min, y_max = -1, 1\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    X_out = net(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype = torch.float))\n",
    "    Z = X_out.data.max(1)[1]\n",
    "    # Z.shape\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "\n",
    "#%% read data\n",
    "\n",
    "data = pd.read_csv('FeedForward_Data_hexa.csv')\n",
    "X = data.values[:, 0:2]  # Take only the first two features.     \n",
    "X = torch.tensor(X, dtype = torch.float)   \n",
    "y = data.values[:, 2]\n",
    "y = torch.tensor(y, dtype = torch.long)\n",
    "\n",
    "\n",
    "#%% train\n",
    "net = Net()\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = .01\n",
    "optimizer = torch.optim.Adam(net.parameters())# lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# create a loss function\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "nepochs = 10000\n",
    "data, target = X, y\n",
    "# run the main training loop\n",
    "for epoch in range(nepochs):\n",
    "#    adjust learning rate if desired\n",
    "#    if epoch % 3000 == 0 and epoch <= 24000:\n",
    "#        for g in optimizer.param_groups:\n",
    "#            g['lr'] = g['lr']/2\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagate\n",
    "    net_out = net(data)\n",
    "    # compute loss\n",
    "    loss = criterion(net_out, target)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # print out report\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correctidx = pred.eq(target.data) \n",
    "        ncorrect = correctidx.sum()\n",
    "        accuracy = ncorrect.item()/len(data)\n",
    "        print('Training accuracy is ', accuracy)\n",
    "    if accuracy > 0.997:\n",
    "        break\n",
    "\n",
    "#%%  plot outputs\n",
    "plot_decision_boundary(net, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 File Feedforward_Data_star.csv contains 13312 two-dimensional data points (feature values located in columns A and B) and their respective binary label (labels located in column C).  Create and train a network that separates the data.  Report your best cross-entropy and accuracy values.  Plot the decision boundaries of your best network by plotting the network outputs in a densely sampled region around.  Report the number of hidden layers, type of activation function and number of neurons per layer used.   [-1.0,1.0] x [-1.0,1.0].  (10 points).\n",
    "\n",
    "Best cross-entropy: 0.13\n",
    "\n",
    "Best accuracy value: 0.949\n",
    "\n",
    "Number of hidden layers: 6\n",
    "\n",
    "Type of activation function: Linear\n",
    "\n",
    "Number of neurons per layer used: 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jungmin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss  0.6769603490829468\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  10 Loss  0.5980677008628845\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  20 Loss  0.5290388464927673\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  30 Loss  0.5108305811882019\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  40 Loss  0.510145902633667\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  50 Loss  0.5105681419372559\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  60 Loss  0.5101805925369263\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  70 Loss  0.5098347663879395\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  80 Loss  0.5097181797027588\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  90 Loss  0.5096856355667114\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  100 Loss  0.5096631646156311\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  110 Loss  0.5096365213394165\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  120 Loss  0.5096092224121094\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  130 Loss  0.5095847249031067\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  140 Loss  0.5095651745796204\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  150 Loss  0.5095460414886475\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  160 Loss  0.509528398513794\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  170 Loss  0.5095071196556091\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  180 Loss  0.5094889998435974\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  190 Loss  0.5094723701477051\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  200 Loss  0.5094512104988098\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  210 Loss  0.5094326734542847\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  220 Loss  0.5094099044799805\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  230 Loss  0.5093854069709778\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  240 Loss  0.5093614459037781\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  250 Loss  0.5093366503715515\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  260 Loss  0.5093126893043518\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  270 Loss  0.5092869400978088\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  280 Loss  0.5092611908912659\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  290 Loss  0.5092360973358154\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  300 Loss  0.5092081427574158\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  310 Loss  0.5091798305511475\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  320 Loss  0.5091455578804016\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  330 Loss  0.5091120600700378\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  340 Loss  0.5090795755386353\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  350 Loss  0.5090452432632446\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  360 Loss  0.5090109705924988\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  370 Loss  0.5089724659919739\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  380 Loss  0.508933961391449\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  390 Loss  0.5088924765586853\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  400 Loss  0.5088469982147217\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  410 Loss  0.5087977051734924\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  420 Loss  0.5087503790855408\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  430 Loss  0.508693516254425\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  440 Loss  0.5086323618888855\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  450 Loss  0.508571982383728\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  460 Loss  0.508510410785675\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  470 Loss  0.5084440112113953\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  480 Loss  0.5083747506141663\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  490 Loss  0.5082995295524597\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  500 Loss  0.5082166790962219\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  510 Loss  0.5081292390823364\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  520 Loss  0.508037269115448\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  530 Loss  0.5079362392425537\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  540 Loss  0.5078272819519043\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  550 Loss  0.5077097415924072\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  560 Loss  0.5075782537460327\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  570 Loss  0.5074424743652344\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  580 Loss  0.5072856545448303\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  590 Loss  0.5071219801902771\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  600 Loss  0.5069418549537659\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  610 Loss  0.5067479014396667\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  620 Loss  0.5065315365791321\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  630 Loss  0.506298840045929\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  640 Loss  0.5060368180274963\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  650 Loss  0.5057399868965149\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  660 Loss  0.5054179430007935\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  670 Loss  0.505050003528595\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  680 Loss  0.504636287689209\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  690 Loss  0.5041349530220032\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  700 Loss  0.5035305023193359\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  710 Loss  0.5028871297836304\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  720 Loss  0.5021370053291321\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  730 Loss  0.5012720227241516\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  740 Loss  0.5002536773681641\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  750 Loss  0.49903371930122375\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  760 Loss  0.4975300133228302\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  770 Loss  0.4956248998641968\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  780 Loss  0.49314969778060913\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  790 Loss  0.4900924861431122\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  800 Loss  0.48652946949005127\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  810 Loss  0.4819510579109192\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  820 Loss  0.4759724736213684\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  830 Loss  0.46804922819137573\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  840 Loss  0.4574393928050995\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  850 Loss  0.443102091550827\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  860 Loss  0.4238109290599823\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  870 Loss  0.3988119959831238\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  880 Loss  0.37017276883125305\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  890 Loss  0.33996978402137756\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  900 Loss  0.3137701749801636\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  910 Loss  0.2933602035045624\n",
      "Training accuracy is  0.7930283224400871\n",
      "Epoch  920 Loss  0.2789818346500397\n",
      "Training accuracy is  0.879948914431673\n",
      "Epoch  930 Loss  0.2682158648967743\n",
      "Training accuracy is  0.8802494177747727\n",
      "Epoch  940 Loss  0.25999149680137634\n",
      "Training accuracy is  0.8783712718803997\n",
      "Epoch  950 Loss  0.25377383828163147\n",
      "Training accuracy is  0.8765682518218015\n",
      "Epoch  960 Loss  0.24901382625102997\n",
      "Training accuracy is  0.8754413642851777\n",
      "Epoch  970 Loss  0.245414137840271\n",
      "Training accuracy is  0.874089099241229\n",
      "Epoch  980 Loss  0.24267488718032837\n",
      "Training accuracy is  0.8727368341972804\n",
      "Epoch  990 Loss  0.24060097336769104\n",
      "Training accuracy is  0.8716850724964316\n",
      "Epoch  1000 Loss  0.23895807564258575\n",
      "Training accuracy is  0.8720607016753061\n",
      "Epoch  1010 Loss  0.2375992089509964\n",
      "Training accuracy is  0.8714596949891068\n",
      "Epoch  1020 Loss  0.23644578456878662\n",
      "Training accuracy is  0.8711591916460071\n",
      "Epoch  1030 Loss  0.2354787290096283\n",
      "Training accuracy is  0.8709338141386823\n",
      "Epoch  1040 Loss  0.2346409410238266\n",
      "Training accuracy is  0.8704830591240328\n",
      "Epoch  1050 Loss  0.2339199185371399\n",
      "Training accuracy is  0.870257681616708\n",
      "Epoch  1060 Loss  0.23330698907375336\n",
      "Training accuracy is  0.8704830591240328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1070 Loss  0.23277324438095093\n",
      "Training accuracy is  0.8706333107955826\n",
      "Epoch  1080 Loss  0.23229895532131195\n",
      "Training accuracy is  0.8705581849598076\n",
      "Epoch  1090 Loss  0.23186138272285461\n",
      "Training accuracy is  0.8703328074524829\n",
      "Epoch  1100 Loss  0.23145748674869537\n",
      "Training accuracy is  0.8704830591240328\n",
      "Epoch  1110 Loss  0.2310691475868225\n",
      "Training accuracy is  0.8705581849598076\n",
      "Epoch  1120 Loss  0.23071415722370148\n",
      "Training accuracy is  0.8708586883029074\n",
      "Epoch  1130 Loss  0.23040850460529327\n",
      "Training accuracy is  0.8706333107955826\n",
      "Epoch  1140 Loss  0.23013386130332947\n",
      "Training accuracy is  0.8705581849598076\n",
      "Epoch  1150 Loss  0.22988110780715942\n",
      "Training accuracy is  0.8704830591240328\n",
      "Epoch  1160 Loss  0.22965452075004578\n",
      "Training accuracy is  0.8704830591240328\n",
      "Epoch  1170 Loss  0.22944505512714386\n",
      "Training accuracy is  0.8704830591240328\n",
      "Epoch  1180 Loss  0.2292507290840149\n",
      "Training accuracy is  0.8704079332882578\n",
      "Epoch  1190 Loss  0.22907041013240814\n",
      "Training accuracy is  0.8704830591240328\n",
      "Epoch  1200 Loss  0.22889651358127594\n",
      "Training accuracy is  0.8707835624671324\n",
      "Epoch  1210 Loss  0.2287265509366989\n",
      "Training accuracy is  0.8707835624671324\n",
      "Epoch  1220 Loss  0.22855940461158752\n",
      "Training accuracy is  0.8708586883029074\n",
      "Epoch  1230 Loss  0.22839979827404022\n",
      "Training accuracy is  0.8710089399744572\n",
      "Epoch  1240 Loss  0.2282474786043167\n",
      "Training accuracy is  0.8710840658102321\n",
      "Epoch  1250 Loss  0.22809389233589172\n",
      "Training accuracy is  0.871234317481782\n",
      "Epoch  1260 Loss  0.2279466837644577\n",
      "Training accuracy is  0.8711591916460071\n",
      "Epoch  1270 Loss  0.2278003841638565\n",
      "Training accuracy is  0.8713845691533318\n",
      "Epoch  1280 Loss  0.22765447199344635\n",
      "Training accuracy is  0.8715348208248817\n",
      "Epoch  1290 Loss  0.2275090366601944\n",
      "Training accuracy is  0.8714596949891068\n",
      "Epoch  1300 Loss  0.2273586094379425\n",
      "Training accuracy is  0.8717601983322064\n",
      "Epoch  1310 Loss  0.22721058130264282\n",
      "Training accuracy is  0.8720607016753061\n",
      "Epoch  1320 Loss  0.2270628809928894\n",
      "Training accuracy is  0.8720607016753061\n",
      "Epoch  1330 Loss  0.2269231379032135\n",
      "Training accuracy is  0.8721358275110811\n",
      "Epoch  1340 Loss  0.22679835557937622\n",
      "Training accuracy is  0.8722109533468559\n",
      "Epoch  1350 Loss  0.2266811728477478\n",
      "Training accuracy is  0.8722109533468559\n",
      "Epoch  1360 Loss  0.22656653821468353\n",
      "Training accuracy is  0.8721358275110811\n",
      "Epoch  1370 Loss  0.2264532893896103\n",
      "Training accuracy is  0.8720607016753061\n",
      "Epoch  1380 Loss  0.226342111825943\n",
      "Training accuracy is  0.8719855758395312\n",
      "Epoch  1390 Loss  0.2262306660413742\n",
      "Training accuracy is  0.8719104500037563\n",
      "Epoch  1400 Loss  0.22612261772155762\n",
      "Training accuracy is  0.8718353241679814\n",
      "Epoch  1410 Loss  0.2260136604309082\n",
      "Training accuracy is  0.8719855758395312\n",
      "Epoch  1420 Loss  0.22590629756450653\n",
      "Training accuracy is  0.8721358275110811\n",
      "Epoch  1430 Loss  0.22579878568649292\n",
      "Training accuracy is  0.8721358275110811\n",
      "Epoch  1440 Loss  0.22569157183170319\n",
      "Training accuracy is  0.8721358275110811\n",
      "Epoch  1450 Loss  0.22558514773845673\n",
      "Training accuracy is  0.8722860791826309\n",
      "Epoch  1460 Loss  0.22547833621501923\n",
      "Training accuracy is  0.8722860791826309\n",
      "Epoch  1470 Loss  0.2253732681274414\n",
      "Training accuracy is  0.8722109533468559\n",
      "Epoch  1480 Loss  0.22526846826076508\n",
      "Training accuracy is  0.8722860791826309\n",
      "Epoch  1490 Loss  0.22516438364982605\n",
      "Training accuracy is  0.8722860791826309\n",
      "Epoch  1500 Loss  0.22506022453308105\n",
      "Training accuracy is  0.8722860791826309\n",
      "Epoch  1510 Loss  0.22495543956756592\n",
      "Training accuracy is  0.8722860791826309\n",
      "Epoch  1520 Loss  0.22484639286994934\n",
      "Training accuracy is  0.8722109533468559\n",
      "Epoch  1530 Loss  0.2247389405965805\n",
      "Training accuracy is  0.8722109533468559\n",
      "Epoch  1540 Loss  0.22463613748550415\n",
      "Training accuracy is  0.8722109533468559\n",
      "Epoch  1550 Loss  0.22453367710113525\n",
      "Training accuracy is  0.8722109533468559\n",
      "Epoch  1560 Loss  0.22443141043186188\n",
      "Training accuracy is  0.8722860791826309\n",
      "Epoch  1570 Loss  0.22432933747768402\n",
      "Training accuracy is  0.8722109533468559\n",
      "Epoch  1580 Loss  0.2242274135351181\n",
      "Training accuracy is  0.8722860791826309\n",
      "Epoch  1590 Loss  0.22412371635437012\n",
      "Training accuracy is  0.8723612050184059\n",
      "Epoch  1600 Loss  0.22402064502239227\n",
      "Training accuracy is  0.8723612050184059\n",
      "Epoch  1610 Loss  0.22391778230667114\n",
      "Training accuracy is  0.8723612050184059\n",
      "Epoch  1620 Loss  0.22381477057933807\n",
      "Training accuracy is  0.8723612050184059\n",
      "Epoch  1630 Loss  0.22371076047420502\n",
      "Training accuracy is  0.8726617083615055\n",
      "Epoch  1640 Loss  0.22360630333423615\n",
      "Training accuracy is  0.8725865825257306\n",
      "Epoch  1650 Loss  0.22350198030471802\n",
      "Training accuracy is  0.8726617083615055\n",
      "Epoch  1660 Loss  0.22339873015880585\n",
      "Training accuracy is  0.8727368341972804\n",
      "Epoch  1670 Loss  0.2232932448387146\n",
      "Training accuracy is  0.8727368341972804\n",
      "Epoch  1680 Loss  0.2231888324022293\n",
      "Training accuracy is  0.8727368341972804\n",
      "Epoch  1690 Loss  0.22308310866355896\n",
      "Training accuracy is  0.8727368341972804\n",
      "Epoch  1700 Loss  0.22297750413417816\n",
      "Training accuracy is  0.8728119600330554\n",
      "Epoch  1710 Loss  0.22287225723266602\n",
      "Training accuracy is  0.8728870858688302\n",
      "Epoch  1720 Loss  0.22276633977890015\n",
      "Training accuracy is  0.8730373375403802\n",
      "Epoch  1730 Loss  0.22265997529029846\n",
      "Training accuracy is  0.8731124633761551\n",
      "Epoch  1740 Loss  0.2225535809993744\n",
      "Training accuracy is  0.8733378408834799\n",
      "Epoch  1750 Loss  0.22244693338871002\n",
      "Training accuracy is  0.8734129667192547\n",
      "Epoch  1760 Loss  0.22233980894088745\n",
      "Training accuracy is  0.8735632183908046\n",
      "Epoch  1770 Loss  0.22223179042339325\n",
      "Training accuracy is  0.8734880925550297\n",
      "Epoch  1780 Loss  0.2221231460571289\n",
      "Training accuracy is  0.8737885958981294\n",
      "Epoch  1790 Loss  0.22201409935951233\n",
      "Training accuracy is  0.8735632183908046\n",
      "Epoch  1800 Loss  0.22190473973751068\n",
      "Training accuracy is  0.8736383442265795\n",
      "Epoch  1810 Loss  0.2217942625284195\n",
      "Training accuracy is  0.8735632183908046\n",
      "Epoch  1820 Loss  0.22168423235416412\n",
      "Training accuracy is  0.8736383442265795\n",
      "Epoch  1830 Loss  0.22157233953475952\n",
      "Training accuracy is  0.8736383442265795\n",
      "Epoch  1840 Loss  0.22145900130271912\n",
      "Training accuracy is  0.8737134700623544\n",
      "Epoch  1850 Loss  0.22134500741958618\n",
      "Training accuracy is  0.8736383442265795\n",
      "Epoch  1860 Loss  0.22122947871685028\n",
      "Training accuracy is  0.8737134700623544\n",
      "Epoch  1870 Loss  0.22111167013645172\n",
      "Training accuracy is  0.8739388475696792\n",
      "Epoch  1880 Loss  0.22099299728870392\n",
      "Training accuracy is  0.874089099241229\n",
      "Epoch  1890 Loss  0.2208745926618576\n",
      "Training accuracy is  0.874164225077004\n",
      "Epoch  1900 Loss  0.22075419127941132\n",
      "Training accuracy is  0.8742393509127789\n",
      "Epoch  1910 Loss  0.22063259780406952\n",
      "Training accuracy is  0.8743896025843287\n",
      "Epoch  1920 Loss  0.220509335398674\n",
      "Training accuracy is  0.8746901059274285\n",
      "Epoch  1930 Loss  0.22038520872592926\n",
      "Training accuracy is  0.8748403575989783\n",
      "Epoch  1940 Loss  0.22026006877422333\n",
      "Training accuracy is  0.8749906092705282\n",
      "Epoch  1950 Loss  0.22013330459594727\n",
      "Training accuracy is  0.875065735106303\n",
      "Epoch  1960 Loss  0.2200053334236145\n",
      "Training accuracy is  0.875140860942078\n",
      "Epoch  1970 Loss  0.21987558901309967\n",
      "Training accuracy is  0.875140860942078\n",
      "Epoch  1980 Loss  0.21974429488182068\n",
      "Training accuracy is  0.875140860942078\n",
      "Epoch  1990 Loss  0.21961018443107605\n",
      "Training accuracy is  0.875215986777853\n",
      "Epoch  2000 Loss  0.21947552263736725\n",
      "Training accuracy is  0.875140860942078\n",
      "Epoch  2010 Loss  0.2193378508090973\n",
      "Training accuracy is  0.875215986777853\n",
      "Epoch  2020 Loss  0.21919842064380646\n",
      "Training accuracy is  0.875065735106303\n",
      "Epoch  2030 Loss  0.21905657649040222\n",
      "Training accuracy is  0.8749906092705282\n",
      "Epoch  2040 Loss  0.21891236305236816\n",
      "Training accuracy is  0.875065735106303\n",
      "Epoch  2050 Loss  0.21876534819602966\n",
      "Training accuracy is  0.8749906092705282\n",
      "Epoch  2060 Loss  0.21861620247364044\n",
      "Training accuracy is  0.875140860942078\n",
      "Epoch  2070 Loss  0.21846449375152588\n",
      "Training accuracy is  0.875140860942078\n",
      "Epoch  2080 Loss  0.21830937266349792\n",
      "Training accuracy is  0.875140860942078\n",
      "Epoch  2090 Loss  0.2181522101163864\n",
      "Training accuracy is  0.8752911126136278\n",
      "Epoch  2100 Loss  0.21799138188362122\n",
      "Training accuracy is  0.8755916159567275\n",
      "Epoch  2110 Loss  0.2178301066160202\n",
      "Training accuracy is  0.8755916159567275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2120 Loss  0.2176651507616043\n",
      "Training accuracy is  0.8756667417925025\n",
      "Epoch  2130 Loss  0.21749639511108398\n",
      "Training accuracy is  0.8755916159567275\n",
      "Epoch  2140 Loss  0.21732652187347412\n",
      "Training accuracy is  0.8756667417925025\n",
      "Epoch  2150 Loss  0.2171531319618225\n",
      "Training accuracy is  0.8758921192998272\n",
      "Epoch  2160 Loss  0.21697764098644257\n",
      "Training accuracy is  0.876042370971377\n",
      "Epoch  2170 Loss  0.21679888665676117\n",
      "Training accuracy is  0.8764931259860266\n",
      "Epoch  2180 Loss  0.216617614030838\n",
      "Training accuracy is  0.8768687551649013\n",
      "Epoch  2190 Loss  0.21643269062042236\n",
      "Training accuracy is  0.8771692585080009\n",
      "Epoch  2200 Loss  0.21624454855918884\n",
      "Training accuracy is  0.8774697618511006\n",
      "Epoch  2210 Loss  0.21605335175991058\n",
      "Training accuracy is  0.8775448876868756\n",
      "Epoch  2220 Loss  0.21585838496685028\n",
      "Training accuracy is  0.8775448876868756\n",
      "Epoch  2230 Loss  0.21566016972064972\n",
      "Training accuracy is  0.8774697618511006\n",
      "Epoch  2240 Loss  0.21545842289924622\n",
      "Training accuracy is  0.8775448876868756\n",
      "Epoch  2250 Loss  0.2152530699968338\n",
      "Training accuracy is  0.8778453910299752\n",
      "Epoch  2260 Loss  0.21504761278629303\n",
      "Training accuracy is  0.8779205168657501\n",
      "Epoch  2270 Loss  0.2148313671350479\n",
      "Training accuracy is  0.8776200135226504\n",
      "Epoch  2280 Loss  0.21468693017959595\n",
      "Training accuracy is  0.8769438810006761\n",
      "Epoch  2290 Loss  0.21563072502613068\n",
      "Training accuracy is  0.8718353241679814\n",
      "Epoch  2300 Loss  0.22153690457344055\n",
      "Training accuracy is  0.8645481180978138\n",
      "Epoch  2310 Loss  0.21411743760108948\n",
      "Training accuracy is  0.8801742919389978\n",
      "Epoch  2320 Loss  0.22685660421848297\n",
      "Training accuracy is  0.8918939223198858\n",
      "Epoch  2330 Loss  0.21729646623134613\n",
      "Training accuracy is  0.8658252573059876\n",
      "Epoch  2340 Loss  0.21421407163143158\n",
      "Training accuracy is  0.8825783186837953\n",
      "Epoch  2350 Loss  0.214985653758049\n",
      "Training accuracy is  0.881902186161821\n",
      "Epoch  2360 Loss  0.21371443569660187\n",
      "Training accuracy is  0.8755916159567275\n",
      "Epoch  2370 Loss  0.2389586716890335\n",
      "Training accuracy is  0.8547817594470738\n",
      "Epoch  2380 Loss  0.21653518080711365\n",
      "Training accuracy is  0.8817519344902712\n",
      "Epoch  2390 Loss  0.21320873498916626\n",
      "Training accuracy is  0.882052437833371\n",
      "Epoch  2400 Loss  0.21321557462215424\n",
      "Training accuracy is  0.8810758019682969\n",
      "Epoch  2410 Loss  0.21580614149570465\n",
      "Training accuracy is  0.8690556682443092\n",
      "Epoch  2420 Loss  0.22008788585662842\n",
      "Training accuracy is  0.8674780256930358\n",
      "Epoch  2430 Loss  0.21663925051689148\n",
      "Training accuracy is  0.8871609946660657\n",
      "Epoch  2440 Loss  0.2145960032939911\n",
      "Training accuracy is  0.8826534445195703\n",
      "Epoch  2450 Loss  0.21849489212036133\n",
      "Training accuracy is  0.8651491247840132\n",
      "Epoch  2460 Loss  0.21352413296699524\n",
      "Training accuracy is  0.8753662384494028\n",
      "Epoch  2470 Loss  0.2128700315952301\n",
      "Training accuracy is  0.8846818420854932\n",
      "Epoch  2480 Loss  0.2223045974969864\n",
      "Training accuracy is  0.8845315904139434\n",
      "Epoch  2490 Loss  0.21387292444705963\n",
      "Training accuracy is  0.8862594846367666\n",
      "Epoch  2500 Loss  0.2151329517364502\n",
      "Training accuracy is  0.869281045751634\n",
      "Epoch  2510 Loss  0.21261803805828094\n",
      "Training accuracy is  0.8846818420854932\n",
      "Epoch  2520 Loss  0.21375714242458344\n",
      "Training accuracy is  0.8841559612350688\n",
      "Epoch  2530 Loss  0.22859323024749756\n",
      "Training accuracy is  0.8925700548418601\n",
      "Epoch  2540 Loss  0.2170834094285965\n",
      "Training accuracy is  0.8643227405904891\n",
      "Epoch  2550 Loss  0.21098069846630096\n",
      "Training accuracy is  0.8832544512057696\n",
      "Epoch  2560 Loss  0.21992908418178558\n",
      "Training accuracy is  0.8914431673052363\n",
      "Epoch  2570 Loss  0.21082419157028198\n",
      "Training accuracy is  0.8772443843437758\n",
      "Epoch  2580 Loss  0.22962605953216553\n",
      "Training accuracy is  0.8560588986552475\n",
      "Epoch  2590 Loss  0.21872878074645996\n",
      "Training accuracy is  0.8909924122905868\n",
      "Epoch  2600 Loss  0.21208073198795319\n",
      "Training accuracy is  0.8728870858688302\n",
      "Epoch  2610 Loss  0.21360507607460022\n",
      "Training accuracy is  0.8737134700623544\n",
      "Epoch  2620 Loss  0.21055318415164948\n",
      "Training accuracy is  0.8848320937570431\n",
      "Epoch  2630 Loss  0.2349175363779068\n",
      "Training accuracy is  0.8931710615280595\n",
      "Epoch  2640 Loss  0.21052612364292145\n",
      "Training accuracy is  0.882878822026895\n",
      "Epoch  2650 Loss  0.20986658334732056\n",
      "Training accuracy is  0.8773195101795508\n",
      "Epoch  2660 Loss  0.21115171909332275\n",
      "Training accuracy is  0.8777702651942003\n",
      "Epoch  2670 Loss  0.21094311773777008\n",
      "Training accuracy is  0.8866351138156412\n",
      "Epoch  2680 Loss  0.21642139554023743\n",
      "Training accuracy is  0.8849072195928179\n",
      "Epoch  2690 Loss  0.21010784804821014\n",
      "Training accuracy is  0.8865599879798662\n",
      "Epoch  2700 Loss  0.21003590524196625\n",
      "Training accuracy is  0.8752911126136278\n",
      "Epoch  2710 Loss  0.20923979580402374\n",
      "Training accuracy is  0.8813011794756217\n",
      "Epoch  2720 Loss  0.21396282315254211\n",
      "Training accuracy is  0.8922695514987604\n",
      "Epoch  2730 Loss  0.20976464450359344\n",
      "Training accuracy is  0.8697318007662835\n",
      "Epoch  2740 Loss  0.2129015177488327\n",
      "Training accuracy is  0.8906167831117121\n",
      "Epoch  2750 Loss  0.21048162877559662\n",
      "Training accuracy is  0.8734880925550297\n",
      "Epoch  2760 Loss  0.2101651281118393\n",
      "Training accuracy is  0.8775448876868756\n",
      "Epoch  2770 Loss  0.2077820897102356\n",
      "Training accuracy is  0.8840808353992938\n",
      "Epoch  2780 Loss  0.2169744372367859\n",
      "Training accuracy is  0.8899406505897378\n",
      "Epoch  2790 Loss  0.22730706632137299\n",
      "Training accuracy is  0.8725114566899557\n",
      "Epoch  2800 Loss  0.21112783253192902\n",
      "Training accuracy is  0.8831793253699948\n",
      "Epoch  2810 Loss  0.2087063044309616\n",
      "Training accuracy is  0.8842310870708436\n",
      "Epoch  2820 Loss  0.20914030075073242\n",
      "Training accuracy is  0.8782210202088498\n",
      "Epoch  2830 Loss  0.20777884125709534\n",
      "Training accuracy is  0.8858838554578919\n",
      "Epoch  2840 Loss  0.2077430635690689\n",
      "Training accuracy is  0.8783712718803997\n",
      "Epoch  2850 Loss  0.2278548777103424\n",
      "Training accuracy is  0.8646232439335888\n",
      "Epoch  2860 Loss  0.20712311565876007\n",
      "Training accuracy is  0.8812260536398467\n",
      "Epoch  2870 Loss  0.20661211013793945\n",
      "Training accuracy is  0.8861843588009917\n",
      "Epoch  2880 Loss  0.2105177342891693\n",
      "Training accuracy is  0.8900157764255128\n",
      "Epoch  2890 Loss  0.20657563209533691\n",
      "Training accuracy is  0.8861092329652167\n",
      "Epoch  2900 Loss  0.2544037103652954\n",
      "Training accuracy is  0.8797235369243482\n",
      "Epoch  2910 Loss  0.20673593878746033\n",
      "Training accuracy is  0.8885132597100143\n",
      "Epoch  2920 Loss  0.21082846820354462\n",
      "Training accuracy is  0.876042370971377\n",
      "Epoch  2930 Loss  0.20774371922016144\n",
      "Training accuracy is  0.8865599879798662\n",
      "Epoch  2940 Loss  0.20868560671806335\n",
      "Training accuracy is  0.875065735106303\n",
      "Epoch  2950 Loss  0.21814991533756256\n",
      "Training accuracy is  0.8662760123206371\n",
      "Epoch  2960 Loss  0.2083054929971695\n",
      "Training accuracy is  0.8915182931410112\n",
      "Epoch  2970 Loss  0.20885926485061646\n",
      "Training accuracy is  0.8874614980091654\n",
      "Epoch  2980 Loss  0.21185624599456787\n",
      "Training accuracy is  0.87318758921193\n",
      "Epoch  2990 Loss  0.20829841494560242\n",
      "Training accuracy is  0.8914431673052363\n",
      "Epoch  3000 Loss  0.21047651767730713\n",
      "Training accuracy is  0.8905416572759371\n",
      "Epoch  3010 Loss  0.21474787592887878\n",
      "Training accuracy is  0.8639471114116144\n",
      "Epoch  3020 Loss  0.20496083796024323\n",
      "Training accuracy is  0.8901660280970626\n",
      "Epoch  3030 Loss  0.21076364815235138\n",
      "Training accuracy is  0.8917436706483359\n",
      "Epoch  3040 Loss  0.20516425371170044\n",
      "Training accuracy is  0.8795732852527984\n",
      "Epoch  3050 Loss  0.21575859189033508\n",
      "Training accuracy is  0.8794981594170235\n",
      "Epoch  3060 Loss  0.20430858433246613\n",
      "Training accuracy is  0.8798737885958982\n",
      "Epoch  3070 Loss  0.20413267612457275\n",
      "Training accuracy is  0.8896401472466381\n",
      "Epoch  3080 Loss  0.2101747840642929\n",
      "Training accuracy is  0.8931710615280595\n",
      "Epoch  3090 Loss  0.2045251876115799\n",
      "Training accuracy is  0.8906167831117121\n",
      "Epoch  3100 Loss  0.24036525189876556\n",
      "Training accuracy is  0.8912929156336864\n",
      "Epoch  3110 Loss  0.2035326361656189\n",
      "Training accuracy is  0.8903914056043873\n",
      "Epoch  3120 Loss  0.2056429237127304\n",
      "Training accuracy is  0.8781458943730749\n",
      "Epoch  3130 Loss  0.20282573997974396\n",
      "Training accuracy is  0.888738637217339\n",
      "Epoch  3140 Loss  0.22487017512321472\n",
      "Training accuracy is  0.8874614980091654\n",
      "Epoch  3150 Loss  0.21192680299282074\n",
      "Training accuracy is  0.8669521448426114\n",
      "Epoch  3160 Loss  0.20649322867393494\n",
      "Training accuracy is  0.8933213131996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3170 Loss  0.2061011642217636\n",
      "Training accuracy is  0.8921944256629855\n",
      "Epoch  3180 Loss  0.2057255655527115\n",
      "Training accuracy is  0.893621816542709\n",
      "Epoch  3190 Loss  0.20306865870952606\n",
      "Training accuracy is  0.8726617083615055\n",
      "Epoch  3200 Loss  0.2104777693748474\n",
      "Training accuracy is  0.8938471940500338\n",
      "Epoch  3210 Loss  0.20609773695468903\n",
      "Training accuracy is  0.8761926226429269\n",
      "Epoch  3220 Loss  0.2023521363735199\n",
      "Training accuracy is  0.8825783186837953\n",
      "Epoch  3230 Loss  0.23214581608772278\n",
      "Training accuracy is  0.8520021035234017\n",
      "Epoch  3240 Loss  0.21033063530921936\n",
      "Training accuracy is  0.8938471940500338\n",
      "Epoch  3250 Loss  0.20975729823112488\n",
      "Training accuracy is  0.8721358275110811\n",
      "Epoch  3260 Loss  0.20142951607704163\n",
      "Training accuracy is  0.8916685448125611\n",
      "Epoch  3270 Loss  0.21669714152812958\n",
      "Training accuracy is  0.8937720682142589\n",
      "Epoch  3280 Loss  0.2062632143497467\n",
      "Training accuracy is  0.8794230335812486\n",
      "Epoch  3290 Loss  0.20640712976455688\n",
      "Training accuracy is  0.8944482007362332\n",
      "Epoch  3300 Loss  0.2003396898508072\n",
      "Training accuracy is  0.8870107429945158\n",
      "Epoch  3310 Loss  0.20970997214317322\n",
      "Training accuracy is  0.8739388475696792\n",
      "Epoch  3320 Loss  0.20238593220710754\n",
      "Training accuracy is  0.8935466907069342\n",
      "Epoch  3330 Loss  0.2020917385816574\n",
      "Training accuracy is  0.8885883855457892\n",
      "Epoch  3340 Loss  0.1992974877357483\n",
      "Training accuracy is  0.8900909022612876\n",
      "Epoch  3350 Loss  0.20991770923137665\n",
      "Training accuracy is  0.8945233265720081\n",
      "Epoch  3360 Loss  0.19908644258975983\n",
      "Training accuracy is  0.8894147697393133\n",
      "Epoch  3370 Loss  0.23075637221336365\n",
      "Training accuracy is  0.8818270603260461\n",
      "Epoch  3380 Loss  0.20670853555202484\n",
      "Training accuracy is  0.8864097363083164\n",
      "Epoch  3390 Loss  0.2041516900062561\n",
      "Training accuracy is  0.875215986777853\n",
      "Epoch  3400 Loss  0.20269383490085602\n",
      "Training accuracy is  0.8934715648711592\n",
      "Epoch  3410 Loss  0.19801677763462067\n",
      "Training accuracy is  0.8891893922319886\n",
      "Epoch  3420 Loss  0.23290561139583588\n",
      "Training accuracy is  0.8467432950191571\n",
      "Epoch  3430 Loss  0.20531386137008667\n",
      "Training accuracy is  0.8899406505897378\n",
      "Epoch  3440 Loss  0.2022733986377716\n",
      "Training accuracy is  0.8933964390353842\n",
      "Epoch  3450 Loss  0.2016405463218689\n",
      "Training accuracy is  0.8814514311471715\n",
      "Epoch  3460 Loss  0.19787615537643433\n",
      "Training accuracy is  0.8876868755164902\n",
      "Epoch  3470 Loss  0.23927025496959686\n",
      "Training accuracy is  0.8495980767786042\n",
      "Epoch  3480 Loss  0.20100480318069458\n",
      "Training accuracy is  0.8903162797686124\n",
      "Epoch  3490 Loss  0.19730153679847717\n",
      "Training accuracy is  0.8893396439035385\n",
      "Epoch  3500 Loss  0.20114822685718536\n",
      "Training accuracy is  0.893621816542709\n",
      "Epoch  3510 Loss  0.20941831171512604\n",
      "Training accuracy is  0.8949740815866577\n",
      "Epoch  3520 Loss  0.19687671959400177\n",
      "Training accuracy is  0.8912177897979116\n",
      "Epoch  3530 Loss  0.21251699328422546\n",
      "Training accuracy is  0.8529036135527007\n",
      "Epoch  3540 Loss  0.21586334705352783\n",
      "Training accuracy is  0.895575088272857\n",
      "Epoch  3550 Loss  0.19648268818855286\n",
      "Training accuracy is  0.8918939223198858\n",
      "Epoch  3560 Loss  0.19703832268714905\n",
      "Training accuracy is  0.8870107429945158\n",
      "Epoch  3570 Loss  0.2028868943452835\n",
      "Training accuracy is  0.8797235369243482\n",
      "Epoch  3580 Loss  0.20134656131267548\n",
      "Training accuracy is  0.8780707685372999\n",
      "Epoch  3590 Loss  0.20340992510318756\n",
      "Training accuracy is  0.8846818420854932\n",
      "Epoch  3600 Loss  0.2098175585269928\n",
      "Training accuracy is  0.8953497107655323\n",
      "Epoch  3610 Loss  0.19681696593761444\n",
      "Training accuracy is  0.8854331004432424\n",
      "Epoch  3620 Loss  0.20620816946029663\n",
      "Training accuracy is  0.8827285703553452\n",
      "Epoch  3630 Loss  0.20479531586170197\n",
      "Training accuracy is  0.8954999624370821\n",
      "Epoch  3640 Loss  0.1958794891834259\n",
      "Training accuracy is  0.8939223198858087\n",
      "Epoch  3650 Loss  0.23449614644050598\n",
      "Training accuracy is  0.8843062129066186\n",
      "Epoch  3660 Loss  0.20200322568416595\n",
      "Training accuracy is  0.888813763053114\n",
      "Epoch  3670 Loss  0.19481928646564484\n",
      "Training accuracy is  0.8906919089474871\n",
      "Epoch  3680 Loss  0.19759252667427063\n",
      "Training accuracy is  0.887762001352265\n",
      "Epoch  3690 Loss  0.21063265204429626\n",
      "Training accuracy is  0.857561415370746\n",
      "Epoch  3700 Loss  0.19823212921619415\n",
      "Training accuracy is  0.8950492074224325\n",
      "Epoch  3710 Loss  0.1941991150379181\n",
      "Training accuracy is  0.8928705581849599\n",
      "Epoch  3720 Loss  0.19809362292289734\n",
      "Training accuracy is  0.874089099241229\n",
      "Epoch  3730 Loss  0.20048481225967407\n",
      "Training accuracy is  0.8961009691232815\n",
      "Epoch  3740 Loss  0.19701196253299713\n",
      "Training accuracy is  0.8918939223198858\n",
      "Epoch  3750 Loss  0.19351644814014435\n",
      "Training accuracy is  0.8900157764255128\n",
      "Epoch  3760 Loss  0.19360940158367157\n",
      "Training accuracy is  0.8915182931410112\n",
      "Epoch  3770 Loss  0.21384328603744507\n",
      "Training accuracy is  0.8523026068665014\n",
      "Epoch  3780 Loss  0.20762187242507935\n",
      "Training accuracy is  0.8954248366013072\n",
      "Epoch  3790 Loss  0.20193226635456085\n",
      "Training accuracy is  0.8805499211178724\n",
      "Epoch  3800 Loss  0.19605569541454315\n",
      "Training accuracy is  0.8949740815866577\n",
      "Epoch  3810 Loss  0.20274360477924347\n",
      "Training accuracy is  0.8958755916159568\n",
      "Epoch  3820 Loss  0.20329348742961884\n",
      "Training accuracy is  0.8640222372473894\n",
      "Epoch  3830 Loss  0.19209909439086914\n",
      "Training accuracy is  0.8952745849297573\n",
      "Epoch  3840 Loss  0.19516092538833618\n",
      "Training accuracy is  0.8953497107655323\n",
      "Epoch  3850 Loss  0.1998787373304367\n",
      "Training accuracy is  0.8958755916159568\n",
      "Epoch  3860 Loss  0.1931794434785843\n",
      "Training accuracy is  0.882878822026895\n",
      "Epoch  3870 Loss  0.19449196755886078\n",
      "Training accuracy is  0.8964014724663812\n",
      "Epoch  3880 Loss  0.19086189568042755\n",
      "Training accuracy is  0.8949740815866577\n",
      "Epoch  3890 Loss  0.23203244805335999\n",
      "Training accuracy is  0.8479453083915559\n",
      "Epoch  3900 Loss  0.19494947791099548\n",
      "Training accuracy is  0.8962512207948313\n",
      "Epoch  3910 Loss  0.1910833716392517\n",
      "Training accuracy is  0.8970024791525806\n",
      "Epoch  3920 Loss  0.18980060517787933\n",
      "Training accuracy is  0.893696942378484\n",
      "Epoch  3930 Loss  0.23055511713027954\n",
      "Training accuracy is  0.8511005934941026\n",
      "Epoch  3940 Loss  0.19170153141021729\n",
      "Training accuracy is  0.8967019758094809\n",
      "Epoch  3950 Loss  0.19297879934310913\n",
      "Training accuracy is  0.8927954323491849\n",
      "Epoch  3960 Loss  0.20087452232837677\n",
      "Training accuracy is  0.8961009691232815\n",
      "Epoch  3970 Loss  0.18906457722187042\n",
      "Training accuracy is  0.893621816542709\n",
      "Epoch  3980 Loss  0.20304954051971436\n",
      "Training accuracy is  0.8734880925550297\n",
      "Epoch  3990 Loss  0.1953059583902359\n",
      "Training accuracy is  0.8973781083314551\n",
      "Epoch  4000 Loss  0.1912609338760376\n",
      "Training accuracy is  0.8967019758094809\n",
      "Epoch  4010 Loss  0.19250492751598358\n",
      "Training accuracy is  0.8919690481556607\n",
      "Epoch  4020 Loss  0.18918362259864807\n",
      "Training accuracy is  0.8924198031703102\n",
      "Epoch  4030 Loss  0.19488385319709778\n",
      "Training accuracy is  0.895575088272857\n",
      "Epoch  4040 Loss  0.20137876272201538\n",
      "Training accuracy is  0.8764931259860266\n",
      "Epoch  4050 Loss  0.18877027928829193\n",
      "Training accuracy is  0.8961760949590564\n",
      "Epoch  4060 Loss  0.18883168697357178\n",
      "Training accuracy is  0.8943730749004583\n",
      "Epoch  4070 Loss  0.1894671767950058\n",
      "Training accuracy is  0.8876117496807152\n",
      "Epoch  4080 Loss  0.19624005258083344\n",
      "Training accuracy is  0.8960258432875066\n",
      "Epoch  4090 Loss  0.18774615228176117\n",
      "Training accuracy is  0.8989557508827286\n",
      "Epoch  4100 Loss  0.19281995296478271\n",
      "Training accuracy is  0.8909924122905868\n",
      "Epoch  4110 Loss  0.19084930419921875\n",
      "Training accuracy is  0.8981293666892044\n",
      "Epoch  4120 Loss  0.19827212393283844\n",
      "Training accuracy is  0.8973781083314551\n",
      "Epoch  4130 Loss  0.18764597177505493\n",
      "Training accuracy is  0.8900157764255128\n",
      "Epoch  4140 Loss  0.1861095428466797\n",
      "Training accuracy is  0.8986552475396289\n",
      "Epoch  4150 Loss  0.20759688317775726\n",
      "Training accuracy is  0.8911426639621366\n",
      "Epoch  4160 Loss  0.1956389993429184\n",
      "Training accuracy is  0.8701825557809331\n",
      "Epoch  4170 Loss  0.1857810765504837\n",
      "Training accuracy is  0.8990308767185035\n",
      "Epoch  4180 Loss  0.21495701372623444\n",
      "Training accuracy is  0.8930959356922846\n",
      "Epoch  4190 Loss  0.19922968745231628\n",
      "Training accuracy is  0.8655247539628879\n",
      "Epoch  4200 Loss  0.18562465906143188\n",
      "Training accuracy is  0.8982796183607543\n",
      "Epoch  4210 Loss  0.20761516690254211\n",
      "Training accuracy is  0.8861092329652167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4220 Loss  0.20261256396770477\n",
      "Training accuracy is  0.8895650214108632\n",
      "Epoch  4230 Loss  0.1899256706237793\n",
      "Training accuracy is  0.883930583727744\n",
      "Epoch  4240 Loss  0.18817035853862762\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  4250 Loss  0.1864091157913208\n",
      "Training accuracy is  0.893621816542709\n",
      "Epoch  4260 Loss  0.18842045962810516\n",
      "Training accuracy is  0.8987303733754038\n",
      "Epoch  4270 Loss  0.19450554251670837\n",
      "Training accuracy is  0.8792727819096987\n",
      "Epoch  4280 Loss  0.18779315054416656\n",
      "Training accuracy is  0.8994065058973781\n",
      "Epoch  4290 Loss  0.18893301486968994\n",
      "Training accuracy is  0.8834798287130944\n",
      "Epoch  4300 Loss  0.18861569464206696\n",
      "Training accuracy is  0.8994065058973781\n",
      "Epoch  4310 Loss  0.18775032460689545\n",
      "Training accuracy is  0.8996318834047029\n",
      "Epoch  4320 Loss  0.18330168724060059\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  4330 Loss  0.20400302112102509\n",
      "Training accuracy is  0.8568101570129968\n",
      "Epoch  4340 Loss  0.1875477433204651\n",
      "Training accuracy is  0.900533393434002\n",
      "Epoch  4350 Loss  0.18764737248420715\n",
      "Training accuracy is  0.9015851551348508\n",
      "Epoch  4360 Loss  0.18511638045310974\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  4370 Loss  0.18568114936351776\n",
      "Training accuracy is  0.8691307940800841\n",
      "Epoch  4380 Loss  0.18290306627750397\n",
      "Training accuracy is  0.8997821350762527\n",
      "Epoch  4390 Loss  0.1871366947889328\n",
      "Training accuracy is  0.9018105326421757\n",
      "Epoch  4400 Loss  0.18648889660835266\n",
      "Training accuracy is  0.888813763053114\n",
      "Epoch  4410 Loss  0.19223959743976593\n",
      "Training accuracy is  0.8880625046953647\n",
      "Epoch  4420 Loss  0.18258805572986603\n",
      "Training accuracy is  0.9021110359852753\n",
      "Epoch  4430 Loss  0.18550269305706024\n",
      "Training accuracy is  0.8657501314702126\n",
      "Epoch  4440 Loss  0.18214799463748932\n",
      "Training accuracy is  0.8957253399444068\n",
      "Epoch  4450 Loss  0.1848783791065216\n",
      "Training accuracy is  0.9023364134926001\n",
      "Epoch  4460 Loss  0.18182244896888733\n",
      "Training accuracy is  0.9028622943430246\n",
      "Epoch  4470 Loss  0.1812351793050766\n",
      "Training accuracy is  0.9025617909999248\n",
      "Epoch  4480 Loss  0.1837134063243866\n",
      "Training accuracy is  0.8700323041093833\n",
      "Epoch  4490 Loss  0.18158391118049622\n",
      "Training accuracy is  0.9036135527007738\n",
      "Epoch  4500 Loss  0.1851740926504135\n",
      "Training accuracy is  0.9022612876568252\n",
      "Epoch  4510 Loss  0.18330900371074677\n",
      "Training accuracy is  0.8924949290060852\n",
      "Epoch  4520 Loss  0.19764837622642517\n",
      "Training accuracy is  0.8676282773645857\n",
      "Epoch  4530 Loss  0.17879259586334229\n",
      "Training accuracy is  0.9041394335511983\n",
      "Epoch  4540 Loss  0.20777693390846252\n",
      "Training accuracy is  0.9026369168356998\n",
      "Epoch  4550 Loss  0.18777889013290405\n",
      "Training accuracy is  0.9023364134926001\n",
      "Epoch  4560 Loss  0.1858607977628708\n",
      "Training accuracy is  0.895650214108632\n",
      "Epoch  4570 Loss  0.1840677559375763\n",
      "Training accuracy is  0.9028622943430246\n",
      "Epoch  4580 Loss  0.1789613515138626\n",
      "Training accuracy is  0.9013597776275261\n",
      "Epoch  4590 Loss  0.18083088099956512\n",
      "Training accuracy is  0.9040643077154233\n",
      "Epoch  4600 Loss  0.1802298128604889\n",
      "Training accuracy is  0.9045901885658478\n",
      "Epoch  4610 Loss  0.2022213190793991\n",
      "Training accuracy is  0.8521523551949516\n",
      "Epoch  4620 Loss  0.194077730178833\n",
      "Training accuracy is  0.9034633010292239\n",
      "Epoch  4630 Loss  0.1774451583623886\n",
      "Training accuracy is  0.9054165727593719\n",
      "Epoch  4640 Loss  0.1776585727930069\n",
      "Training accuracy is  0.9058673277740215\n",
      "Epoch  4650 Loss  0.19655926525592804\n",
      "Training accuracy is  0.8528284877169259\n",
      "Epoch  4660 Loss  0.19734515249729156\n",
      "Training accuracy is  0.9048155660731726\n",
      "Epoch  4670 Loss  0.18307124078273773\n",
      "Training accuracy is  0.9046653144016227\n",
      "Epoch  4680 Loss  0.1827080249786377\n",
      "Training accuracy is  0.8924949290060852\n",
      "Epoch  4690 Loss  0.17557509243488312\n",
      "Training accuracy is  0.9060927052813462\n",
      "Epoch  4700 Loss  0.24911274015903473\n",
      "Training accuracy is  0.8894898955750883\n",
      "Epoch  4710 Loss  0.19020800292491913\n",
      "Training accuracy is  0.9002328900909022\n",
      "Epoch  4720 Loss  0.17605246603488922\n",
      "Training accuracy is  0.9060927052813462\n",
      "Epoch  4730 Loss  0.17646236717700958\n",
      "Training accuracy is  0.9060927052813462\n",
      "Epoch  4740 Loss  0.18811525404453278\n",
      "Training accuracy is  0.8749906092705282\n",
      "Epoch  4750 Loss  0.17637969553470612\n",
      "Training accuracy is  0.9084967320261438\n",
      "Epoch  4760 Loss  0.22441112995147705\n",
      "Training accuracy is  0.8844564645781684\n",
      "Epoch  4770 Loss  0.17857681214809418\n",
      "Training accuracy is  0.9086469836976936\n",
      "Epoch  4780 Loss  0.1752953827381134\n",
      "Training accuracy is  0.9059424536097964\n",
      "Epoch  4790 Loss  0.18055175244808197\n",
      "Training accuracy is  0.9016602809706258\n",
      "Epoch  4800 Loss  0.1733805239200592\n",
      "Training accuracy is  0.908346480354594\n",
      "Epoch  4810 Loss  0.2143746018409729\n",
      "Training accuracy is  0.906318082788671\n",
      "Epoch  4820 Loss  0.18906420469284058\n",
      "Training accuracy is  0.9081962286830441\n",
      "Epoch  4830 Loss  0.18241603672504425\n",
      "Training accuracy is  0.9061678311171212\n",
      "Epoch  4840 Loss  0.17476709187030792\n",
      "Training accuracy is  0.9099241229058673\n",
      "Epoch  4850 Loss  0.188571497797966\n",
      "Training accuracy is  0.9003080159266772\n",
      "Epoch  4860 Loss  0.17388717830181122\n",
      "Training accuracy is  0.9038389302080986\n",
      "Epoch  4870 Loss  0.1845930516719818\n",
      "Training accuracy is  0.8908421606190369\n",
      "Epoch  4880 Loss  0.17251208424568176\n",
      "Training accuracy is  0.9101495004131921\n",
      "Epoch  4890 Loss  0.19752220809459686\n",
      "Training accuracy is  0.9084216061903688\n",
      "Epoch  4900 Loss  0.18492251634597778\n",
      "Training accuracy is  0.9055668244309218\n",
      "Epoch  4910 Loss  0.17877839505672455\n",
      "Training accuracy is  0.9060175794455714\n",
      "Epoch  4920 Loss  0.17741045355796814\n",
      "Training accuracy is  0.908346480354594\n",
      "Epoch  4930 Loss  0.17854025959968567\n",
      "Training accuracy is  0.9097738712343175\n",
      "Epoch  4940 Loss  0.173500195145607\n",
      "Training accuracy is  0.9109758846067163\n",
      "Epoch  4950 Loss  0.18653373420238495\n",
      "Training accuracy is  0.8968522274810308\n",
      "Epoch  4960 Loss  0.19592252373695374\n",
      "Training accuracy is  0.8671023965141612\n",
      "Epoch  4970 Loss  0.17266912758350372\n",
      "Training accuracy is  0.9101495004131921\n",
      "Epoch  4980 Loss  0.17406167089939117\n",
      "Training accuracy is  0.9109007587709413\n",
      "Epoch  4990 Loss  0.1834782510995865\n",
      "Training accuracy is  0.8998572609120277\n",
      "Epoch  5000 Loss  0.1897759735584259\n",
      "Training accuracy is  0.8680039065434603\n",
      "Epoch  5010 Loss  0.17359791696071625\n",
      "Training accuracy is  0.9112012621140411\n",
      "Epoch  5020 Loss  0.1794021874666214\n",
      "Training accuracy is  0.8976786116745549\n",
      "Epoch  5030 Loss  0.16943073272705078\n",
      "Training accuracy is  0.9114266396213658\n",
      "Epoch  5040 Loss  0.26868265867233276\n",
      "Training accuracy is  0.8844564645781684\n",
      "Epoch  5050 Loss  0.1877346932888031\n",
      "Training accuracy is  0.9016602809706258\n",
      "Epoch  5060 Loss  0.17547491192817688\n",
      "Training accuracy is  0.9087972353692435\n",
      "Epoch  5070 Loss  0.17247360944747925\n",
      "Training accuracy is  0.9116520171286906\n",
      "Epoch  5080 Loss  0.1740766167640686\n",
      "Training accuracy is  0.9106753812636166\n",
      "Epoch  5090 Loss  0.19872914254665375\n",
      "Training accuracy is  0.8985801217038539\n",
      "Epoch  5100 Loss  0.1802990585565567\n",
      "Training accuracy is  0.8773195101795508\n",
      "Epoch  5110 Loss  0.1708165556192398\n",
      "Training accuracy is  0.9111261362782661\n",
      "Epoch  5120 Loss  0.19211800396442413\n",
      "Training accuracy is  0.8957253399444068\n",
      "Epoch  5130 Loss  0.1816873997449875\n",
      "Training accuracy is  0.8826534445195703\n",
      "Epoch  5140 Loss  0.17882587015628815\n",
      "Training accuracy is  0.9078205995041695\n",
      "Epoch  5150 Loss  0.1692686825990677\n",
      "Training accuracy is  0.912177897979115\n",
      "Epoch  5160 Loss  0.2077673375606537\n",
      "Training accuracy is  0.848696566749305\n",
      "Epoch  5170 Loss  0.18310461938381195\n",
      "Training accuracy is  0.9117271429644654\n",
      "Epoch  5180 Loss  0.1698455959558487\n",
      "Training accuracy is  0.9113515137855909\n",
      "Epoch  5190 Loss  0.1674923598766327\n",
      "Training accuracy is  0.9127789046653144\n",
      "Epoch  5200 Loss  0.20855167508125305\n",
      "Training accuracy is  0.8532792427315754\n",
      "Epoch  5210 Loss  0.1804678589105606\n",
      "Training accuracy is  0.9093982420554428\n",
      "Epoch  5220 Loss  0.17699679732322693\n",
      "Training accuracy is  0.8775448876868756\n",
      "Epoch  5230 Loss  0.16709306836128235\n",
      "Training accuracy is  0.9133799113515138\n",
      "Epoch  5240 Loss  0.17030377686023712\n",
      "Training accuracy is  0.9130794080084141\n",
      "Epoch  5250 Loss  0.19122111797332764\n",
      "Training accuracy is  0.8932461873638344\n",
      "Epoch  5260 Loss  0.18835677206516266\n",
      "Training accuracy is  0.8801742919389978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5270 Loss  0.1733500361442566\n",
      "Training accuracy is  0.9127037788295395\n",
      "Epoch  5280 Loss  0.17527785897254944\n",
      "Training accuracy is  0.888738637217339\n",
      "Epoch  5290 Loss  0.17005908489227295\n",
      "Training accuracy is  0.9148824280670123\n",
      "Epoch  5300 Loss  0.18279096484184265\n",
      "Training accuracy is  0.9075200961610698\n",
      "Epoch  5310 Loss  0.16532954573631287\n",
      "Training accuracy is  0.914206295545038\n",
      "Epoch  5320 Loss  0.2469220906496048\n",
      "Training accuracy is  0.8515513485087521\n",
      "Epoch  5330 Loss  0.16790571808815002\n",
      "Training accuracy is  0.8961760949590564\n",
      "Epoch  5340 Loss  0.1752777248620987\n",
      "Training accuracy is  0.9113515137855909\n",
      "Epoch  5350 Loss  0.169338196516037\n",
      "Training accuracy is  0.9098489970700924\n",
      "Epoch  5360 Loss  0.1908949911594391\n",
      "Training accuracy is  0.8851325971001427\n",
      "Epoch  5370 Loss  0.17502108216285706\n",
      "Training accuracy is  0.9118022688002404\n",
      "Epoch  5380 Loss  0.16479460895061493\n",
      "Training accuracy is  0.9146570505596875\n",
      "Epoch  5390 Loss  0.19518506526947021\n",
      "Training accuracy is  0.9124032754864397\n",
      "Epoch  5400 Loss  0.1759595423936844\n",
      "Training accuracy is  0.9087972353692435\n",
      "Epoch  5410 Loss  0.1723797470331192\n",
      "Training accuracy is  0.9192397265419577\n",
      "Epoch  5420 Loss  0.1716141551733017\n",
      "Training accuracy is  0.9112763879498159\n",
      "Epoch  5430 Loss  0.18321211636066437\n",
      "Training accuracy is  0.9087972353692435\n",
      "Epoch  5440 Loss  0.173825204372406\n",
      "Training accuracy is  0.8823529411764706\n",
      "Epoch  5450 Loss  0.16400274634361267\n",
      "Training accuracy is  0.9146570505596875\n",
      "Epoch  5460 Loss  0.16376426815986633\n",
      "Training accuracy is  0.9146570505596875\n",
      "Epoch  5470 Loss  0.22006231546401978\n",
      "Training accuracy is  0.8500488317932537\n",
      "Epoch  5480 Loss  0.17124824225902557\n",
      "Training accuracy is  0.9148073022312373\n",
      "Epoch  5490 Loss  0.1640973687171936\n",
      "Training accuracy is  0.9147321763954624\n",
      "Epoch  5500 Loss  0.18425406515598297\n",
      "Training accuracy is  0.9047404402373976\n",
      "Epoch  5510 Loss  0.166921004652977\n",
      "Training accuracy is  0.9078957253399444\n",
      "Epoch  5520 Loss  0.17695222795009613\n",
      "Training accuracy is  0.9069190894748704\n",
      "Epoch  5530 Loss  0.17330557107925415\n",
      "Training accuracy is  0.910224626248967\n",
      "Epoch  5540 Loss  0.1635030061006546\n",
      "Training accuracy is  0.9144316730523627\n",
      "Epoch  5550 Loss  0.1627180129289627\n",
      "Training accuracy is  0.9157839380963113\n",
      "Epoch  5560 Loss  0.20266689360141754\n",
      "Training accuracy is  0.8900157764255128\n",
      "Epoch  5570 Loss  0.17439214885234833\n",
      "Training accuracy is  0.9184133423484336\n",
      "Epoch  5580 Loss  0.16199460625648499\n",
      "Training accuracy is  0.9152580572458868\n",
      "Epoch  5590 Loss  0.17319993674755096\n",
      "Training accuracy is  0.9113515137855909\n",
      "Epoch  5600 Loss  0.16522128880023956\n",
      "Training accuracy is  0.9136052888588385\n",
      "Epoch  5610 Loss  0.16550391912460327\n",
      "Training accuracy is  0.8913680414694614\n",
      "Epoch  5620 Loss  0.17072294652462006\n",
      "Training accuracy is  0.9157088122605364\n",
      "Epoch  5630 Loss  0.1727321445941925\n",
      "Training accuracy is  0.9103748779205169\n",
      "Epoch  5640 Loss  0.1637812852859497\n",
      "Training accuracy is  0.9149575539027872\n",
      "Epoch  5650 Loss  0.1621760129928589\n",
      "Training accuracy is  0.916084441439411\n",
      "Epoch  5660 Loss  0.16931521892547607\n",
      "Training accuracy is  0.913154533844189\n",
      "Epoch  5670 Loss  0.1636144369840622\n",
      "Training accuracy is  0.9166103222898355\n",
      "Epoch  5680 Loss  0.1752455085515976\n",
      "Training accuracy is  0.9127789046653144\n",
      "Epoch  5690 Loss  0.17659316956996918\n",
      "Training accuracy is  0.9074449703252949\n",
      "Epoch  5700 Loss  0.16169394552707672\n",
      "Training accuracy is  0.9172864548118098\n",
      "Epoch  5710 Loss  0.1605159193277359\n",
      "Training accuracy is  0.9165351964540606\n",
      "Epoch  5720 Loss  0.16563764214515686\n",
      "Training accuracy is  0.9124784013222147\n",
      "Epoch  5730 Loss  0.18664014339447021\n",
      "Training accuracy is  0.8613177071594922\n",
      "Epoch  5740 Loss  0.1609824150800705\n",
      "Training accuracy is  0.9179625873337841\n",
      "Epoch  5750 Loss  0.16029395163059235\n",
      "Training accuracy is  0.9158590639320863\n",
      "Epoch  5760 Loss  0.16902165114879608\n",
      "Training accuracy is  0.9138306663661633\n",
      "Epoch  5770 Loss  0.1761590838432312\n",
      "Training accuracy is  0.9102997520847419\n",
      "Epoch  5780 Loss  0.1591424196958542\n",
      "Training accuracy is  0.9166854481256104\n",
      "Epoch  5790 Loss  0.22055187821388245\n",
      "Training accuracy is  0.8610172038163925\n",
      "Epoch  5800 Loss  0.15982899069786072\n",
      "Training accuracy is  0.9184884681842086\n",
      "Epoch  5810 Loss  0.15983767807483673\n",
      "Training accuracy is  0.9162346931109608\n",
      "Epoch  5820 Loss  0.17308083176612854\n",
      "Training accuracy is  0.9138306663661633\n",
      "Epoch  5830 Loss  0.1670217514038086\n",
      "Training accuracy is  0.8921192998272106\n",
      "Epoch  5840 Loss  0.1626604050397873\n",
      "Training accuracy is  0.9139057922019382\n",
      "Epoch  5850 Loss  0.16982445120811462\n",
      "Training accuracy is  0.9023364134926001\n",
      "Epoch  5860 Loss  0.1593121439218521\n",
      "Training accuracy is  0.9165351964540606\n",
      "Epoch  5870 Loss  0.18574829399585724\n",
      "Training accuracy is  0.9136804146946135\n",
      "Epoch  5880 Loss  0.1586069017648697\n",
      "Training accuracy is  0.9173615806475847\n",
      "Epoch  5890 Loss  0.1600133776664734\n",
      "Training accuracy is  0.9165351964540606\n",
      "Epoch  5900 Loss  0.16280634701251984\n",
      "Training accuracy is  0.9012846517917512\n",
      "Epoch  5910 Loss  0.1741609424352646\n",
      "Training accuracy is  0.9060175794455714\n",
      "Epoch  5920 Loss  0.16196288168430328\n",
      "Training accuracy is  0.9172864548118098\n",
      "Epoch  5930 Loss  0.16023646295070648\n",
      "Training accuracy is  0.9164600706182856\n",
      "Epoch  5940 Loss  0.17560453712940216\n",
      "Training accuracy is  0.8705581849598076\n",
      "Epoch  5950 Loss  0.16352275013923645\n",
      "Training accuracy is  0.9145819247239125\n",
      "Epoch  5960 Loss  0.15764182806015015\n",
      "Training accuracy is  0.9181128390053339\n",
      "Epoch  5970 Loss  0.19069649279117584\n",
      "Training accuracy is  0.8930959356922846\n",
      "Epoch  5980 Loss  0.15923060476779938\n",
      "Training accuracy is  0.9175118323191346\n",
      "Epoch  5990 Loss  0.1767560839653015\n",
      "Training accuracy is  0.895575088272857\n",
      "Epoch  6000 Loss  0.16663791239261627\n",
      "Training accuracy is  0.9138306663661633\n",
      "Epoch  6010 Loss  0.15848572552204132\n",
      "Training accuracy is  0.9166103222898355\n",
      "Epoch  6020 Loss  0.1631397157907486\n",
      "Training accuracy is  0.9213432499436556\n",
      "Epoch  6030 Loss  0.1657310575246811\n",
      "Training accuracy is  0.8992562542258282\n",
      "Epoch  6040 Loss  0.1576921045780182\n",
      "Training accuracy is  0.9161595672751859\n",
      "Epoch  6050 Loss  0.15916341543197632\n",
      "Training accuracy is  0.9205168657501315\n",
      "Epoch  6060 Loss  0.16341333091259003\n",
      "Training accuracy is  0.9187889715273082\n",
      "Epoch  6070 Loss  0.16797786951065063\n",
      "Training accuracy is  0.9145067988881377\n",
      "Epoch  6080 Loss  0.1589972972869873\n",
      "Training accuracy is  0.9175118323191346\n",
      "Epoch  6090 Loss  0.18831828236579895\n",
      "Training accuracy is  0.8967019758094809\n",
      "Epoch  6100 Loss  0.17416071891784668\n",
      "Training accuracy is  0.913154533844189\n",
      "Epoch  6110 Loss  0.15764345228672028\n",
      "Training accuracy is  0.9166103222898355\n",
      "Epoch  6120 Loss  0.17082354426383972\n",
      "Training accuracy is  0.8968522274810308\n",
      "Epoch  6130 Loss  0.15611740946769714\n",
      "Training accuracy is  0.9178874614980091\n",
      "Epoch  6140 Loss  0.16429403424263\n",
      "Training accuracy is  0.9106002554278416\n",
      "Epoch  6150 Loss  0.19357474148273468\n",
      "Training accuracy is  0.87318758921193\n",
      "Epoch  6160 Loss  0.1562822014093399\n",
      "Training accuracy is  0.9171362031402599\n",
      "Epoch  6170 Loss  0.15604782104492188\n",
      "Training accuracy is  0.9175118323191346\n",
      "Epoch  6180 Loss  0.1652810424566269\n",
      "Training accuracy is  0.9144316730523627\n",
      "Epoch  6190 Loss  0.16095270216464996\n",
      "Training accuracy is  0.9178874614980091\n",
      "Epoch  6200 Loss  0.18429572880268097\n",
      "Training accuracy is  0.8649988731124634\n",
      "Epoch  6210 Loss  0.1645483672618866\n",
      "Training accuracy is  0.9148824280670123\n",
      "Epoch  6220 Loss  0.15771892666816711\n",
      "Training accuracy is  0.9257756742543761\n",
      "Epoch  6230 Loss  0.16176821291446686\n",
      "Training accuracy is  0.9178123356622342\n",
      "Epoch  6240 Loss  0.15593166649341583\n",
      "Training accuracy is  0.9184133423484336\n",
      "Epoch  6250 Loss  0.183757483959198\n",
      "Training accuracy is  0.8622192171887912\n",
      "Epoch  6260 Loss  0.16615280508995056\n",
      "Training accuracy is  0.9146570505596875\n",
      "Epoch  6270 Loss  0.15650533139705658\n",
      "Training accuracy is  0.9253249192397266\n",
      "Epoch  6280 Loss  0.16568417847156525\n",
      "Training accuracy is  0.9235218991811284\n",
      "Epoch  6290 Loss  0.15573643147945404\n",
      "Training accuracy is  0.9190894748704079\n",
      "Epoch  6300 Loss  0.18567201495170593\n",
      "Training accuracy is  0.8620689655172413\n",
      "Epoch  6310 Loss  0.16560660302639008\n",
      "Training accuracy is  0.9148073022312373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6320 Loss  0.15539729595184326\n",
      "Training accuracy is  0.9275786943129742\n",
      "Epoch  6330 Loss  0.17180085182189941\n",
      "Training accuracy is  0.9226955149876043\n",
      "Epoch  6340 Loss  0.1572665423154831\n",
      "Training accuracy is  0.9181879648411089\n",
      "Epoch  6350 Loss  0.17329473793506622\n",
      "Training accuracy is  0.8740139734054542\n",
      "Epoch  6360 Loss  0.15837563574314117\n",
      "Training accuracy is  0.916084441439411\n",
      "Epoch  6370 Loss  0.1543692648410797\n",
      "Training accuracy is  0.919014349034633\n",
      "Epoch  6380 Loss  0.16928865015506744\n",
      "Training accuracy is  0.9060175794455714\n",
      "Epoch  6390 Loss  0.17662952840328217\n",
      "Training accuracy is  0.8895650214108632\n",
      "Epoch  6400 Loss  0.16052941977977753\n",
      "Training accuracy is  0.9178874614980091\n",
      "Epoch  6410 Loss  0.1593092381954193\n",
      "Training accuracy is  0.9177372098264593\n",
      "Epoch  6420 Loss  0.1610579937696457\n",
      "Training accuracy is  0.9208173690932312\n",
      "Epoch  6430 Loss  0.1735907644033432\n",
      "Training accuracy is  0.9101495004131921\n",
      "Epoch  6440 Loss  0.1570427417755127\n",
      "Training accuracy is  0.9217188791225303\n",
      "Epoch  6450 Loss  0.15666744112968445\n",
      "Training accuracy is  0.9287055818495981\n",
      "Epoch  6460 Loss  0.19516871869564056\n",
      "Training accuracy is  0.8565096536698971\n",
      "Epoch  6470 Loss  0.16389015316963196\n",
      "Training accuracy is  0.9169859514687101\n",
      "Epoch  6480 Loss  0.16525040566921234\n",
      "Training accuracy is  0.9133799113515138\n",
      "Epoch  6490 Loss  0.15216851234436035\n",
      "Training accuracy is  0.9198407332281572\n",
      "Epoch  6500 Loss  0.21330246329307556\n",
      "Training accuracy is  0.8961760949590564\n",
      "Epoch  6510 Loss  0.1534443199634552\n",
      "Training accuracy is  0.9188640973630832\n",
      "Epoch  6520 Loss  0.16032609343528748\n",
      "Training accuracy is  0.9154834347532116\n",
      "Epoch  6530 Loss  0.1537914127111435\n",
      "Training accuracy is  0.9189392231988581\n",
      "Epoch  6540 Loss  0.17803412675857544\n",
      "Training accuracy is  0.9096987453985426\n",
      "Epoch  6550 Loss  0.16489368677139282\n",
      "Training accuracy is  0.9067688378033205\n",
      "Epoch  6560 Loss  0.15188291668891907\n",
      "Training accuracy is  0.9186387198557584\n",
      "Epoch  6570 Loss  0.15114526450634003\n",
      "Training accuracy is  0.9196904815566073\n",
      "Epoch  6580 Loss  0.2877218425273895\n",
      "Training accuracy is  0.8509503418225528\n",
      "Epoch  6590 Loss  0.168545201420784\n",
      "Training accuracy is  0.9136052888588385\n",
      "Epoch  6600 Loss  0.16380442678928375\n",
      "Training accuracy is  0.9020359101495005\n",
      "Epoch  6610 Loss  0.15174855291843414\n",
      "Training accuracy is  0.9196153557208324\n",
      "Epoch  6620 Loss  0.1648247092962265\n",
      "Training accuracy is  0.9150326797385621\n",
      "Epoch  6630 Loss  0.15126848220825195\n",
      "Training accuracy is  0.9195402298850575\n",
      "Epoch  6640 Loss  0.19387736916542053\n",
      "Training accuracy is  0.8836300803846443\n",
      "Epoch  6650 Loss  0.15559113025665283\n",
      "Training accuracy is  0.9195402298850575\n",
      "Epoch  6660 Loss  0.16979661583900452\n",
      "Training accuracy is  0.9047404402373976\n",
      "Epoch  6670 Loss  0.15302696824073792\n",
      "Training accuracy is  0.9192397265419577\n",
      "Epoch  6680 Loss  0.15814177691936493\n",
      "Training accuracy is  0.9189392231988581\n",
      "Epoch  6690 Loss  0.15530753135681152\n",
      "Training accuracy is  0.917061077304485\n",
      "Epoch  6700 Loss  0.1508810818195343\n",
      "Training accuracy is  0.9188640973630832\n",
      "Epoch  6710 Loss  0.20250317454338074\n",
      "Training accuracy is  0.8612425813237172\n",
      "Epoch  6720 Loss  0.1603957861661911\n",
      "Training accuracy is  0.9180377131695591\n",
      "Epoch  6730 Loss  0.1685057431459427\n",
      "Training accuracy is  0.9011344001202013\n",
      "Epoch  6740 Loss  0.15206335484981537\n",
      "Training accuracy is  0.9192397265419577\n",
      "Epoch  6750 Loss  0.16604623198509216\n",
      "Training accuracy is  0.9184884681842086\n",
      "Epoch  6760 Loss  0.15065059065818787\n",
      "Training accuracy is  0.9201412365712569\n",
      "Epoch  6770 Loss  0.15825049579143524\n",
      "Training accuracy is  0.9183382165126587\n",
      "Epoch  6780 Loss  0.14979125559329987\n",
      "Training accuracy is  0.9201412365712569\n",
      "Epoch  6790 Loss  0.16576601564884186\n",
      "Training accuracy is  0.902411539328375\n",
      "Epoch  6800 Loss  0.1736280769109726\n",
      "Training accuracy is  0.8951243332582075\n",
      "Epoch  6810 Loss  0.1632339507341385\n",
      "Training accuracy is  0.8991811283900534\n",
      "Epoch  6820 Loss  0.15248842537403107\n",
      "Training accuracy is  0.9184884681842086\n",
      "Epoch  6830 Loss  0.15304404497146606\n",
      "Training accuracy is  0.9191646007061829\n",
      "Epoch  6840 Loss  0.15095628798007965\n",
      "Training accuracy is  0.920066110735482\n",
      "Epoch  6850 Loss  0.15221764147281647\n",
      "Training accuracy is  0.9252497934039516\n",
      "Epoch  6860 Loss  0.17292848229408264\n",
      "Training accuracy is  0.9127789046653144\n",
      "Epoch  6870 Loss  0.1578633338212967\n",
      "Training accuracy is  0.9177372098264593\n",
      "Epoch  6880 Loss  0.14974690973758698\n",
      "Training accuracy is  0.9235218991811284\n",
      "Epoch  6890 Loss  0.16136829555034637\n",
      "Training accuracy is  0.9187138456915334\n",
      "Epoch  6900 Loss  0.1522592306137085\n",
      "Training accuracy is  0.9220945083014048\n",
      "Epoch  6910 Loss  0.15082374215126038\n",
      "Training accuracy is  0.9193899782135077\n",
      "Epoch  6920 Loss  0.1563161015510559\n",
      "Training accuracy is  0.9183382165126587\n",
      "Epoch  6930 Loss  0.1521604210138321\n",
      "Training accuracy is  0.9187889715273082\n",
      "Epoch  6940 Loss  0.15072181820869446\n",
      "Training accuracy is  0.92201938246563\n",
      "Epoch  6950 Loss  0.15654292702674866\n",
      "Training accuracy is  0.9171362031402599\n",
      "Epoch  6960 Loss  0.14898529648780823\n",
      "Training accuracy is  0.9212681241078807\n",
      "Epoch  6970 Loss  0.20012874901294708\n",
      "Training accuracy is  0.87318758921193\n",
      "Epoch  6980 Loss  0.15959705412387848\n",
      "Training accuracy is  0.9180377131695591\n",
      "Epoch  6990 Loss  0.1600220799446106\n",
      "Training accuracy is  0.9119525204717902\n",
      "Epoch  7000 Loss  0.14922046661376953\n",
      "Training accuracy is  0.9203666140785817\n",
      "Epoch  7010 Loss  0.1697705239057541\n",
      "Training accuracy is  0.9108256329351664\n",
      "Epoch  7020 Loss  0.15773361921310425\n",
      "Training accuracy is  0.9198407332281572\n",
      "Epoch  7030 Loss  0.14825621247291565\n",
      "Training accuracy is  0.9202914882428067\n",
      "Epoch  7040 Loss  0.18269267678260803\n",
      "Training accuracy is  0.9143565472165878\n",
      "Epoch  7050 Loss  0.15026429295539856\n",
      "Training accuracy is  0.9212681241078807\n",
      "Epoch  7060 Loss  0.15173353254795074\n",
      "Training accuracy is  0.9199158590639321\n",
      "Epoch  7070 Loss  0.15504923462867737\n",
      "Training accuracy is  0.9172113289760349\n",
      "Epoch  7080 Loss  0.15114407241344452\n",
      "Training accuracy is  0.9180377131695591\n",
      "Epoch  7090 Loss  0.1566515564918518\n",
      "Training accuracy is  0.919014349034633\n",
      "Epoch  7100 Loss  0.14810606837272644\n",
      "Training accuracy is  0.9205919915859064\n",
      "Epoch  7110 Loss  0.17449769377708435\n",
      "Training accuracy is  0.9026369168356998\n",
      "Epoch  7120 Loss  0.17102816700935364\n",
      "Training accuracy is  0.9118773946360154\n",
      "Epoch  7130 Loss  0.15395674109458923\n",
      "Training accuracy is  0.9198407332281572\n",
      "Epoch  7140 Loss  0.1584726721048355\n",
      "Training accuracy is  0.9129291563368642\n",
      "Epoch  7150 Loss  0.14787225425243378\n",
      "Training accuracy is  0.920892494929006\n",
      "Epoch  7160 Loss  0.16086040437221527\n",
      "Training accuracy is  0.9172113289760349\n",
      "Epoch  7170 Loss  0.14819540083408356\n",
      "Training accuracy is  0.9260010517617009\n",
      "Epoch  7180 Loss  0.15875361859798431\n",
      "Training accuracy is  0.9194651040492825\n",
      "Epoch  7190 Loss  0.150066539645195\n",
      "Training accuracy is  0.9243482833746526\n",
      "Epoch  7200 Loss  0.14747627079486847\n",
      "Training accuracy is  0.9204417399143565\n",
      "Epoch  7210 Loss  0.16203255951404572\n",
      "Training accuracy is  0.9101495004131921\n",
      "Epoch  7220 Loss  0.16465426981449127\n",
      "Training accuracy is  0.906318082788671\n",
      "Epoch  7230 Loss  0.15916673839092255\n",
      "Training accuracy is  0.9169108256329351\n",
      "Epoch  7240 Loss  0.14705955982208252\n",
      "Training accuracy is  0.9212681241078807\n",
      "Epoch  7250 Loss  0.1807968020439148\n",
      "Training accuracy is  0.8550822627901735\n",
      "Epoch  7260 Loss  0.16532613337039948\n",
      "Training accuracy is  0.9160093156036361\n",
      "Epoch  7270 Loss  0.15741708874702454\n",
      "Training accuracy is  0.9293817143715724\n",
      "Epoch  7280 Loss  0.15060627460479736\n",
      "Training accuracy is  0.9194651040492825\n",
      "Epoch  7290 Loss  0.14932145178318024\n",
      "Training accuracy is  0.9206671174216813\n",
      "Epoch  7300 Loss  0.15001733601093292\n",
      "Training accuracy is  0.9252497934039516\n",
      "Epoch  7310 Loss  0.1469302475452423\n",
      "Training accuracy is  0.9247990383893021\n",
      "Epoch  7320 Loss  0.15154191851615906\n",
      "Training accuracy is  0.9205919915859064\n",
      "Epoch  7330 Loss  0.1539798229932785\n",
      "Training accuracy is  0.9148073022312373\n",
      "Epoch  7340 Loss  0.14795613288879395\n",
      "Training accuracy is  0.9203666140785817\n",
      "Epoch  7350 Loss  0.15735994279384613\n",
      "Training accuracy is  0.9184884681842086\n",
      "Epoch  7360 Loss  0.1589605212211609\n",
      "Training accuracy is  0.9045901885658478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7370 Loss  0.15259066224098206\n",
      "Training accuracy is  0.9178874614980091\n",
      "Epoch  7380 Loss  0.1549108326435089\n",
      "Training accuracy is  0.9249492900608519\n",
      "Epoch  7390 Loss  0.14842933416366577\n",
      "Training accuracy is  0.9241229058673278\n",
      "Epoch  7400 Loss  0.15950477123260498\n",
      "Training accuracy is  0.9115017654571407\n",
      "Epoch  7410 Loss  0.16436238586902618\n",
      "Training accuracy is  0.9067688378033205\n",
      "Epoch  7420 Loss  0.15667782723903656\n",
      "Training accuracy is  0.9181879648411089\n",
      "Epoch  7430 Loss  0.1467505693435669\n",
      "Training accuracy is  0.9208173690932312\n",
      "Epoch  7440 Loss  0.18052241206169128\n",
      "Training accuracy is  0.9135301630230637\n",
      "Epoch  7450 Loss  0.1537809520959854\n",
      "Training accuracy is  0.9252497934039516\n",
      "Epoch  7460 Loss  0.16339696943759918\n",
      "Training accuracy is  0.915107805574337\n",
      "Epoch  7470 Loss  0.1484648585319519\n",
      "Training accuracy is  0.927879197656074\n",
      "Epoch  7480 Loss  0.1752883791923523\n",
      "Training accuracy is  0.9178874614980091\n",
      "Epoch  7490 Loss  0.15151439607143402\n",
      "Training accuracy is  0.9206671174216813\n",
      "Epoch  7500 Loss  0.15657994151115417\n",
      "Training accuracy is  0.9130794080084141\n",
      "Epoch  7510 Loss  0.15217779576778412\n",
      "Training accuracy is  0.9179625873337841\n",
      "Epoch  7520 Loss  0.15659481287002563\n",
      "Training accuracy is  0.9243482833746526\n",
      "Epoch  7530 Loss  0.14662836492061615\n",
      "Training accuracy is  0.9212681241078807\n",
      "Epoch  7540 Loss  0.16616316139698029\n",
      "Training accuracy is  0.9060175794455714\n",
      "Epoch  7550 Loss  0.16535155475139618\n",
      "Training accuracy is  0.9254000450755014\n",
      "Epoch  7560 Loss  0.14724914729595184\n",
      "Training accuracy is  0.9205919915859064\n",
      "Epoch  7570 Loss  0.17188815772533417\n",
      "Training accuracy is  0.8843062129066186\n",
      "Epoch  7580 Loss  0.15030376613140106\n",
      "Training accuracy is  0.9189392231988581\n",
      "Epoch  7590 Loss  0.14723795652389526\n",
      "Training accuracy is  0.9207422432574562\n",
      "Epoch  7600 Loss  0.18702878057956696\n",
      "Training accuracy is  0.9025617909999248\n",
      "Epoch  7610 Loss  0.14697547256946564\n",
      "Training accuracy is  0.9212681241078807\n",
      "Epoch  7620 Loss  0.14626359939575195\n",
      "Training accuracy is  0.9272781909698745\n",
      "Epoch  7630 Loss  0.16718578338623047\n",
      "Training accuracy is  0.9243482833746526\n",
      "Epoch  7640 Loss  0.15401525795459747\n",
      "Training accuracy is  0.9184133423484336\n",
      "Epoch  7650 Loss  0.15918272733688354\n",
      "Training accuracy is  0.9179625873337841\n",
      "Epoch  7660 Loss  0.15646357834339142\n",
      "Training accuracy is  0.9289309593569228\n",
      "Epoch  7670 Loss  0.14631865918636322\n",
      "Training accuracy is  0.9211178724363308\n",
      "Epoch  7680 Loss  0.14463390409946442\n",
      "Training accuracy is  0.9224701374802795\n",
      "Epoch  7690 Loss  0.19558930397033691\n",
      "Training accuracy is  0.8931710615280595\n",
      "Epoch  7700 Loss  0.14635896682739258\n",
      "Training accuracy is  0.92201938246563\n",
      "Epoch  7710 Loss  0.1525147408246994\n",
      "Training accuracy is  0.9340395161896176\n",
      "Epoch  7720 Loss  0.14686113595962524\n",
      "Training accuracy is  0.9312598602659454\n",
      "Epoch  7730 Loss  0.1551106572151184\n",
      "Training accuracy is  0.9145067988881377\n",
      "Epoch  7740 Loss  0.1481459140777588\n",
      "Training accuracy is  0.9216437532867553\n",
      "Epoch  7750 Loss  0.14458811283111572\n",
      "Training accuracy is  0.9214935016152055\n",
      "Epoch  7760 Loss  0.18045194447040558\n",
      "Training accuracy is  0.8610923296521674\n",
      "Epoch  7770 Loss  0.15603111684322357\n",
      "Training accuracy is  0.9185635940199834\n",
      "Epoch  7780 Loss  0.1590007096529007\n",
      "Training accuracy is  0.9239726541957779\n",
      "Epoch  7790 Loss  0.14519791305065155\n",
      "Training accuracy is  0.9227706408233791\n",
      "Epoch  7800 Loss  0.18101029098033905\n",
      "Training accuracy is  0.9043648110585231\n",
      "Epoch  7810 Loss  0.1488606333732605\n",
      "Training accuracy is  0.9227706408233791\n",
      "Epoch  7820 Loss  0.14420704543590546\n",
      "Training accuracy is  0.9215686274509803\n",
      "Epoch  7830 Loss  0.18922802805900574\n",
      "Training accuracy is  0.8601156937870934\n",
      "Epoch  7840 Loss  0.15581531822681427\n",
      "Training accuracy is  0.9201412365712569\n",
      "Epoch  7850 Loss  0.15551018714904785\n",
      "Training accuracy is  0.9365186687701901\n",
      "Epoch  7860 Loss  0.14410236477851868\n",
      "Training accuracy is  0.9256254225828262\n",
      "Epoch  7870 Loss  0.1465812474489212\n",
      "Training accuracy is  0.9218691307940801\n",
      "Epoch  7880 Loss  0.17375816404819489\n",
      "Training accuracy is  0.9272781909698745\n",
      "Epoch  7890 Loss  0.15423832833766937\n",
      "Training accuracy is  0.9341146420253925\n",
      "Epoch  7900 Loss  0.1501040756702423\n",
      "Training accuracy is  0.9202163624070318\n",
      "Epoch  7910 Loss  0.14611977338790894\n",
      "Training accuracy is  0.9324618736383442\n",
      "Epoch  7920 Loss  0.14610999822616577\n",
      "Training accuracy is  0.9193148523777327\n",
      "Epoch  7930 Loss  0.15101438760757446\n",
      "Training accuracy is  0.9354669070693411\n",
      "Epoch  7940 Loss  0.14804722368717194\n",
      "Training accuracy is  0.9338141386822928\n",
      "Epoch  7950 Loss  0.16683368384838104\n",
      "Training accuracy is  0.9341146420253925\n",
      "Epoch  7960 Loss  0.1442444771528244\n",
      "Training accuracy is  0.9217188791225303\n",
      "Epoch  7970 Loss  0.18719038367271423\n",
      "Training accuracy is  0.8803996694463226\n",
      "Epoch  7980 Loss  0.15138961374759674\n",
      "Training accuracy is  0.9201412365712569\n",
      "Epoch  7990 Loss  0.15422165393829346\n",
      "Training accuracy is  0.9096236195627676\n",
      "Epoch  8000 Loss  0.15570256114006042\n",
      "Training accuracy is  0.9181879648411089\n",
      "Epoch  8010 Loss  0.14950145781040192\n",
      "Training accuracy is  0.9314101119374953\n",
      "Epoch  8020 Loss  0.1487024426460266\n",
      "Training accuracy is  0.9189392231988581\n",
      "Epoch  8030 Loss  0.14970123767852783\n",
      "Training accuracy is  0.9245736608819773\n",
      "Epoch  8040 Loss  0.1536223292350769\n",
      "Training accuracy is  0.9184133423484336\n",
      "Epoch  8050 Loss  0.14301884174346924\n",
      "Training accuracy is  0.9218691307940801\n",
      "Epoch  8060 Loss  0.18424715101718903\n",
      "Training accuracy is  0.8975283600030051\n",
      "Epoch  8070 Loss  0.1676824390888214\n",
      "Training accuracy is  0.8447148974532341\n",
      "Epoch  8080 Loss  0.1825382262468338\n",
      "Training accuracy is  0.8706333107955826\n",
      "Epoch  8090 Loss  0.15346287190914154\n",
      "Training accuracy is  0.9155585605889865\n",
      "Epoch  8100 Loss  0.15533222258090973\n",
      "Training accuracy is  0.9223198858087296\n",
      "Epoch  8110 Loss  0.15255463123321533\n",
      "Training accuracy is  0.9211929982721058\n",
      "Epoch  8120 Loss  0.15004177391529083\n",
      "Training accuracy is  0.919990984899707\n",
      "Epoch  8130 Loss  0.1484776884317398\n",
      "Training accuracy is  0.920066110735482\n",
      "Epoch  8140 Loss  0.1475074291229248\n",
      "Training accuracy is  0.920967620764781\n",
      "Epoch  8150 Loss  0.14648212492465973\n",
      "Training accuracy is  0.9206671174216813\n",
      "Epoch  8160 Loss  0.14553608000278473\n",
      "Training accuracy is  0.9208173690932312\n",
      "Epoch  8170 Loss  0.1447238028049469\n",
      "Training accuracy is  0.9208173690932312\n",
      "Epoch  8180 Loss  0.14391399919986725\n",
      "Training accuracy is  0.9211178724363308\n",
      "Epoch  8190 Loss  0.14320974051952362\n",
      "Training accuracy is  0.9216437532867553\n",
      "Epoch  8200 Loss  0.14252257347106934\n",
      "Training accuracy is  0.9218691307940801\n",
      "Epoch  8210 Loss  0.16663770377635956\n",
      "Training accuracy is  0.9054165727593719\n",
      "Epoch  8220 Loss  0.15659649670124054\n",
      "Training accuracy is  0.9169859514687101\n",
      "Epoch  8230 Loss  0.15290988981723785\n",
      "Training accuracy is  0.9178123356622342\n",
      "Epoch  8240 Loss  0.14664053916931152\n",
      "Training accuracy is  0.9206671174216813\n",
      "Epoch  8250 Loss  0.15848638117313385\n",
      "Training accuracy is  0.8836300803846443\n",
      "Epoch  8260 Loss  0.15131206810474396\n",
      "Training accuracy is  0.9185635940199834\n",
      "Epoch  8270 Loss  0.15128052234649658\n",
      "Training accuracy is  0.9374953046352641\n",
      "Epoch  8280 Loss  0.16019901633262634\n",
      "Training accuracy is  0.933663887010743\n",
      "Epoch  8290 Loss  0.14648641645908356\n",
      "Training accuracy is  0.9205168657501315\n",
      "Epoch  8300 Loss  0.1434348225593567\n",
      "Training accuracy is  0.9230711441664788\n",
      "Epoch  8310 Loss  0.1434108316898346\n",
      "Training accuracy is  0.9211178724363308\n",
      "Epoch  8320 Loss  0.15954548120498657\n",
      "Training accuracy is  0.9172113289760349\n",
      "Epoch  8330 Loss  0.15091021358966827\n",
      "Training accuracy is  0.934640522875817\n",
      "Epoch  8340 Loss  0.14697112143039703\n",
      "Training accuracy is  0.92201938246563\n",
      "Epoch  8350 Loss  0.14172980189323425\n",
      "Training accuracy is  0.9230711441664788\n",
      "Epoch  8360 Loss  0.19997645914554596\n",
      "Training accuracy is  0.8909172864548118\n",
      "Epoch  8370 Loss  0.14482051134109497\n",
      "Training accuracy is  0.9220945083014048\n",
      "Epoch  8380 Loss  0.16425926983356476\n",
      "Training accuracy is  0.9118773946360154\n",
      "Epoch  8390 Loss  0.14408497512340546\n",
      "Training accuracy is  0.9211929982721058\n",
      "Epoch  8400 Loss  0.16774015128612518\n",
      "Training accuracy is  0.9143565472165878\n",
      "Epoch  8410 Loss  0.1472131460905075\n",
      "Training accuracy is  0.9304334760724213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8420 Loss  0.1592872440814972\n",
      "Training accuracy is  0.9112763879498159\n",
      "Epoch  8430 Loss  0.1524454951286316\n",
      "Training accuracy is  0.933588761174968\n",
      "Epoch  8440 Loss  0.15007281303405762\n",
      "Training accuracy is  0.9188640973630832\n",
      "Epoch  8450 Loss  0.14531457424163818\n",
      "Training accuracy is  0.9217940049583052\n",
      "Epoch  8460 Loss  0.14114297926425934\n",
      "Training accuracy is  0.9214935016152055\n",
      "Epoch  8470 Loss  0.17442677915096283\n",
      "Training accuracy is  0.9130042821726392\n",
      "Epoch  8480 Loss  0.1465124487876892\n",
      "Training accuracy is  0.9292314627000225\n",
      "Epoch  8490 Loss  0.15258026123046875\n",
      "Training accuracy is  0.9165351964540606\n",
      "Epoch  8500 Loss  0.14660273492336273\n",
      "Training accuracy is  0.9298324693862219\n",
      "Epoch  8510 Loss  0.1438256800174713\n",
      "Training accuracy is  0.9211178724363308\n",
      "Epoch  8520 Loss  0.1607639640569687\n",
      "Training accuracy is  0.9193148523777327\n",
      "Epoch  8530 Loss  0.1449897587299347\n",
      "Training accuracy is  0.9262264292690257\n",
      "Epoch  8540 Loss  0.144584059715271\n",
      "Training accuracy is  0.9416272256028848\n",
      "Epoch  8550 Loss  0.1458268016576767\n",
      "Training accuracy is  0.9188640973630832\n",
      "Epoch  8560 Loss  0.16060884296894073\n",
      "Training accuracy is  0.9276538201487492\n",
      "Epoch  8570 Loss  0.15147271752357483\n",
      "Training accuracy is  0.9175869581549094\n",
      "Epoch  8580 Loss  0.14136703312397003\n",
      "Training accuracy is  0.9247239125535271\n",
      "Epoch  8590 Loss  0.16421209275722504\n",
      "Training accuracy is  0.8964765983021561\n",
      "Epoch  8600 Loss  0.14286771416664124\n",
      "Training accuracy is  0.9211929982721058\n",
      "Epoch  8610 Loss  0.1429346799850464\n",
      "Training accuracy is  0.9213432499436556\n",
      "Epoch  8620 Loss  0.15328143537044525\n",
      "Training accuracy is  0.9205168657501315\n",
      "Epoch  8630 Loss  0.1438751071691513\n",
      "Training accuracy is  0.9282548268349485\n",
      "Epoch  8640 Loss  0.14042729139328003\n",
      "Training accuracy is  0.921944256629855\n",
      "Epoch  8650 Loss  0.15356244146823883\n",
      "Training accuracy is  0.8810758019682969\n",
      "Epoch  8660 Loss  0.26073378324508667\n",
      "Training accuracy is  0.9020359101495005\n",
      "Epoch  8670 Loss  0.21629662811756134\n",
      "Training accuracy is  0.8803245436105477\n",
      "Epoch  8680 Loss  0.1671840399503708\n",
      "Training accuracy is  0.92201938246563\n",
      "Epoch  8690 Loss  0.1489962935447693\n",
      "Training accuracy is  0.9196904815566073\n",
      "Epoch  8700 Loss  0.14973309636116028\n",
      "Training accuracy is  0.9205168657501315\n",
      "Epoch  8710 Loss  0.14718924462795258\n",
      "Training accuracy is  0.9202163624070318\n",
      "Epoch  8720 Loss  0.1458137184381485\n",
      "Training accuracy is  0.920967620764781\n",
      "Epoch  8730 Loss  0.1443202644586563\n",
      "Training accuracy is  0.920967620764781\n",
      "Epoch  8740 Loss  0.14318925142288208\n",
      "Training accuracy is  0.9211929982721058\n",
      "Epoch  8750 Loss  0.142295241355896\n",
      "Training accuracy is  0.9214183757794305\n",
      "Epoch  8760 Loss  0.14155462384223938\n",
      "Training accuracy is  0.9216437532867553\n",
      "Epoch  8770 Loss  0.14087988436222076\n",
      "Training accuracy is  0.9217188791225303\n",
      "Epoch  8780 Loss  0.14017841219902039\n",
      "Training accuracy is  0.921944256629855\n",
      "Epoch  8790 Loss  0.15855370461940765\n",
      "Training accuracy is  0.9114266396213658\n",
      "Epoch  8800 Loss  0.1581123322248459\n",
      "Training accuracy is  0.9279543234918488\n",
      "Epoch  8810 Loss  0.15158407390117645\n",
      "Training accuracy is  0.9184133423484336\n",
      "Epoch  8820 Loss  0.142366424202919\n",
      "Training accuracy is  0.921944256629855\n",
      "Epoch  8830 Loss  0.17412061989307404\n",
      "Training accuracy is  0.8655247539628879\n",
      "Epoch  8840 Loss  0.1532517671585083\n",
      "Training accuracy is  0.9206671174216813\n",
      "Epoch  8850 Loss  0.1455700546503067\n",
      "Training accuracy is  0.9203666140785817\n",
      "Epoch  8860 Loss  0.14041811227798462\n",
      "Training accuracy is  0.9306588535797461\n",
      "Epoch  8870 Loss  0.14419905841350555\n",
      "Training accuracy is  0.9226203891518293\n",
      "Epoch  8880 Loss  0.1486807018518448\n",
      "Training accuracy is  0.9314852377732702\n",
      "Epoch  8890 Loss  0.14783215522766113\n",
      "Training accuracy is  0.9188640973630832\n",
      "Epoch  8900 Loss  0.14181822538375854\n",
      "Training accuracy is  0.9331380061603185\n",
      "Epoch  8910 Loss  0.14366482198238373\n",
      "Training accuracy is  0.920967620764781\n",
      "Epoch  8920 Loss  0.14416664838790894\n",
      "Training accuracy is  0.9223950116445045\n",
      "Epoch  8930 Loss  0.14046818017959595\n",
      "Training accuracy is  0.9218691307940801\n",
      "Epoch  8940 Loss  0.1640341579914093\n",
      "Training accuracy is  0.9149575539027872\n",
      "Epoch  8950 Loss  0.14307855069637299\n",
      "Training accuracy is  0.9244985350462024\n",
      "Epoch  8960 Loss  0.1634288877248764\n",
      "Training accuracy is  0.9090977387123432\n",
      "Epoch  8970 Loss  0.14825883507728577\n",
      "Training accuracy is  0.9379460596499136\n",
      "Epoch  8980 Loss  0.14785093069076538\n",
      "Training accuracy is  0.9191646007061829\n",
      "Epoch  8990 Loss  0.1415783017873764\n",
      "Training accuracy is  0.9376455563068139\n",
      "Epoch  9000 Loss  0.14369527995586395\n",
      "Training accuracy is  0.920967620764781\n",
      "Epoch  9010 Loss  0.15293605625629425\n",
      "Training accuracy is  0.9208173690932312\n",
      "Epoch  9020 Loss  0.1403038054704666\n",
      "Training accuracy is  0.9233716475095786\n",
      "Epoch  9030 Loss  0.17452390491962433\n",
      "Training accuracy is  0.9057170761024717\n",
      "Epoch  9040 Loss  0.14009471237659454\n",
      "Training accuracy is  0.9220945083014048\n",
      "Epoch  9050 Loss  0.1543470323085785\n",
      "Training accuracy is  0.9349410262189167\n",
      "Epoch  9060 Loss  0.14456325769424438\n",
      "Training accuracy is  0.9201412365712569\n",
      "Epoch  9070 Loss  0.1410360187292099\n",
      "Training accuracy is  0.9341146420253925\n",
      "Epoch  9080 Loss  0.14245375990867615\n",
      "Training accuracy is  0.9208173690932312\n",
      "Epoch  9090 Loss  0.14526893198490143\n",
      "Training accuracy is  0.9226203891518293\n",
      "Epoch  9100 Loss  0.14012035727500916\n",
      "Training accuracy is  0.9233716475095786\n",
      "Epoch  9110 Loss  0.17347536981105804\n",
      "Training accuracy is  0.9105251295920667\n",
      "Epoch  9120 Loss  0.1413850486278534\n",
      "Training accuracy is  0.9226955149876043\n",
      "Epoch  9130 Loss  0.1385601907968521\n",
      "Training accuracy is  0.9241980317031027\n",
      "Epoch  9140 Loss  0.22359292209148407\n",
      "Training accuracy is  0.8894898955750883\n",
      "Epoch  9150 Loss  0.3132769763469696\n",
      "Training accuracy is  0.8791225302381489\n",
      "Epoch  9160 Loss  0.24957363307476044\n",
      "Training accuracy is  0.900458267598227\n",
      "Epoch  9170 Loss  0.16439397633075714\n",
      "Training accuracy is  0.8991060025542784\n",
      "Epoch  9180 Loss  0.16770394146442413\n",
      "Training accuracy is  0.903388175193449\n",
      "Epoch  9190 Loss  0.16413827240467072\n",
      "Training accuracy is  0.9155585605889865\n",
      "Epoch  9200 Loss  0.16105623543262482\n",
      "Training accuracy is  0.9155585605889865\n",
      "Epoch  9210 Loss  0.15776942670345306\n",
      "Training accuracy is  0.9168356997971603\n",
      "Epoch  9220 Loss  0.15610921382904053\n",
      "Training accuracy is  0.9184884681842086\n",
      "Epoch  9230 Loss  0.1546156406402588\n",
      "Training accuracy is  0.9190894748704079\n",
      "Epoch  9240 Loss  0.15323065221309662\n",
      "Training accuracy is  0.9198407332281572\n",
      "Epoch  9250 Loss  0.1519254744052887\n",
      "Training accuracy is  0.919990984899707\n",
      "Epoch  9260 Loss  0.15065620839595795\n",
      "Training accuracy is  0.9199158590639321\n",
      "Epoch  9270 Loss  0.14950115978717804\n",
      "Training accuracy is  0.9201412365712569\n",
      "Epoch  9280 Loss  0.14844095706939697\n",
      "Training accuracy is  0.9199158590639321\n",
      "Epoch  9290 Loss  0.14730162918567657\n",
      "Training accuracy is  0.9202163624070318\n",
      "Epoch  9300 Loss  0.14620648324489594\n",
      "Training accuracy is  0.9202163624070318\n",
      "Epoch  9310 Loss  0.14540308713912964\n",
      "Training accuracy is  0.9203666140785817\n",
      "Epoch  9320 Loss  0.14461076259613037\n",
      "Training accuracy is  0.9207422432574562\n",
      "Epoch  9330 Loss  0.14382410049438477\n",
      "Training accuracy is  0.9211929982721058\n",
      "Epoch  9340 Loss  0.14304330945014954\n",
      "Training accuracy is  0.9211178724363308\n",
      "Epoch  9350 Loss  0.14223504066467285\n",
      "Training accuracy is  0.9216437532867553\n",
      "Epoch  9360 Loss  0.14141449332237244\n",
      "Training accuracy is  0.9218691307940801\n",
      "Epoch  9370 Loss  0.14068637788295746\n",
      "Training accuracy is  0.9217940049583052\n",
      "Epoch  9380 Loss  0.139979287981987\n",
      "Training accuracy is  0.9215686274509803\n",
      "Epoch  9390 Loss  0.1393093317747116\n",
      "Training accuracy is  0.9222447599729547\n",
      "Epoch  9400 Loss  0.1393902450799942\n",
      "Training accuracy is  0.9224701374802795\n",
      "Epoch  9410 Loss  0.1582041084766388\n",
      "Training accuracy is  0.912177897979115\n",
      "Epoch  9420 Loss  0.13928894698619843\n",
      "Training accuracy is  0.9302080985650966\n",
      "Epoch  9430 Loss  0.16169831156730652\n",
      "Training accuracy is  0.931710615280595\n",
      "Epoch  9440 Loss  0.13850943744182587\n",
      "Training accuracy is  0.9224701374802795\n",
      "Epoch  9450 Loss  0.17339912056922913\n",
      "Training accuracy is  0.9101495004131921\n",
      "Epoch  9460 Loss  0.15448856353759766\n",
      "Training accuracy is  0.926827435955225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9470 Loss  0.14517483115196228\n",
      "Training accuracy is  0.9409510930809105\n",
      "Epoch  9480 Loss  0.14022600650787354\n",
      "Training accuracy is  0.9241980317031027\n",
      "Epoch  9490 Loss  0.14803557097911835\n",
      "Training accuracy is  0.9193899782135077\n",
      "Epoch  9500 Loss  0.15015928447246552\n",
      "Training accuracy is  0.9198407332281572\n",
      "Epoch  9510 Loss  0.138881653547287\n",
      "Training accuracy is  0.9361430395913155\n",
      "Epoch  9520 Loss  0.15095245838165283\n",
      "Training accuracy is  0.9372699271279393\n",
      "Epoch  9530 Loss  0.1405220627784729\n",
      "Training accuracy is  0.921944256629855\n",
      "Epoch  9540 Loss  0.15402023494243622\n",
      "Training accuracy is  0.9168356997971603\n",
      "Epoch  9550 Loss  0.14509837329387665\n",
      "Training accuracy is  0.9216437532867553\n",
      "Epoch  9560 Loss  0.1405191570520401\n",
      "Training accuracy is  0.9211178724363308\n",
      "Epoch  9570 Loss  0.13831423223018646\n",
      "Training accuracy is  0.92675231011945\n",
      "Epoch  9580 Loss  0.14493080973625183\n",
      "Training accuracy is  0.9157839380963113\n",
      "Epoch  9590 Loss  0.14728830754756927\n",
      "Training accuracy is  0.9350161520546916\n",
      "Epoch  9600 Loss  0.1398366391658783\n",
      "Training accuracy is  0.9220945083014048\n",
      "Epoch  9610 Loss  0.1560925394296646\n",
      "Training accuracy is  0.8951243332582075\n",
      "Epoch  9620 Loss  0.19784311950206757\n",
      "Training accuracy is  0.9009090226128765\n",
      "Epoch  9630 Loss  0.15809468924999237\n",
      "Training accuracy is  0.8920441739914357\n",
      "Epoch  9640 Loss  0.1694268137216568\n",
      "Training accuracy is  0.9181879648411089\n",
      "Epoch  9650 Loss  0.14668111503124237\n",
      "Training accuracy is  0.9202914882428067\n",
      "Epoch  9660 Loss  0.1463189721107483\n",
      "Training accuracy is  0.9207422432574562\n",
      "Epoch  9670 Loss  0.1430642306804657\n",
      "Training accuracy is  0.9217940049583052\n",
      "Epoch  9680 Loss  0.14085467159748077\n",
      "Training accuracy is  0.9226955149876043\n",
      "Epoch  9690 Loss  0.13994455337524414\n",
      "Training accuracy is  0.9223198858087296\n",
      "Epoch  9700 Loss  0.13927021622657776\n",
      "Training accuracy is  0.9220945083014048\n",
      "Epoch  9710 Loss  0.1383252590894699\n",
      "Training accuracy is  0.92201938246563\n",
      "Epoch  9720 Loss  0.1376296877861023\n",
      "Training accuracy is  0.9229960183307039\n",
      "Epoch  9730 Loss  0.1397845596075058\n",
      "Training accuracy is  0.9206671174216813\n",
      "Epoch  9740 Loss  0.13875289261341095\n",
      "Training accuracy is  0.931710615280595\n",
      "Epoch  9750 Loss  0.1371700018644333\n",
      "Training accuracy is  0.9260010517617009\n",
      "Epoch  9760 Loss  0.18247292935848236\n",
      "Training accuracy is  0.9025617909999248\n",
      "Epoch  9770 Loss  0.22984816133975983\n",
      "Training accuracy is  0.8742393509127789\n",
      "Epoch  9780 Loss  0.15646083652973175\n",
      "Training accuracy is  0.8983547441965292\n",
      "Epoch  9790 Loss  0.15043164789676666\n",
      "Training accuracy is  0.9112763879498159\n",
      "Epoch  9800 Loss  0.14610758423805237\n",
      "Training accuracy is  0.9199158590639321\n",
      "Epoch  9810 Loss  0.14578792452812195\n",
      "Training accuracy is  0.9217188791225303\n",
      "Epoch  9820 Loss  0.1432238519191742\n",
      "Training accuracy is  0.9225452633160544\n",
      "Epoch  9830 Loss  0.14196725189685822\n",
      "Training accuracy is  0.9232965216738036\n",
      "Epoch  9840 Loss  0.14098113775253296\n",
      "Training accuracy is  0.9217188791225303\n",
      "Epoch  9850 Loss  0.13985151052474976\n",
      "Training accuracy is  0.9226203891518293\n",
      "Epoch  9860 Loss  0.13893088698387146\n",
      "Training accuracy is  0.9227706408233791\n",
      "Epoch  9870 Loss  0.13805675506591797\n",
      "Training accuracy is  0.9225452633160544\n",
      "Epoch  9880 Loss  0.13896474242210388\n",
      "Training accuracy is  0.9311096085943956\n",
      "Epoch  9890 Loss  0.156617671251297\n",
      "Training accuracy is  0.8876117496807152\n",
      "Epoch  9900 Loss  0.1520867496728897\n",
      "Training accuracy is  0.9155585605889865\n",
      "Epoch  9910 Loss  0.14129352569580078\n",
      "Training accuracy is  0.9398242055442867\n",
      "Epoch  9920 Loss  0.15047183632850647\n",
      "Training accuracy is  0.9436556231688078\n",
      "Epoch  9930 Loss  0.13915970921516418\n",
      "Training accuracy is  0.9217188791225303\n",
      "Epoch  9940 Loss  0.1478443294763565\n",
      "Training accuracy is  0.9203666140785817\n",
      "Epoch  9950 Loss  0.14403028786182404\n",
      "Training accuracy is  0.9262264292690257\n",
      "Epoch  9960 Loss  0.19486303627490997\n",
      "Training accuracy is  0.9087972353692435\n",
      "Epoch  9970 Loss  0.14041389524936676\n",
      "Training accuracy is  0.9233716475095786\n",
      "Epoch  9980 Loss  0.1561369150876999\n",
      "Training accuracy is  0.9251746675681767\n",
      "Epoch  9990 Loss  0.14368967711925507\n",
      "Training accuracy is  0.934640522875817\n",
      "Epoch  10000 Loss  0.14830003678798676\n",
      "Training accuracy is  0.9128540305010894\n",
      "Epoch  10010 Loss  0.1389359086751938\n",
      "Training accuracy is  0.9181879648411089\n",
      "Epoch  10020 Loss  0.14785438776016235\n",
      "Training accuracy is  0.9177372098264593\n",
      "Epoch  10030 Loss  0.14272695779800415\n",
      "Training accuracy is  0.9201412365712569\n",
      "Epoch  10040 Loss  0.13737815618515015\n",
      "Training accuracy is  0.9235218991811284\n",
      "Epoch  10050 Loss  0.13888444006443024\n",
      "Training accuracy is  0.9306588535797461\n",
      "Epoch  10060 Loss  0.1601618230342865\n",
      "Training accuracy is  0.9118773946360154\n",
      "Epoch  10070 Loss  0.13887131214141846\n",
      "Training accuracy is  0.8876117496807152\n",
      "Epoch  10080 Loss  0.37330350279808044\n",
      "Training accuracy is  0.8890391405604388\n",
      "Epoch  10090 Loss  0.18746241927146912\n",
      "Training accuracy is  0.8983547441965292\n",
      "Epoch  10100 Loss  0.15091240406036377\n",
      "Training accuracy is  0.9006836451055518\n",
      "Epoch  10110 Loss  0.1522897630929947\n",
      "Training accuracy is  0.9178874614980091\n",
      "Epoch  10120 Loss  0.15069612860679626\n",
      "Training accuracy is  0.9199158590639321\n",
      "Epoch  10130 Loss  0.14623340964317322\n",
      "Training accuracy is  0.9211929982721058\n",
      "Epoch  10140 Loss  0.14503921568393707\n",
      "Training accuracy is  0.9220945083014048\n",
      "Epoch  10150 Loss  0.14406980574131012\n",
      "Training accuracy is  0.9208173690932312\n",
      "Epoch  10160 Loss  0.14303869009017944\n",
      "Training accuracy is  0.9212681241078807\n",
      "Epoch  10170 Loss  0.142099991440773\n",
      "Training accuracy is  0.9212681241078807\n",
      "Epoch  10180 Loss  0.1412353366613388\n",
      "Training accuracy is  0.9214183757794305\n",
      "Epoch  10190 Loss  0.14035843312740326\n",
      "Training accuracy is  0.9215686274509803\n",
      "Epoch  10200 Loss  0.1394435465335846\n",
      "Training accuracy is  0.9220945083014048\n",
      "Epoch  10210 Loss  0.13859236240386963\n",
      "Training accuracy is  0.9224701374802795\n",
      "Epoch  10220 Loss  0.13775567710399628\n",
      "Training accuracy is  0.9226955149876043\n",
      "Epoch  10230 Loss  0.13917280733585358\n",
      "Training accuracy is  0.9389978213507625\n",
      "Epoch  10240 Loss  0.14016032218933105\n",
      "Training accuracy is  0.9412515964240102\n",
      "Epoch  10250 Loss  0.1592981368303299\n",
      "Training accuracy is  0.926902561791\n",
      "Epoch  10260 Loss  0.13844436407089233\n",
      "Training accuracy is  0.9326121253098941\n",
      "Epoch  10270 Loss  0.14592225849628448\n",
      "Training accuracy is  0.9216437532867553\n",
      "Epoch  10280 Loss  0.2760433554649353\n",
      "Training accuracy is  0.9065434602959958\n",
      "Epoch  10290 Loss  0.19519367814064026\n",
      "Training accuracy is  0.9239726541957779\n",
      "Epoch  10300 Loss  0.1476464718580246\n",
      "Training accuracy is  0.924874164225077\n",
      "Epoch  10310 Loss  0.1410454362630844\n",
      "Training accuracy is  0.9275786943129742\n",
      "Epoch  10320 Loss  0.13973267376422882\n",
      "Training accuracy is  0.9260010517617009\n",
      "Epoch  10330 Loss  0.13973824679851532\n",
      "Training accuracy is  0.921944256629855\n",
      "Epoch  10340 Loss  0.13842009007930756\n",
      "Training accuracy is  0.922920892494929\n",
      "Epoch  10350 Loss  0.1373012810945511\n",
      "Training accuracy is  0.9225452633160544\n",
      "Epoch  10360 Loss  0.13673032820224762\n",
      "Training accuracy is  0.9228457666591541\n",
      "Epoch  10370 Loss  0.14388713240623474\n",
      "Training accuracy is  0.9212681241078807\n",
      "Epoch  10380 Loss  0.14649604260921478\n",
      "Training accuracy is  0.9207422432574562\n",
      "Epoch  10390 Loss  0.14664405584335327\n",
      "Training accuracy is  0.9205168657501315\n",
      "Epoch  10400 Loss  0.1467759609222412\n",
      "Training accuracy is  0.9178874614980091\n",
      "Epoch  10410 Loss  0.1466188281774521\n",
      "Training accuracy is  0.9266020584479002\n",
      "Epoch  10420 Loss  0.1426815539598465\n",
      "Training accuracy is  0.9498159417023514\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 70)\n",
    "        self.fc2 = nn.Linear(70, 70)\n",
    "        self.fc3 = nn.Linear(70, 70)\n",
    "        self.fc4 = nn.Linear(70, 70)\n",
    "        self.fc5 = nn.Linear(70, 70)\n",
    "        self.fc6 = nn.Linear(70, 70)\n",
    "        self.fc7 = nn.Linear(70, 70)\n",
    "        self.fc8 = nn.Linear(70, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = self.fc8(x)\n",
    "        return F.log_softmax(x)\n",
    "        #return F.softmax(x)\n",
    "\n",
    "#%% plot function      \n",
    "def plot_decision_boundary(clf, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    #x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    #y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    x_min, x_max = -1, 1\n",
    "    y_min, y_max = -1, 1\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    X_out = net(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype = torch.float))\n",
    "    Z = X_out.data.max(1)[1]\n",
    "    # Z.shape\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "\n",
    "#%% read data\n",
    "data = pd.read_csv('FeedForward_Data_star.csv')\n",
    "X = data.values[:, 0:2]  # Take only the first two features.     \n",
    "X = torch.tensor(X, dtype = torch.float)   \n",
    "y = data.values[:, 2]\n",
    "y = torch.tensor(y, dtype = torch.long)\n",
    "\n",
    "#%% train\n",
    "net = Net()\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = .01\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# create a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "nepochs = 20000\n",
    "data, target = X, y\n",
    "# run the main training loop\n",
    "for epoch in range(nepochs):\n",
    "#    adjust learning rate if desired\n",
    "#    if epoch % 3000 == 0 and epoch <= 24000:\n",
    "#        for g in optimizer.param_groups:\n",
    "#            g['lr'] = g['lr']/2\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagate\n",
    "    net_out = net(data)\n",
    "    # compute loss\n",
    "    loss = criterion(net_out, target)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # print out report\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correctidx = pred.eq(target.data) \n",
    "        ncorrect = correctidx.sum()\n",
    "        accuracy = ncorrect.item()/len(data)\n",
    "        print('Training accuracy is ', accuracy)\n",
    "    if accuracy > 0.949:\n",
    "        break\n",
    "\n",
    "#%%  plot outputs\n",
    "plot_decision_boundary(net, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
