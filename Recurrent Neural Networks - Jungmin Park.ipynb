{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Systematic processing of data (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.Effect of hidden state length: run the script for hidden state sizes of 32, 64 and 128 by modifying the value of variable n_hidden. Report the accuracy numbers yielded by the different algorithm variants. (5 points).\n",
    "\n",
    "Hidden size = 32 -> accuracy = 0.933197\n",
    "\n",
    "Hidden size = 64 -> accuracy = 0.940072\n",
    "\n",
    "Hidden size = 128 -> accuracy = 0.943559\n",
    "\n",
    "Average accuracy  = 0.93894267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runned the same code 3 times by only changing the hidden states sizes to 32, 64 and 128\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Build the names dictionary, a list of names per language\n",
    "# dictionary keys are languages, values are names\n",
    "\n",
    "names = {}\n",
    "languages = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    languages.append(category)\n",
    "    lines = readLines(filename)\n",
    "    names[category] = lines\n",
    "\n",
    "n_categories = len(languages)\n",
    "\n",
    "def findName(dict, name):\n",
    "    keys = dict.keys()\n",
    "    for key in keys:\n",
    "        if name in dict[key]:\n",
    "            return key\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return key for any value \n",
    "def get_key(val): \n",
    "    for key, value in names.items(): \n",
    "         if val in value: \n",
    "            return key \n",
    "\n",
    "# X list - names\n",
    "x_list = []\n",
    "for key in names.keys():\n",
    "    x_list.extend(names[key])\n",
    "\n",
    "    \n",
    "# Y list - categories\n",
    "y_list = []\n",
    "for name in x_list:\n",
    "    y_list.append(get_key(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning Names into Tensors\n",
    "# --------------------------\n",
    "import torch\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def nameToTensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, n_letters)\n",
    "    for li, letter in enumerate(name):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Training\n",
    "# ========\n",
    "# Preparing for Training\n",
    "# ----------------------\n",
    "def categoryFromOutput(output):\n",
    "    # compute max\n",
    "    top_n, top_i = output.topk(1)\n",
    "    # output index of max\n",
    "    category_i = top_i.item()\n",
    "    return languages[category_i], category_i\n",
    "\n",
    "# We will also want a quick way to get a training example (a name and its\n",
    "# language):\n",
    "    \n",
    "def randomTrainingExample(i):\n",
    "    category = y_list[i]\n",
    "    name = x_list[i]\n",
    "    category_tensor = torch.tensor([languages.index(category)], dtype=torch.long)\n",
    "    name_tensor = nameToTensor(name)\n",
    "    return category, name, category_tensor, name_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Training the Network\n",
    "# --------------------\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, name_tensor):\n",
    "    # initialize hidden state - do this every time before passing an input sequence\n",
    "    hidden = rnn.initHidden()\n",
    "    # reset grad counters - do this every time after backprop\n",
    "    rnn.zero_grad()\n",
    "    # manually go through each element in input sequence\n",
    "    for i in range(name_tensor.size()[0]):\n",
    "        output, hidden = rnn(name_tensor[i], hidden)\n",
    "    # backpropagate based on loss at last element only\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Update network parameters\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.944605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(n_confusion):\\n    category, name, category_tensor, name_tensor = randomTrainingExample(i)\\n    print(i)\\n    output = evaluate(name_tensor)\\n    guess, guess_i = categoryFromOutput(output)\\n    category_i = languages.index(category)\\n    confusion[category_i][guess_i] += 1\\n    \\naccuracy = sum(confusion.diag())/sum(sum(confusion))\\nprint('Accuracy is %f' % accuracy.item())\\n\\n#n_correct = 0\\n#for iter in range(1, n_iters + 1):\\n#        category, line, category_tensor, line_tensor = randomTrainingExample()\\n#        print(iter)\\n#        output, loss = train(category_tensor, line_tensor)\\n#        current_loss += loss\\n#        guess, guess_i = categoryFromOutput(output)\\n#        category_i = languages.index(category)\\n#        # compare category_i, guess_i\\n#        if category_i == guess_i:\\n#            n_correct += 1\\n\\n#accuracy = n_correct / len(x_list)\\n#print('Accuracy is %f' % accuracy)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iters = len(x_list)\n",
    "print_every = 5\n",
    "plot_every = 1000\n",
    "\n",
    "# Keep track of loss for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "n_correct = 0\n",
    "\n",
    "for iter in range(0, n_iters):\n",
    "    category, name, category_tensor, name_tensor = randomTrainingExample(iter)\n",
    "    output, loss = train(category_tensor, name_tensor)\n",
    "    current_loss += loss\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    if guess == category:\n",
    "        n_correct += 1\n",
    "            \n",
    "accuracy = n_correct / len(x_list)\n",
    "print('Accuracy is %f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.Effect of systematic training: the script trains the network by going through 100 thousand data samples (see variable n_iters) one by one in a random manner. The network parameters are updated by backpropagating losses computed on a per-sample basis. Modify the script so that, instead of picking each training sample randomly, it goes through every available sample exactly once per training epoch. Randomize the order of the samples within each epoch. Train the network for five epochs, and report accuracy results as you change the hidden state size as in problem 1.1. Since the dataset comprises around 20 thousand datapoints, the total number of data passes for this modified training process are similar to those required by problem 1.1. Report the accuracy numbers yielded by the different algorithm variants. (10 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runned this code 3 times for each different hidden state size (32, 64, 128)\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Build the names dictionary, a list of names per language\n",
    "# dictionary keys are languages, values are names\n",
    "names = {}\n",
    "languages = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    languages.append(category)\n",
    "    lines = readLines(filename)\n",
    "    names[category] = lines\n",
    "\n",
    "n_categories = len(languages)\n",
    "\n",
    "def findName(dict, name):\n",
    "    keys = dict.keys()\n",
    "    for key in keys:\n",
    "        if name in dict[key]:\n",
    "            return key\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return key for any value \n",
    "def get_key(val): \n",
    "    for key, value in names.items(): \n",
    "         if val in value: \n",
    "            return key \n",
    "\n",
    "# X list - names\n",
    "x_list = []\n",
    "for key in names.keys():\n",
    "    x_list.extend(names[key])\n",
    "\n",
    "    \n",
    "# Y list - categories\n",
    "y_list = []\n",
    "for name in x_list:\n",
    "    y_list.append(get_key(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning Names into Tensors\n",
    "# --------------------------\n",
    "import torch\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def nameToTensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, n_letters)\n",
    "    for li, letter in enumerate(name):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 32\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Training\n",
    "# ========\n",
    "# Preparing for Training\n",
    "# ----------------------\n",
    "def categoryFromOutput(output):\n",
    "    # compute max\n",
    "    top_n, top_i = output.topk(1)\n",
    "    # output index of max\n",
    "    category_i = top_i.item()\n",
    "    return languages[category_i], category_i\n",
    "\n",
    "# We will also want a quick way to get a training example (a name and its\n",
    "# language):\n",
    "\n",
    "# tuple (category, name) list\n",
    "category_name_list = []\n",
    "\n",
    "# list of index from 0 to 20073\n",
    "index_list=[x for x in range(0,len(y_list))]\n",
    "\n",
    "for i in index_list:\n",
    "    category_name_list.append( (y_list[i], x_list[i]) ) \n",
    "    \n",
    "    \n",
    "def randomTrainingExample():\n",
    "    random_index = random.choice(index_list)\n",
    "    index_list.remove(random_index)\n",
    "    category = category_name_list[random_index][0]\n",
    "    name = category_name_list[random_index][1]\n",
    "    category_tensor = torch.tensor([languages.index(category)], dtype=torch.long)\n",
    "    name_tensor = nameToTensor(name)\n",
    "    return category, name, category_tensor, name_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Training the Network\n",
    "# --------------------\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, name_tensor):\n",
    "    # initialize hidden state - do this every time before passing an input sequence\n",
    "    hidden = rnn.initHidden()\n",
    "    # reset grad counters - do this every time after backprop\n",
    "    rnn.zero_grad()\n",
    "    # manually go through each element in input sequence\n",
    "    for i in range(name_tensor.size()[0]):\n",
    "        output, hidden = rnn(name_tensor[i], hidden)\n",
    "    # backpropagate based on loss at last element only\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Update network parameters\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.725267\n"
     ]
    }
   ],
   "source": [
    "# number of total data samples\n",
    "n_iters = len(x_list)\n",
    "\n",
    "# Keep track of loss for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "nepoch = 5\n",
    "print_every = 100\n",
    "n_correct = 0\n",
    "\n",
    "for epoch in range(nepoch):\n",
    "    # number of category_i equals to guess_i\n",
    "    n_correct = 0\n",
    "    index_list=[x for x in range(0,len(y_list))]\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        category, name, category_tensor, name_tensor = randomTrainingExample()\n",
    "        output, loss = train(category_tensor, name_tensor)\n",
    "        current_loss += loss\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        if guess == category:\n",
    "            n_correct += 1\n",
    "        # Print iter number, loss, name and guess\n",
    "        #correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        #print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, name, guess, correct))\n",
    "\n",
    "accuracy = n_correct / len(x_list)\n",
    "print('Accuracy is %f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
